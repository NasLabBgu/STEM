{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import List, Any, Dict, Tuple, Set, Iterable, Sequence\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, starmap, groupby, product, chain, islice\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from conversant.conversation import Conversation\n",
    "from conversant.interactions import InteractionsGraph\n",
    "from conversant.interactions.interactions_graph import PairInteractionsData\n",
    "from stance_classification.data.iac import FourForumInteractionsBuilder\n",
    "from stance_classification.data.iac.fourforum_data import load_post_records, build_conversations\n",
    "from stance_classification.data.iac.fourforum_labels import load_author_labels, AuthorLabel\n",
    "%matplotlib inline\n",
    "\n",
    "from stance_classification.classifiers.maxcut_stance_classifier import MaxcutStanceClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''â€¦",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1466a69e0aa04dc79919f3bd11ce0a37"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load quotes mapping\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/home/dev/data/stance/IAC/alternative/fourforums\"\n",
    "records = tqdm(load_post_records(data_path))\n",
    "# convs = list(islice(build_conversations(records), 100))\n",
    "convs = list(build_conversations(records))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11079\n",
      "37.40888166802058\n",
      "17.0\n"
     ]
    }
   ],
   "source": [
    "sizes = [c.size for c in convs]\n",
    "print(len(sizes))\n",
    "print(np.mean(sizes))\n",
    "print(np.median(sizes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7165\n",
      "55.2115840893231\n",
      "32.0\n"
     ]
    }
   ],
   "source": [
    "filtered_sizes = [s for s in sizes if s >= 10]\n",
    "print(len(filtered_sizes))\n",
    "print(np.mean(filtered_sizes))\n",
    "print(np.median(filtered_sizes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Author labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324\n",
      "4188\n"
     ]
    }
   ],
   "source": [
    "def create_author_labels_dict(labels: Iterable[AuthorLabel]) -> Dict[Any, int]:\n",
    "    return {l.author_id: (l.stance - 2) for l in labels if l.stance is not None}\n",
    "\n",
    "path = \"/home/dev/data/stance/IAC/alternative/fourforums/mturk_author_stance.txt\"\n",
    "author_labels = list(load_author_labels(path))\n",
    "author_labels_per_conversation = {cid: create_author_labels_dict(labels) for cid, labels in groupby(author_labels, key=lambda a: a.discussion_id)}\n",
    "author_labels_per_conversation = {k: v for k, v in author_labels_per_conversation.items() if len(v) > 0}\n",
    "print(len(author_labels_per_conversation))\n",
    "print(sum(len(v) for v in author_labels_per_conversation.values()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load posts labels (Chang Li)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "24658"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_post_label_mapping(path: str) -> Dict[str, int]:\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def decode_original_post_identification(post_id: str) -> Tuple[str, int, int]:\n",
    "    topic, numeric_id = post_id.split('.')\n",
    "    original_discussion_index = int(numeric_id[:-5])\n",
    "    original_post_index = int(numeric_id[-3:])\n",
    "    return topic, original_discussion_index, original_post_index\n",
    "\n",
    "\n",
    "labels_path = \"/home/dev/data/stance/chang-li/data/compressed-4forum/allPostLabelMap.pickle\"\n",
    "raw_post_labels = load_post_label_mapping(labels_path)\n",
    "post_labels = {itemgetter(1,2)(decode_original_post_identification(raw_post_id)): (stance % 2) for (raw_post_id, stance) in raw_post_labels.items()}\n",
    "len(post_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def get_author_labels(conv: Conversation) -> Dict[Any, int]:\n",
    "    if conv.id not in author_labels_per_conversation:\n",
    "        return None\n",
    "\n",
    "    return author_labels_per_conversation[conv.id]\n",
    "\n",
    "def get_maxcut_results(graph: InteractionsGraph, op: Any) -> MaxcutStanceClassifier:\n",
    "    maxcut = MaxcutStanceClassifier(weight_field=graph.WEIGHT_FIELD)\n",
    "    maxcut.set_input(graph.graph)\n",
    "    maxcut.classify_stance(op)\n",
    "    return maxcut\n",
    "\n",
    "def align_gs_with_predictions(maxcut: MaxcutStanceClassifier, authors_labels: Dict[Any, int]) -> Tuple[List[int], List[int]]:\n",
    "    support_label = authors_labels[op]\n",
    "    opposer_label = 1 - support_label\n",
    "    supporters = maxcut.get_supporters()\n",
    "    opposers = maxcut.get_complement()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    for supporter in supporters:\n",
    "        true_label = authors_labels.get(supporter)\n",
    "        if true_label is not None:\n",
    "            y_true.append(true_label)\n",
    "            y_pred.append(support_label)\n",
    "\n",
    "    for opposer in opposers:\n",
    "        true_label = authors_labels.get(opposer)\n",
    "        if true_label is not None:\n",
    "            y_true.append(true_label)\n",
    "            y_pred.append(opposer_label)\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "def predict_for_partition(true: List[int], preds: List[int]) -> Tuple[List[int], List[int]]:\n",
    "    acc = accuracy_score(true, preds)\n",
    "    if acc < 0.5:\n",
    "        preds = [1-l for l in preds]\n",
    "\n",
    "    return true, preds\n",
    "\n",
    "def predict_post_labels(conv: Conversation, post_labels: Dict[Any, int], supporters: Set[int], opposers: Set[int]) -> Tuple[List[int], List[int]]:\n",
    "    y_true, y_pred = [], []\n",
    "    conv_id = conv.id\n",
    "    for depth, node in conv.iter_conversation():\n",
    "        label = post_labels.get((conv_id, node.node_id), None)\n",
    "        if label is None: continue\n",
    "\n",
    "        author = node.author\n",
    "        pred = 0 if author in supporters else 1 if author in opposers else None\n",
    "        if pred is None: continue\n",
    "\n",
    "        y_true.append(label)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    return y_true, y_pred\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=11079.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e0f00868a4e64bb0996609e3ac8f51c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "interactions_parser = FourForumInteractionsBuilder()\n",
    "author_true, author_pred = [], []\n",
    "author_true_partition, author_pred_partition = [], []\n",
    "posts_true, posts_pred = [], []\n",
    "post_true_partition, post_pred_partition = [], []\n",
    "filtered_convs = []\n",
    "full_graphs = []\n",
    "core_graphs = []\n",
    "maxcut_results: List[MaxcutStanceClassifier] = []\n",
    "classification_results: List[Tuple[List[int], List[int]]] = []\n",
    "empty_core = []\n",
    "unlabeled_conversations = []\n",
    "unlabeled_op = []\n",
    "insufficient_author_labels = []\n",
    "too_small_cut_value = []\n",
    "op_not_in_core = []\n",
    "large_graphs = []\n",
    "\n",
    "def calc_weight(interactions: PairInteractionsData) -> float:\n",
    "    n_replies = interactions[\"replies\"]\n",
    "    n_quotes = interactions[\"quotes\"]\n",
    "    # return n_replies + n_quotes\n",
    "    return n_quotes\n",
    "\n",
    "\"\"\"abortion = 3\n",
    "   evolution = 7\n",
    "   gay marriage = 8\n",
    "   gun control = 9\n",
    "   \"\"\"\n",
    "# convs[0].root.data[\"topic\"]\n",
    "# conv: Conversation\n",
    "for conv in tqdm(convs):\n",
    "    topic = conv.root.data[\"topic\"]\n",
    "    if topic != 9: continue\n",
    "    authors_labels = get_author_labels(conv)\n",
    "    if authors_labels is None:\n",
    "        unlabeled_conversations.append(conv)\n",
    "        continue\n",
    "\n",
    "    op = conv.root.author\n",
    "    if op not in authors_labels:\n",
    "        unlabeled_op.append(conv)\n",
    "        continue\n",
    "\n",
    "    if len(authors_labels) < 3:\n",
    "        insufficient_author_labels.append(conv)\n",
    "        continue\n",
    "\n",
    "    interaction_graph = interactions_parser.build(conv)\n",
    "\n",
    "    interaction_graph.set_interaction_weights(calc_weight)\n",
    "    zero_edges = [(v, u) for v, u, d in interaction_graph.graph.edges(data=True) if d[\"weight\"] == 0]\n",
    "    interaction_graph.graph.remove_edges_from(zero_edges)\n",
    "\n",
    "    core_interactions = interaction_graph.get_core_interactions()\n",
    "    if op not in core_interactions.graph.nodes:\n",
    "        op_not_in_core.append(conv)\n",
    "        continue\n",
    "\n",
    "    core_interactions = core_interactions.get_op_connected_components()\n",
    "    if core_interactions.graph.size() < 2:\n",
    "            empty_core.append(conv)\n",
    "            continue\n",
    "\n",
    "    # if core_interactions.graph.order() > 120:\n",
    "    #     large_graphs.append(conv)\n",
    "    #     continue\n",
    "\n",
    "    maxcut = get_maxcut_results(core_interactions, op)\n",
    "    if maxcut.cut_value < 3:\n",
    "        too_small_cut_value.append(conv)\n",
    "        continue\n",
    "\n",
    "    true, preds = align_gs_with_predictions(maxcut, authors_labels)\n",
    "    author_true.append(true)\n",
    "    author_pred.append(preds)\n",
    "\n",
    "    true, preds = predict_for_partition(true, preds)\n",
    "    author_true_partition.append(true)\n",
    "    author_pred_partition.append(preds)\n",
    "\n",
    "    true, preds = predict_post_labels(conv, post_labels, maxcut.get_supporters(), maxcut.get_complement())\n",
    "    posts_true.append(true)\n",
    "    posts_pred.append(preds)\n",
    "\n",
    "    true, preds = predict_for_partition(true, preds)\n",
    "    post_true_partition.append(true)\n",
    "    post_pred_partition.append(preds)\n",
    "\n",
    "    filtered_convs.append(conv)\n",
    "    full_graphs.append(interaction_graph)\n",
    "    core_graphs.append(core_interactions)\n",
    "    maxcut_results.append(maxcut)\n",
    "    classification_results.append((true, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of conversations: 11079\n",
      "total number of conversations with labeled authors: 324\n",
      "number of conversations in eval: 27\n",
      "total number of labeled authors: 4188\n",
      "number of authors in eval: 27\n",
      "number of posts in eval: 27\n",
      "=========\n",
      "number of conversations with empty core: 0\n",
      "number of conversations with op not in core: 12\n",
      "number of conversations with too large core: 0\n",
      "number of conversations with too small cut value: 0\n",
      "number of unlabeled conversations: 856\n",
      "number of conversations with unlabeled op: 9\n",
      "number of conversations with insufficient labeled authors: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"total number of conversations: {len(convs)}\")\n",
    "print(f\"total number of conversations with labeled authors: {len(author_labels_per_conversation)}\")\n",
    "print(f\"number of conversations in eval: {len(filtered_convs)}\")\n",
    "labeled_authors = sum(len(v) for v in author_labels_per_conversation.values())\n",
    "print(f\"total number of labeled authors: {labeled_authors}\")\n",
    "print(f\"number of authors in eval: {len(author_true)}\")\n",
    "print(f\"number of posts in eval: {len(posts_true)}\")\n",
    "print(\"=========\")\n",
    "print(f\"number of conversations with empty core: {len(empty_core)}\")\n",
    "print(f\"number of conversations with op not in core: {len(op_not_in_core)}\")\n",
    "print(f\"number of conversations with too large core: {len(large_graphs)}\")\n",
    "print(f\"number of conversations with too small cut value: {len(too_small_cut_value)}\")\n",
    "print(f\"number of unlabeled conversations: {len(unlabeled_conversations)}\")\n",
    "print(f\"number of conversations with unlabeled op: {len(unlabeled_op)}\")\n",
    "print(f\"number of conversations with insufficient labeled authors: {len(insufficient_author_labels)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.92      0.78        86\n",
      "           1       0.94      0.75      0.84       149\n",
      "\n",
      "    accuracy                           0.81       235\n",
      "   macro avg       0.81      0.84      0.81       235\n",
      "weighted avg       0.85      0.81      0.82       235\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = list(chain(*author_true))\n",
    "y_pred = list(chain(*author_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.77      0.86      1103\n",
      "           1       0.85      0.99      0.91      1423\n",
      "\n",
      "    accuracy                           0.89      2526\n",
      "   macro avg       0.92      0.88      0.89      2526\n",
      "weighted avg       0.91      0.89      0.89      2526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = [l%2 for l in list(chain(*post_true_partition))]\n",
    "y_true = list(chain(*post_pred_partition))\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "def compute_pairs_average_distance(\n",
    "        pairs: Iterable[Tuple[int, int]],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    distances = list(starmap(lambda i, j: cosine(embeddings[i], embeddings[j]), pairs))\n",
    "    return float(np.mean(distances))\n",
    "\n",
    "\n",
    "def compute_average_angle_from_node(\n",
    "        node_index: int,\n",
    "        group_indices: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = ((node_index, i) for i in group_indices)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)\n",
    "\n",
    "\n",
    "def compute_group_average_angle(\n",
    "        group_indices: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = combinations(group_indices, 2)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)\n",
    "\n",
    "\n",
    "def compute_cross_groups_average_angle(\n",
    "        group1: Sequence[int],\n",
    "        group2: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = product(group1, group2)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total conversations 27\n",
      "supporters avg. cosine 0.19147302200149308\n",
      "opposers avg. cosine 0.18682940321769442\n",
      "cross groups avg. cosine 1.8421883878213943\n",
      "op to supporters avg. cosine 0.1319225727938942\n",
      "op to opposers avg. cosine 1.8700531134749667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dev/.virtualenvs/conv/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/home/dev/.virtualenvs/conv/lib/python3.8/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "supporters_avg_angles = []\n",
    "opposers_avg_angles = []\n",
    "mean_cross_angle = []\n",
    "op2supporters = []\n",
    "op2opposers = []\n",
    "for i in range(len(maxcut_results)):\n",
    "    maxcut = maxcut_results[i]\n",
    "    op, all_embeddings, supporters, opposers =\\\n",
    "        maxcut.op, maxcut.embeddings, maxcut.get_supporters(), maxcut.get_complement()\n",
    "\n",
    "    op2supporters.append(compute_average_angle_from_node(op, supporters, all_embeddings))\n",
    "    op2opposers.append(compute_average_angle_from_node(op, opposers, all_embeddings))\n",
    "\n",
    "    supporters_avg_angles.append(compute_group_average_angle(supporters, all_embeddings))\n",
    "    opposers_avg_angles.append(compute_group_average_angle(opposers, all_embeddings))\n",
    "\n",
    "    mean_cross_angle.append(compute_cross_groups_average_angle(supporters, opposers, all_embeddings))\n",
    "\n",
    "print(f\"total conversations {len(maxcut_results)}\")\n",
    "print(f\"supporters avg. cosine {np.nanmean(supporters_avg_angles)}\")\n",
    "print(f\"opposers avg. cosine {np.nanmean(opposers_avg_angles)}\")\n",
    "print(f\"cross groups avg. cosine {np.mean(mean_cross_angle)}\")\n",
    "print(f\"op to supporters avg. cosine {np.mean(op2supporters)}\")\n",
    "print(f\"op to opposers avg. cosine {np.mean(op2opposers)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "26"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strong_convs_indices = []\n",
    "for i in range(len(filtered_convs)):\n",
    "    op2s = op2supporters[i]\n",
    "    op2o = op2opposers[i]\n",
    "    if op2supporters[i] * op2opposers[i] == 0:\n",
    "        continue\n",
    "\n",
    "    diff = op2o - op2s\n",
    "    ratio = op2o / op2s\n",
    "    if (ratio > 2) and (diff > 1):\n",
    "        strong_convs_indices.append(i)\n",
    "\n",
    "len(strong_convs_indices)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.99      0.88       784\n",
      "           1       0.99      0.86      0.92      1380\n",
      "\n",
      "    accuracy                           0.90      2164\n",
      "   macro avg       0.89      0.92      0.90      2164\n",
      "weighted avg       0.92      0.90      0.90      2164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "strong_true, strong_preds = zip(*[classification_results[i] for i in strong_convs_indices])\n",
    "strong_true = list(chain(*strong_true))\n",
    "strong_preds = list(chain(*strong_preds))\n",
    "print(classification_report(strong_true, strong_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[(21, 23),\n (1, 18),\n (20, 15),\n (12, 14),\n (25, 14),\n (15, 13),\n (5, 12),\n (3, 11),\n (13, 11),\n (2, 10),\n (19, 10),\n (9, 9),\n (10, 9),\n (4, 8),\n (6, 8),\n (16, 8),\n (0, 7),\n (8, 7),\n (22, 7),\n (23, 7)]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_i = 0\n",
    "max_shape = 0\n",
    "# sizes = [(i, g.graph.order()) for i, g  in enumerate(core_graphs)]\n",
    "sizes = [(i, core_graphs[i].graph.order()) for i in strong_convs_indices]\n",
    "sorted_sized = sorted(sizes, key=itemgetter(1), reverse=True)\n",
    "sorted_sized[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mIndexError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-17-cba3f9c40ca7>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mresult_index\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m91\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mmaxcut\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmaxcut_results\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mresult_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0memb\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msupporters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mopposers\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmaxcut\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mop\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmaxcut\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membeddings\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmaxcut\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_supporters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmaxcut\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_complement\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mIndexError\u001B[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "result_index = 91\n",
    "\n",
    "maxcut = maxcut_results[result_index]\n",
    "op, emb, supporters, opposers = maxcut.op, maxcut.embeddings, maxcut.get_supporters(), maxcut.get_complement()\n",
    "\n",
    "s_cosine = compute_group_average_angle(supporters, emb)\n",
    "o_cosine = compute_group_average_angle(opposers, emb)\n",
    "cross_cosine = compute_cross_groups_average_angle(supporters, opposers, emb)\n",
    "op2support = compute_average_angle_from_node(op, supporters, emb)\n",
    "op2oppose = compute_average_angle_from_node(op, opposers, emb)\n",
    "print(f\"num supporters: {len(supporters)}\")\n",
    "print(f\"num opposers: {len(opposers)}\")\n",
    "print(f\"supporters avg. cosine: {s_cosine}\")\n",
    "print(f\"opposers avg. cosine: {o_cosine}\")\n",
    "print(f\"cross-groups avg. cosine: {cross_cosine}\")\n",
    "print(f\"op <-> supporters avg. cosine: {op2support}\")\n",
    "print(f\"op <-> opposers avg. cosine: {op2oppose}\")\n",
    "print(f\"supporters - opposers diff cosine with op: {op2oppose - op2support}\")\n",
    "print(f\"supporters - opposers ratio cosine with op: {op2oppose / op2support}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true, preds = classification_results[result_index]\n",
    "print(classification_report(true, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true, preds = post_true_partition[result_index], post_pred_partition[result_index]\n",
    "print(classification_report(true, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv = filtered_convs[result_index]\n",
    "authors_labels = get_author_labels(conv)\n",
    "true_supporters = [n for n, l in author_labels.items() if l == 1]\n",
    "true_opposers = [n for n, l in author_labels.items() if l == 0]\n",
    "unknown_labels = (set(supporters) | set(opposers)) - set(author_labels.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "\n",
    "X = np.vstack([np.array(x) for x in emb.values()])\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "# X_2d = TSNE(n_components=2).fit_transform(X)\n",
    "print(pca.explained_variance_)\n",
    "op = maxcut.op\n",
    "nodes = emb.keys()\n",
    "tp_supporters_indices = [i for i, n in enumerate(nodes) if n in true_supporters and n in supporters]\n",
    "fn_supporters_indices = [i for i, n in enumerate(nodes) if n in true_supporters and n in opposers]\n",
    "tp_opposers_indices = [i for i, n in enumerate(nodes) if n in true_opposers and n in opposers]\n",
    "fn_opposers_indices = [i for i, n in enumerate(nodes) if n in true_opposers and n in supporters]\n",
    "unlabeled_supporters = [i for i, n in enumerate(nodes) if n not in author_labels and n in supporters]\n",
    "unlabeled_opposers = [i for i, n in enumerate(nodes) if n not in author_labels and n in opposers]\n",
    "\n",
    "op_index = [i for i, n in enumerate(nodes) if n == op]\n",
    "\n",
    "plt.scatter(X_2d[tp_supporters_indices, 0], X_2d[tp_supporters_indices, 1], color='g', marker='+')\n",
    "plt.scatter(X_2d[fn_supporters_indices, 0], X_2d[fn_supporters_indices, 1], color='r', marker='+')\n",
    "plt.scatter(X_2d[tp_opposers_indices, 0], X_2d[tp_opposers_indices, 1], color='r', marker='x')\n",
    "plt.scatter(X_2d[fn_opposers_indices, 0], X_2d[fn_opposers_indices, 1], color='g', marker='x')\n",
    "plt.scatter(X_2d[unlabeled_supporters, 0], X_2d[unlabeled_supporters, 1], color='g', marker='_')\n",
    "plt.scatter(X_2d[unlabeled_opposers, 0], X_2d[unlabeled_opposers, 1], color='r', marker='_')\n",
    "plt.scatter([X_2d[op_index, 0]], [X_2d[op_index, 1]], color='b', marker='o')\n",
    "\n",
    "# colors = ['b' if i == op else 'g' if i in supporters else 'r' for i in nodes]\n",
    "# markers = ['o' if i ==op else 'x' if i in supporters else '+' for i in nodes]\n",
    "# plt.scatter(X_2d[:, 0], X_2d[:, 1], color=colors)\n",
    "# op_index = [i for i, n  in enumerate(nodes) if n == op][0]\n",
    "\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_id = filtered_convs[result_index].id\n",
    "author_labels = author_labels_per_conversation[conv_id]\n",
    "print(author_labels)\n",
    "maxcut.draw(true_labels=author_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_graph = full_graphs[result_index]\n",
    "layout = nx.spring_layout(full_graph.graph)\n",
    "nx.draw(full_graph.graph, layout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kcore = core_graphs[result_index]\n",
    "layout = nx.spring_layout(kcore.graph)\n",
    "nx.draw(kcore.graph, layout)\n",
    "\n",
    "kcore.graph.order()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Evaluating Post-Level"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading posts labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Predicting posts labels\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}