{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from typing import List, Any, Dict, Tuple, Set, Iterable, Sequence\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, starmap, groupby, product, chain, islice\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from conversant.conversation import Conversation\n",
    "from conversant.conversation.parse import DataFrameConversationReader\n",
    "from conversant.interactions import InteractionsGraph\n",
    "from conversant.interactions.interactions_graph import PairInteractionsData\n",
    "from conversant.interactions.reply_interactions_parser import get_reply_interactions_parser\n",
    "from stance_classification.classifiers.base_stance_classifier import BaseStanceClassifier\n",
    "from stance_classification.classifiers.greedy_stance_classifier import MSTStanceClassifier\n",
    "from stance_classification.data.iac.convinceme_conversation_parser import ConvinceMeConversationParser\n",
    "from stance_classification.draw_utils import new_figure\n",
    "%matplotlib inline\n",
    "\n",
    "from stance_classification.classifiers.maxcut_stance_classifier import MaxcutStanceClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "       discussion_id  post_id  parent_post_id  parent_missing  author_id  \\\n0                  1        1             NaN               0         10   \n1                  1        2             NaN               0         12   \n2                  1        3             NaN               0          1   \n3                  1        4             2.0               0          1   \n4                  1        5             6.0               0          1   \n...              ...      ...             ...             ...        ...   \n65363           5413        1             NaN               0       5782   \n65364           5413        2             NaN               0       3747   \n65365           5413        3             NaN               0       5783   \n65366           5413        4             NaN               0       5649   \n65367           5413        5             NaN               0       5688   \n\n                            username            timestamp  \\\n0                               king  2007-01-02 00:00:00   \n1                            mknorpp  2007-01-04 00:00:00   \n2                   kittycatmeowmeow  2007-02-01 00:00:00   \n3                   kittycatmeowmeow  2007-02-01 00:00:00   \n4                   kittycatmeowmeow  2007-02-01 00:00:00   \n...                              ...                  ...   \n65363                 Rich Dellinger  2012-07-28 00:00:00   \n65364              Leonardo Carvalho  2012-08-05 00:00:00   \n65365              Samuel Hermansson  2012-08-06 00:00:00   \n65366                  Hany Mohammed  2012-08-16 00:00:00   \n65367  Natasha Lynn Valentine Hudson  2012-09-02 00:00:00   \n\n                                                    text  \\\n0      I have never used iMovie before, but I have us...   \n1      EVERYTHING is difficult to do on a PC...Mac's ...   \n2      Everything may be hard to do on a PC if you ar...   \n3      I have a website.\\nI do not have a mac.\\nI hav...   \n4      Maybe you should use better software for the m...   \n...                                                  ...   \n65363  TV is just a tool. It is how you use it that m...   \n65364  The concept of TV and media is brilliant, incr...   \n65365  I think that TV has helped us with many things...   \n65366  I will use analogy to explain…\\nIf I present a...   \n65367  People spend hours in front of a television. A...   \n\n                                       discussion_stance topic stance  votes  \n0      Mac's iMovie is easier to use, and produces a ...   NaN    NaN     58  \n1      Mac's iMovie is easier to use, and produces a ...   NaN    NaN     59  \n2      Windows Media Maker is easier to use, and prod...   NaN    NaN      1  \n3      Windows Media Maker is easier to use, and prod...   NaN    NaN      0  \n4      Windows Media Maker is easier to use, and prod...   NaN    NaN      0  \n...                                                  ...   ...    ...    ...  \n65363                                                 No   NaN    NaN      1  \n65364                                                 No   NaN    NaN      1  \n65365                                                Yes   NaN    NaN      0  \n65366                                                 No   NaN    NaN      1  \n65367                                                Yes   NaN    NaN      0  \n\n[65368 rows x 12 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discussion_id</th>\n      <th>post_id</th>\n      <th>parent_post_id</th>\n      <th>parent_missing</th>\n      <th>author_id</th>\n      <th>username</th>\n      <th>timestamp</th>\n      <th>text</th>\n      <th>discussion_stance</th>\n      <th>topic</th>\n      <th>stance</th>\n      <th>votes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>10</td>\n      <td>king</td>\n      <td>2007-01-02 00:00:00</td>\n      <td>I have never used iMovie before, but I have us...</td>\n      <td>Mac's iMovie is easier to use, and produces a ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>12</td>\n      <td>mknorpp</td>\n      <td>2007-01-04 00:00:00</td>\n      <td>EVERYTHING is difficult to do on a PC...Mac's ...</td>\n      <td>Mac's iMovie is easier to use, and produces a ...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>59</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>1</td>\n      <td>kittycatmeowmeow</td>\n      <td>2007-02-01 00:00:00</td>\n      <td>Everything may be hard to do on a PC if you ar...</td>\n      <td>Windows Media Maker is easier to use, and prod...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>2.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>kittycatmeowmeow</td>\n      <td>2007-02-01 00:00:00</td>\n      <td>I have a website.\\nI do not have a mac.\\nI hav...</td>\n      <td>Windows Media Maker is easier to use, and prod...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>6.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>kittycatmeowmeow</td>\n      <td>2007-02-01 00:00:00</td>\n      <td>Maybe you should use better software for the m...</td>\n      <td>Windows Media Maker is easier to use, and prod...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>65363</th>\n      <td>5413</td>\n      <td>1</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5782</td>\n      <td>Rich Dellinger</td>\n      <td>2012-07-28 00:00:00</td>\n      <td>TV is just a tool. It is how you use it that m...</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>65364</th>\n      <td>5413</td>\n      <td>2</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>3747</td>\n      <td>Leonardo Carvalho</td>\n      <td>2012-08-05 00:00:00</td>\n      <td>The concept of TV and media is brilliant, incr...</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>65365</th>\n      <td>5413</td>\n      <td>3</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5783</td>\n      <td>Samuel Hermansson</td>\n      <td>2012-08-06 00:00:00</td>\n      <td>I think that TV has helped us with many things...</td>\n      <td>Yes</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>65366</th>\n      <td>5413</td>\n      <td>4</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5649</td>\n      <td>Hany Mohammed</td>\n      <td>2012-08-16 00:00:00</td>\n      <td>I will use analogy to explain…\\nIf I present a...</td>\n      <td>No</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>65367</th>\n      <td>5413</td>\n      <td>5</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>5688</td>\n      <td>Natasha Lynn Valentine Hudson</td>\n      <td>2012-09-02 00:00:00</td>\n      <td>People spend hours in front of a television. A...</td>\n      <td>Yes</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>65368 rows × 12 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/home/dev/data/stance/convinceme/posts.txt\"\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "# df[\"post_id\"] = df[\"post_id\"].astype(str)\n",
    "# df[\"discussion_id\"] = df[\"discussion_id\"].astype(str)\n",
    "# df[\"author_id\"] = df[\"author_id\"].astype(str)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "      discussion_id                                     discussion_url  \\\n0                 1  http://www.convinceme.net/debates/1/Windows-Me...   \n1                 2  http://www.convinceme.net/debates/2/The-Beatle...   \n2                 3  http://www.convinceme.net/debates/3/Is-Sufjan-...   \n3                 4  http://www.convinceme.net/debates/4/2008-Presi...   \n4                 5  http://www.convinceme.net/debates/5/Ninjas-ver...   \n...             ...                                                ...   \n5408           5409  http://www.convinceme.net/debates/2069181831/I...   \n5409           5410  http://www.convinceme.net/debates/2090410726/J...   \n5410           5411  http://www.convinceme.net/debates/2095956490/s...   \n5411           5412  http://www.convinceme.net/debates/2103454116/S...   \n5412           5413  http://www.convinceme.net/debates/2112398537/T...   \n\n                                                  title topic  \n0                Windows Media Maker 2.0 vs. Mac iMovie   NaN  \n1                    The Beatles vs. The Rolling Stones   NaN  \n2                                Is Sufjan Stevens Gay?   NaN  \n3     2008 Presidential Elections: Rudy Giuliani vs....   NaN  \n4                                 Ninjas versus Pirates   NaN  \n...                                                 ...   ...  \n5408  Is is right that Marlins manager Ozzie Guillen...   NaN  \n5409                           JESUS CHRIST VS MUHAMMAD   NaN  \n5410  should people get victimised for putting a sta...   NaN  \n5411  Should (Norwegian) schools have mandatory trip...   NaN  \n5412                                   TV: Good or bad?   NaN  \n\n[5413 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discussion_id</th>\n      <th>discussion_url</th>\n      <th>title</th>\n      <th>topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>http://www.convinceme.net/debates/1/Windows-Me...</td>\n      <td>Windows Media Maker 2.0 vs. Mac iMovie</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>http://www.convinceme.net/debates/2/The-Beatle...</td>\n      <td>The Beatles vs. The Rolling Stones</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>http://www.convinceme.net/debates/3/Is-Sufjan-...</td>\n      <td>Is Sufjan Stevens Gay?</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>http://www.convinceme.net/debates/4/2008-Presi...</td>\n      <td>2008 Presidential Elections: Rudy Giuliani vs....</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>http://www.convinceme.net/debates/5/Ninjas-ver...</td>\n      <td>Ninjas versus Pirates</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>5408</th>\n      <td>5409</td>\n      <td>http://www.convinceme.net/debates/2069181831/I...</td>\n      <td>Is is right that Marlins manager Ozzie Guillen...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5409</th>\n      <td>5410</td>\n      <td>http://www.convinceme.net/debates/2090410726/J...</td>\n      <td>JESUS CHRIST VS MUHAMMAD</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5410</th>\n      <td>5411</td>\n      <td>http://www.convinceme.net/debates/2095956490/s...</td>\n      <td>should people get victimised for putting a sta...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5411</th>\n      <td>5412</td>\n      <td>http://www.convinceme.net/debates/2103454116/S...</td>\n      <td>Should (Norwegian) schools have mandatory trip...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>5412</th>\n      <td>5413</td>\n      <td>http://www.convinceme.net/debates/2112398537/T...</td>\n      <td>TV: Good or bad?</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5413 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discussion_path = \"/home/dev/data/stance/convinceme/discussions.csv\"\n",
    "discussions_df = pd.read_csv(discussion_path)\n",
    "discussions_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({nan: 5226,\n         'gay marriage': 18,\n         'climate change': 11,\n         'evolution': 17,\n         'communism vs capitalism': 8,\n         'marijuana legalization': 18,\n         'gun control': 20,\n         'abortion': 28,\n         'Israel/Palestine': 2,\n         'existence of God': 18,\n         'immigration': 6,\n         'death penalty': 27,\n         'legalized prostitution': 5,\n         'vegetarianism': 3,\n         'women in the military': 1,\n         'minimum wage: pro or con': 1,\n         'obamacare': 4})"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(discussions_df[\"topic\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Counter({nan: 58752,\n         'gay marriage': 971,\n         'climate change': 368,\n         'evolution': 882,\n         'communism vs capitalism': 231,\n         'marijuana legalization': 455,\n         'gun control': 391,\n         'abortion': 1077,\n         'Israel/Palestine': 67,\n         'existence of God': 998,\n         'immigration': 195,\n         'death penalty': 600,\n         'legalized prostitution': 145,\n         'vegetarianism': 58,\n         'women in the military': 34,\n         'minimum wage: pro or con': 17,\n         'obamacare': 127})"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "Counter(df[\"topic\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "187"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_to_dict(path: str) -> dict:\n",
    "    with open(path, 'r') as f:\n",
    "        return dict(tuple(l.strip().split('\\t',1)) for l in f)\n",
    "\n",
    "\n",
    "topic_path = \"/home/dev/data/stance/IAC/alternative/convinceme/topic.txt\"\n",
    "topics_map = load_to_dict(topic_path)\n",
    "# topics_map[\"unknown\"] = \"unknown\"\n",
    "# topics_map[\"other\"] = \"other\"\n",
    "\n",
    "discussion_topic_path = \"/home/dev/data/stance/IAC/alternative/convinceme/discussion_topic.txt\"\n",
    "discussion_topic_map = {int(k): topics_map[v] for k, v in load_to_dict(discussion_topic_path).items()}\n",
    "len(discussion_topic_map)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "array([None, 'gay marriage', 'climate change', 'evolution',\n       'communism vs capitalism', 'marijuana legalization', 'gun control',\n       'abortion', 'Israel/Palestine', 'existence of God', 'immigration',\n       'death penalty', 'legalized prostitution', 'vegetarianism',\n       'women in the military', 'minimum wage: pro or con', 'obamacare'],\n      dtype=object)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"topic\"] = df[\"discussion_id\"].apply(lambda cid: discussion_topic_map.get(cid, None))\n",
    "df[\"topic\"].unique()\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0           1.0\n1           1.0\n2           1.0\n3             2\n4             6\n          ...  \n65363    5413.0\n65364    5413.0\n65365    5413.0\n65366    5413.0\n65367    5413.0\nName: parent_post_id, Length: 65368, dtype: object"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"parent_post_id\"] = df.apply(\n",
    "    lambda row: (str(row[\"discussion_id\"]) + \".0\") if pd.isna(row[\"parent_post_id\"]) else row[\"parent_post_id\"],\n",
    "    axis=1\n",
    ")\n",
    "df[\"parent_post_id\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### add the first post to the dataframe\n",
    "add the record that started the discussion as posts in the discussion, so the conversation parser would add them as records.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "new_records = []\n",
    "for discussion_id in df[\"discussion_id\"].unique():\n",
    "    record = {\n",
    "        \"topic\": discussion_topic_map.get(discussion_id, None),\n",
    "        \"discussion_id\": discussion_id,\n",
    "        \"post_id\": str(discussion_id) + \".0\",\n",
    "        \"author_id\": \"!UNK\",\n",
    "        \"creation_date\": \"00:00\",\n",
    "        \"parent_post_id\": None,\n",
    "        \"parent_missing\": 0,\n",
    "        \"text_id\": -1,\n",
    "        \"points\": 0,\n",
    "        \"discussion_stance_id\": 0.5,\n",
    "        \"is_rebuttal\": None\n",
    "    }\n",
    "    new_records.append(record)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "       discussion_id post_id author_id        creation_date parent_post_id  \\\n0                  1       1        10  2007-01-02 00:00:00            1.0   \n1                  1       2        12  2007-01-04 00:00:00            1.0   \n2                  1       3         1  2007-02-01 00:00:00            1.0   \n3                  1       4         1  2007-02-01 00:00:00              2   \n4                  1       5         1  2007-02-01 00:00:00              6   \n...              ...     ...       ...                  ...            ...   \n70776           5409  5409.0      !UNK                00:00           None   \n70777           5410  5410.0      !UNK                00:00           None   \n70778           5411  5411.0      !UNK                00:00           None   \n70779           5412  5412.0      !UNK                00:00           None   \n70780           5413  5413.0      !UNK                00:00           None   \n\n       parent_missing  text_id  points  discussion_stance_id is_rebuttal topic  \n0                   0        1      58                   1.0           1  None  \n1                   0        2      59                   1.0           1  None  \n2                   0        3       1                   0.0           1  None  \n3                   0        4       0                   0.0           1  None  \n4                   0        5       0                   0.0           1  None  \n...               ...      ...     ...                   ...         ...   ...  \n70776               0       -1       0                   0.5        None  None  \n70777               0       -1       0                   0.5        None  None  \n70778               0       -1       0                   0.5        None  None  \n70779               0       -1       0                   0.5        None  None  \n70780               0       -1       0                   0.5        None  None  \n\n[70781 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discussion_id</th>\n      <th>post_id</th>\n      <th>author_id</th>\n      <th>creation_date</th>\n      <th>parent_post_id</th>\n      <th>parent_missing</th>\n      <th>text_id</th>\n      <th>points</th>\n      <th>discussion_stance_id</th>\n      <th>is_rebuttal</th>\n      <th>topic</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>10</td>\n      <td>2007-01-02 00:00:00</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>58</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>12</td>\n      <td>2007-01-04 00:00:00</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>59</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2007-02-01 00:00:00</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>2007-02-01 00:00:00</td>\n      <td>2</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>2007-02-01 00:00:00</td>\n      <td>6</td>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>70776</th>\n      <td>5409</td>\n      <td>5409.0</td>\n      <td>!UNK</td>\n      <td>00:00</td>\n      <td>None</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>70777</th>\n      <td>5410</td>\n      <td>5410.0</td>\n      <td>!UNK</td>\n      <td>00:00</td>\n      <td>None</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>70778</th>\n      <td>5411</td>\n      <td>5411.0</td>\n      <td>!UNK</td>\n      <td>00:00</td>\n      <td>None</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>70779</th>\n      <td>5412</td>\n      <td>5412.0</td>\n      <td>!UNK</td>\n      <td>00:00</td>\n      <td>None</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>70780</th>\n      <td>5413</td>\n      <td>5413.0</td>\n      <td>!UNK</td>\n      <td>00:00</td>\n      <td>None</td>\n      <td>0</td>\n      <td>-1</td>\n      <td>0</td>\n      <td>0.5</td>\n      <td>None</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>70781 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.append(new_records, ignore_index=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f0cd80692ed146d08ddeb4cb63a449e3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "5413"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pasre_strategy = {\n",
    "    \"node_id\": \"post_id\",\n",
    "    \"author\": \"author_id\",\n",
    "    \"timestamp\": \"creation_date\",\n",
    "    \"parent_id\": \"parent_post_id\"\n",
    "    }\n",
    "parser = DataFrameConversationReader(pasre_strategy)\n",
    "gb = df.groupby(\"discussion_id\")\n",
    "convs: List[Conversation] = list(tqdm(map(parser.parse, map(itemgetter(1), gb))))\n",
    "len(convs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# pasre_strategy = {\n",
    "#     \"node_id\": \"post_id\",\n",
    "#     \"author\": \"author_id\",\n",
    "#     \"timestamp\": \"creation_date\",\n",
    "#     \"parent_id\": \"parent_post_id\"\n",
    "#     }\n",
    "#\n",
    "# def build_conversations(data: pd.DataFrame) -> Iterable[Conversation]:\n",
    "#     parser = ConvinceMeConversationParser()\n",
    "#     for discussion_id, posts in data.groupby(\"discussion_id\"):\n",
    "#         conversation = parser.parse((discussion_id, posts))\n",
    "#         yield conversation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# convs = list(tqdm(build_conversations(df)))\n",
    "# len(convs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "32220"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_convs = [Conversation(child, conversation_id=str(conv.id) + str(child.node_id)) for conv in convs for child in conv.root.children]\n",
    "len(sub_convs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### create post labels dictionary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "65368"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_labels = {(conv.id, node.node_id): node.data[\"discussion_stance_id\"] for conv in sub_convs for _,node in conv.iter_conversation() if node.data[\"discussion_stance_id\"] != 0.5}\n",
    "len(post_labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32220\n",
      "49930\n"
     ]
    }
   ],
   "source": [
    "def get_majority_vote(labels: List[int]) -> int:\n",
    "    return int(np.mean(labels) >= 0.5)\n",
    "\n",
    "def create_author_labels(c: Conversation) -> Dict[Any, int]:\n",
    "    authors_post_labels = {}\n",
    "    conv_id = c.id\n",
    "    for depth, node in c.iter_conversation():\n",
    "        author = node.author\n",
    "        post_label = post_labels.get((conv_id, node.node_id), None)\n",
    "        if post_label is None: continue\n",
    "        current_author_labels = authors_post_labels.setdefault(author, [])\n",
    "        current_author_labels.append(post_label)\n",
    "\n",
    "    result_labels = {a: get_majority_vote(labels) for a, labels in authors_post_labels.items()}\n",
    "    return result_labels\n",
    "\n",
    "author_labels_per_conversation = {c.id: create_author_labels(c) for c in sub_convs}\n",
    "author_labels_per_conversation = {k: v for k, v in author_labels_per_conversation.items() if len(v) > 0 and not (len(v) == 1 and None in v)}\n",
    "print(len(author_labels_per_conversation))\n",
    "print(sum(len(v) for v in author_labels_per_conversation.values()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def get_ordered_candidates_for_pivot(graph: nx.Graph, weight_field: str = \"weight\") -> Sequence[Any]:\n",
    "    inv_weight_field = \"inv_weight\"\n",
    "    for _, _, pair_data in graph.edges(data=True):\n",
    "        weight = pair_data.data[weight_field]\n",
    "        pair_data.data[inv_weight_field] = 1 / weight\n",
    "\n",
    "    node_centralities = nx.closeness_centrality(graph, distance=inv_weight_field)\n",
    "    return list(map(itemgetter(0), sorted(node_centralities.items(), key=itemgetter(1), reverse=True)))\n",
    "\n",
    "def get_pivot_node(graph: nx.Graph, labeled_authors: Set[Any], weight_field: str = \"weight\") -> Any:\n",
    "    candidates = get_ordered_candidates_for_pivot(graph, weight_field=weight_field)\n",
    "    return next(iter(filter(labeled_authors.__contains__, candidates)), None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def extend_preds(graph: nx.Graph, seed_node: Any, core_authors_preds: Dict[Any, int]) -> Dict[Any, int]:\n",
    "    extended_results = dict(core_authors_preds.items())\n",
    "    for (n1, n2) in nx.bfs_edges(graph, source=seed_node):\n",
    "        if n2 not in extended_results:\n",
    "            n1_label = extended_results[n1]\n",
    "            extended_results[n2] = 1 - n1_label\n",
    "\n",
    "    return extended_results\n",
    "\n",
    "def get_authors_labels_in_conv(conv: Conversation) -> Dict[Any, int]:\n",
    "    if conv.id not in author_labels_per_conversation:\n",
    "        return None\n",
    "\n",
    "    return author_labels_per_conversation[conv.id]\n",
    "\n",
    "def get_author_preds(clf: BaseStanceClassifier, pivot: Any) -> Dict[Any, int]:\n",
    "    support_label = authors_labels[pivot]\n",
    "    opposer_label = 1 - support_label\n",
    "    supporters = clf.get_supporters()\n",
    "    opposers = clf.get_complement()\n",
    "    preds = {}\n",
    "    for supporter in supporters:\n",
    "        preds[supporter] = support_label\n",
    "    for opposer in opposers:\n",
    "        preds[opposer] = opposer_label\n",
    "\n",
    "    return preds\n",
    "\n",
    "def get_maxcut_results(graph: InteractionsGraph, op: Any) -> MaxcutStanceClassifier:\n",
    "    maxcut = MaxcutStanceClassifier(weight_field=graph.WEIGHT_FIELD)\n",
    "    maxcut.set_input(graph.graph, op)\n",
    "    maxcut.classify_stance()\n",
    "    return maxcut\n",
    "\n",
    "def get_greedy_results(graph: InteractionsGraph, op: Any) -> BaseStanceClassifier:\n",
    "    clf = MSTStanceClassifier()#weight_field=graph.WEIGHT_FIELD)\n",
    "    clf.set_input(graph.graph)\n",
    "    clf.classify_stance(op)\n",
    "    return clf\n",
    "\n",
    "def align_gs_with_predictions(authors_labels: Dict[Any, int], author_preds: Dict[Any, int]) -> Tuple[List[int], List[int]]:\n",
    "    y_true, y_pred = [], []\n",
    "    for author, true_label in authors_labels.items():\n",
    "        pred = author_preds.get(author, None)\n",
    "        if pred is None: continue\n",
    "\n",
    "        y_true.append(true_label)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "def predict_for_partition(true: List[int], preds: List[int]) -> Tuple[List[int], List[int]]:\n",
    "    acc = accuracy_score(true, preds)\n",
    "    if acc < 0.5:\n",
    "        preds = [1-l for l in preds]\n",
    "\n",
    "    return true, preds\n",
    "\n",
    "def get_best_preds(true_labels: Dict[Any, int], pred_labels: Dict[Any, int]) -> Dict[Any, int]:\n",
    "    true, preds = align_gs_with_predictions(true_labels, pred_labels)\n",
    "    acc = accuracy_score(true, preds)\n",
    "    if acc < 0.5:\n",
    "        return {k: (1-  l) for k, l in pred_labels.items()}\n",
    "\n",
    "    return pred_labels\n",
    "\n",
    "def get_posts_preds(conv: Conversation, post_labels: Dict[Any, int], author_preds: Dict[Any, int]) -> Tuple[Dict[Any, int], Dict[Any, int]]:\n",
    "    posts_true, posts_pred = {}, {}\n",
    "    conv_id = conv.id\n",
    "    for depth, node in conv.iter_conversation():\n",
    "        label = post_labels.get((conv_id, node.node_id), None)\n",
    "        if label is None: continue\n",
    "        pred = author_preds.get(node.author, None)\n",
    "        if pred is None: continue\n",
    "\n",
    "        posts_true[node.node_id] = label\n",
    "        posts_pred[node.node_id] = pred\n",
    "\n",
    "    return posts_true, posts_pred\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "700b8fc502bb482da702012882c48138"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "interactions_parser = get_reply_interactions_parser()\n",
    "\n",
    "convs_by_id: Dict[Any, Conversation] = {}\n",
    "full_graphs: Dict[Any, InteractionsGraph] = {}\n",
    "core_graphs: Dict[Any, InteractionsGraph] = {}\n",
    "maxcut_results: Dict[Any, MaxcutStanceClassifier] = {}\n",
    "pivot_nodes = {}\n",
    "\n",
    "author_predictions: Dict[Any, Dict[str, Dict[Any, int]]] = {}\n",
    "posts_predictions: Dict[Any, Dict[str, Dict[Any, int]]] = {}\n",
    "\n",
    "\n",
    "\n",
    "empty_core = []\n",
    "unlabeled_conversations = []\n",
    "unlabeled_op = []\n",
    "insufficient_author_labels = []\n",
    "too_small_cut_value = []\n",
    "op_not_in_core = []\n",
    "large_graphs = []\n",
    "single_author_conv = []\n",
    "\n",
    "extend_results = False\n",
    "naive_results = False\n",
    "\n",
    "def calc_weight(interactions: PairInteractionsData) -> float:\n",
    "    n_replies = interactions[\"replies\"]\n",
    "    # n_quotes = interactions[\"quotes\"]\n",
    "    return n_replies\n",
    "    # return n_quotes\n",
    "\n",
    "\"\"\"abortion = 3\n",
    "   evolution = 7\n",
    "   gay marriage = 8\n",
    "   gun control = 9\n",
    "   \"\"\"\n",
    "# convs[0].root.data[\"topic\"]\n",
    "# conv: Conversation\n",
    "count_conv = 0\n",
    "for i, conv in tqdm(enumerate(sub_convs)):\n",
    "    # topic = conv.root.data[\"topic\"]\n",
    "    # if topic not in relevant_topics: continue\n",
    "\n",
    "    count_conv += 1\n",
    "    authors_labels = get_authors_labels_in_conv(conv)\n",
    "    if authors_labels is None:\n",
    "        unlabeled_conversations.append(i)\n",
    "        continue\n",
    "\n",
    "    if len(authors_labels) == 0:\n",
    "        insufficient_author_labels.append(i)\n",
    "        continue\n",
    "\n",
    "    interaction_graph = interactions_parser.parse(conv)\n",
    "    interaction_graph.set_interaction_weights(calc_weight)\n",
    "    zero_edges = [(v, u) for v, u, d in interaction_graph.graph.edges(data=True) if d[\"weight\"] == 0]\n",
    "    interaction_graph.graph.remove_edges_from(zero_edges)\n",
    "\n",
    "    if len(conv.participants) <= 1:\n",
    "        single_author_conv.append(i)\n",
    "        continue\n",
    "\n",
    "    convs_by_id[conv.id] = conv\n",
    "    full_graphs[conv.id] = interaction_graph\n",
    "\n",
    "    pivot_node = get_pivot_node(interaction_graph.graph, authors_labels, weight_field=\"weight\")\n",
    "    pivot_nodes[conv.id] = pivot_node\n",
    "\n",
    "    mst = get_greedy_results(interaction_graph, pivot_node)\n",
    "    preds = get_author_preds(mst, pivot_node)\n",
    "    author_predictions[conv.id] = {\"mst\": preds}\n",
    "\n",
    "    if naive_results:\n",
    "        continue\n",
    "\n",
    "    core_interactions = interaction_graph.get_core_interactions()\n",
    "    core_graphs[conv.id] = core_interactions\n",
    "    if core_interactions.graph.size() == 0:\n",
    "        empty_core.append(i)\n",
    "        continue\n",
    "\n",
    "    components = list(nx.connected_components(core_interactions.graph))\n",
    "    core_interactions = core_interactions.get_subgraph(components[0])\n",
    "    pivot_node = get_pivot_node(core_interactions.graph, authors_labels, weight_field=\"weight\")\n",
    "    maxcut = get_maxcut_results(core_interactions, pivot_node)\n",
    "    if maxcut.cut_value < 3:\n",
    "        too_small_cut_value.append(i)\n",
    "        continue\n",
    "\n",
    "    maxcut_results[conv.id] = maxcut\n",
    "\n",
    "    # if core_interactions.graph.order() > 120:\n",
    "    #     large_graphs.append(conv)\n",
    "    #     continue\n",
    "\n",
    "    preds = get_author_preds(maxcut, pivot_node)\n",
    "    author_predictions[conv.id][\"core\"] = preds\n",
    "\n",
    "    # get extended results\n",
    "    preds = extend_preds(interaction_graph.graph, pivot_node, preds)\n",
    "    author_predictions[conv.id][\"full\"] = preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of conversations (in all topics): 5413\n",
      "total number of conversations (in the relevant topics): 32220\n",
      "total number of conversations with labeled authors (in all topics): 32220\n",
      "total number of conversations with labeled authors (in the relevant topics): 32220\n",
      "number of conversations in eval: 9521\n",
      "number of unique authors in eval: 3641\n",
      "number of unique authors in core: 490\n",
      "total number of labeled authors: 49930\n",
      "=========\n",
      "number of conversations with single author: 22699\n",
      "number of conversations with empty core: 8970\n",
      "number of conversations with op not in core: 0\n",
      "number of conversations with too large core: 0\n",
      "number of conversations with too small cut value: 51\n",
      "number of unlabeled conversations: 0\n",
      "number of conversations with unlabeled op: 0\n",
      "number of conversations with insufficient labeled authors: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"total number of conversations (in all topics): {len(convs)}\")\n",
    "print(f\"total number of conversations (in the relevant topics): {count_conv}\")\n",
    "print(f\"total number of conversations with labeled authors (in all topics): {len(author_labels_per_conversation)}\")\n",
    "print(f\"total number of conversations with labeled authors (in the relevant topics): {count_conv - len(unlabeled_conversations)}\")\n",
    "\n",
    "print(f\"number of conversations in eval: {len(convs_by_id)}\")\n",
    "all_authors_in_eval = set(chain(*[predictions[\"mst\"].keys() for predictions in author_predictions.values()]))\n",
    "print(f\"number of unique authors in eval: {len(all_authors_in_eval)}\")\n",
    "all_authors_in_core_eval = set(chain(*[predictions.get(\"core\", {}).keys() for predictions in author_predictions.values()]))\n",
    "print(f\"number of unique authors in core: {len(all_authors_in_core_eval)}\")\n",
    "\n",
    "labeled_authors = sum(len(v) for v in author_labels_per_conversation.values())\n",
    "print(f\"total number of labeled authors: {labeled_authors}\")\n",
    "print(\"=========\")\n",
    "print(f\"number of conversations with single author: {len(single_author_conv)}\")\n",
    "print(f\"number of conversations with empty core: {len(empty_core)}\")\n",
    "print(f\"number of conversations with op not in core: {len(op_not_in_core)}\")\n",
    "print(f\"number of conversations with too large core: {len(large_graphs)}\")\n",
    "print(f\"number of conversations with too small cut value: {len(too_small_cut_value)}\")\n",
    "print(f\"number of unlabeled conversations: {len(unlabeled_conversations)}\")\n",
    "print(f\"number of conversations with unlabeled op: {len(unlabeled_op)}\")\n",
    "print(f\"number of conversations with insufficient labeled authors: {len(insufficient_author_labels)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "data": {
      "text/plain": "17"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, precision_score\n",
    "relevant_topics = set(discussion_topic_map.values())\n",
    "results = {}\n",
    "others = {}\n",
    "for conv_id, prediction in author_predictions.items():\n",
    "    conv = convs_by_id[conv_id]\n",
    "    topic = conv.root.data[\"topic\"]\n",
    "    if  topic not in relevant_topics:\n",
    "        topic = \"other\"\n",
    "\n",
    "    author_labels = get_authors_labels_in_conv(conv)\n",
    "    author_preds = prediction.get(\"full\", prediction[\"mst\"])\n",
    "    best_preds = get_best_preds(author_labels, author_preds)\n",
    "    y_true, y_pred = align_gs_with_predictions(author_labels, best_preds)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    posts_true, posts_preds = get_posts_preds(conv, post_labels, author_preds)\n",
    "    best_preds = get_best_preds(posts_true, posts_preds)\n",
    "    p_true, p_pred = align_gs_with_predictions(posts_true, best_preds)\n",
    "    p_acc = accuracy_score(p_true, p_pred)\n",
    "\n",
    "    accuracies, p_accuracies, sizes, psizes = results.setdefault(topic, ([], [], [], []))\n",
    "    accuracies.append(acc)\n",
    "    p_accuracies.append(p_acc)\n",
    "    sizes.append(len(y_true))\n",
    "    psizes.append(len(p_true))\n",
    "    # print(f\"{topic} {len(sizes)}\\t{sum(sizes)}\\t{macro_acc}\\t{micro_acc}\")\n",
    "len(results)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Other & 37537 & 0.95 & - \\\\\n",
      " Gay Marriage & 708 & 0.98 & - \\\\\n",
      " Evolution & 688 & 0.99 & - \\\\\n",
      " Communism Vs Capitalism & 185 & 0.99 & - \\\\\n",
      " Marijuana Legalization & 261 & 0.98 & - \\\\\n",
      " Gun Control & 314 & 0.95 & - \\\\\n",
      " Abortion & 834 & 0.96 & - \\\\\n",
      " Climate Change & 255 & 1.00 & - \\\\\n",
      " Israel/Palestine & 36 & 1.00 & - \\\\\n",
      " Existence Of God & 842 & 0.98 & - \\\\\n",
      " Immigration & 166 & 0.87 & - \\\\\n",
      " Death Penalty & 474 & 0.98 & - \\\\\n",
      " Legalized Prostitution & 108 & 0.88 & - \\\\\n",
      " Vegetarianism & 43 & 1.00 & - \\\\\n",
      " Women In The Military & 22 & 1.00 & - \\\\\n",
      " Minimum Wage: Pro Or Con & 14 & 0.95 & - \\\\\n",
      " Obamacare & 101 & 0.98 & - \\\\\n"
     ]
    }
   ],
   "source": [
    "for topic, (accuracies, p_accuracies, sizes, psizes) in results.items():\n",
    "    macro_acc = np.mean(accuracies)\n",
    "    p_acc = np.mean(p_accuracies)\n",
    "    micro_acc = np.dot(accuracies, sizes) / sum(sizes)\n",
    "    micro_p_acc = np.dot(p_accuracies, psizes) / sum(sizes)\n",
    "    print(f\" {topic.title()} & {sum(psizes)} & {p_acc:.2f} & - \\\\\\\\\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evalute Results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_authors_in_eval = set(chain(*[predictions[\"mst\"].keys() for predictions in author_predictions.values()]))\n",
    "print(len(all_authors_in_eval))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "all_authors_in_core_eval = set(chain(*[predictions.get(\"core\", {}).keys() for predictions in author_predictions.values()]))\n",
    "len(all_authors_in_core_eval)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sum(1 for p in author_predictions.values() if \"core\" in p)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for predictor in [\"core\", \"full\", \"mst\"]:\n",
    "    all_true, all_pred = [], []\n",
    "    all_true_best, all_pred_best = [], []\n",
    "\n",
    "    for conv_id, predictions in author_predictions.items():\n",
    "        conv = convs_by_id[conv_id]\n",
    "        author_labels = get_authors_labels_in_conv(conv)\n",
    "        author_preds = predictions.get(predictor, None)\n",
    "        if author_preds is None: continue\n",
    "\n",
    "        y_true, y_pred = align_gs_with_predictions(author_labels, author_preds)\n",
    "        all_true.extend(y_true)\n",
    "        all_pred.extend(y_pred)\n",
    "\n",
    "        best_preds = get_best_preds(author_labels, author_preds)\n",
    "        y_true, y_pred = align_gs_with_predictions(author_labels, best_preds)\n",
    "        all_true_best.extend(y_true)\n",
    "        all_pred_best.extend(y_pred)\n",
    "\n",
    "    acc = accuracy_score(all_true, all_pred)\n",
    "    acc_best = accuracy_score(all_true_best, all_pred_best)\n",
    "    print(f\"accuracy: {acc}\")\n",
    "    print(f\"accuracy-best: {acc_best}\")\n",
    "    print(f\"Showing results of predictor: {predictor}\")\n",
    "    print(classification_report(all_true, all_pred))\n",
    "    print(f\"\\n\\t\\tResults for best partition (regardless for stance assignment\")\n",
    "    print(classification_report(all_true_best, all_pred_best))\n",
    "    print(\"-----------------------------------------------------------------------------\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for predictor in [\"core\", \"full\", \"mst\"]:\n",
    "    all_true, all_pred = [], []\n",
    "    all_true_best, all_pred_best = [], []\n",
    "\n",
    "    for conv_id, predictions in author_predictions.items():\n",
    "        conv = convs_by_id[conv_id]\n",
    "        author_labels = get_authors_labels_in_conv(conv)\n",
    "        author_preds = predictions.get(predictor, None)\n",
    "        if author_preds is None: continue\n",
    "\n",
    "        posts_true, posts_preds = get_posts_preds(conv, post_labels, author_preds)\n",
    "\n",
    "        y_true, y_pred = align_gs_with_predictions(posts_true, posts_preds)\n",
    "        all_true.extend(y_true)\n",
    "        all_pred.extend(y_pred)\n",
    "\n",
    "        best_preds = get_best_preds(posts_true, posts_preds)\n",
    "        y_true, y_pred = align_gs_with_predictions(posts_true, best_preds)\n",
    "        all_true_best.extend(y_true)\n",
    "        all_pred_best.extend(y_pred)\n",
    "\n",
    "    print(f\"Showing results of predictor: {predictor}\")\n",
    "    print(classification_report(all_true, all_pred))\n",
    "    print(f\"\\n\\tResults for best partition (regardless for stance assignment\")\n",
    "    print(classification_report(all_true_best, all_pred_best))\n",
    "    print(\"-----------------------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "accs = [82,80,64,70,35,82,75,76,84,37,73,33,88,85,19,73,63,50]\n",
    "print(len(accs))\n",
    "np.mean(accs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "interaction_graph = reply_interactions_parser.parse(convs[4])\n",
    "layout = nx.spring_layout(interaction_graph.graph)\n",
    "nx.draw(interaction_graph.graph, layout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_graphs():\n",
    "    for j, conv in enumerate(large_convs):\n",
    "        interaction_graph = reply_interactions_parser.parse(conv)\n",
    "        if interaction_graph.graph.order() > 10:\n",
    "            kcore = interaction_graph.get_core_interactions()\n",
    "            if kcore.graph.order() > 5:\n",
    "                print(j)\n",
    "                yield(interaction_graph)\n",
    "\n",
    "graphs = get_graphs()\n",
    "\n",
    "i = next(graphs)\n",
    "layout = nx.spring_layout(i.graph)\n",
    "nx.draw(i.graph, layout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = next(graphs)\n",
    "layout = nx.spring_layout(i.graph)\n",
    "nx.draw(i.graph, layout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = next(graphs)\n",
    "layout = nx.spring_layout(i.graph)\n",
    "nx.draw(i.graph, layout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "i = next(graphs)\n",
    "layout = nx.spring_layout(i.graph)\n",
    "nx.draw(i.graph, layout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(large_convs[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "supporters_avg_angles = []\n",
    "opposers_avg_angles = []\n",
    "mean_cross_angle = []\n",
    "\n",
    "for i in range(len(results)):\n",
    "    r = results[i]\n",
    "    supporters_distances = list(starmap(lambda i, j: cosine(r[0][i], r[0][j]), combinations(r[1], 2)))\n",
    "    opposers_distances = list(starmap(lambda i, j: cosine(r[0][i], r[0][j]), combinations(r[2], 2)))\n",
    "    supporters_avg_angle = np.mean(supporters_distances)\n",
    "    opposers_avg_angle = np.mean(opposers_distances)\n",
    "\n",
    "    supporters_avg_angles.append(supporters_avg_angle)\n",
    "    opposers_avg_angles.append(opposers_avg_angle)\n",
    "\n",
    "    supporters_mean_embedding = np.mean([np.array(r[0][i]) for i in r[1]], axis=0)[0]\n",
    "    opposers_mean_embedding = np.mean([np.array(r[0][i]) for i in r[2]], axis=0)[0]\n",
    "    cross_angle = cosine(supporters_mean_embedding, opposers_mean_embedding)\n",
    "    mean_cross_angle.append(cross_angle)\n",
    "\n",
    "print(f\"support {len(results)}\")\n",
    "print(f\"support cosine {len(results)}\")\n",
    "print(f\"support {len(results)}\")\n",
    "print(f\"support {len(results)}\")\n",
    "len(results), np.nanmean(supporters_avg_angles), np.nanmean(opposers_avg_angles), np.mean(mean_cross_angle)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_i = 0\n",
    "max_shape = 0\n",
    "sizes = [(i, len(r[0])) for i, r in enumerate(results)]\n",
    "sorted_sized = sorted(sizes, key=itemgetter(1), reverse=True)\n",
    "sorted_sized[:20]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "r = results[0]\n",
    "X = np.vstack([np.array(x) for x in r[0].values()])\n",
    "X_pca = PCA(n_components=2).fit_transform(X)\n",
    "X_tsne = TSNE(n_components=2).fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nodes = r[0].keys()\n",
    "colors = ['r' if i in r[1] else 'g' for i in nodes]\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], color=colors)\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plt.scatter(X_pca[:, 0], X_pca[:, 1], color=colors)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.is_rebuttal.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}