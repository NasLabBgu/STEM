{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from typing import List, Any, Dict, Tuple, Set, Iterable, Sequence\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, starmap, groupby, product, chain, islice, takewhile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from conversant.conversation import Conversation\n",
    "from conversant.conversation.parse import DataFrameConversationReader\n",
    "from conversant.interactions import InteractionsGraph\n",
    "from conversant.interactions.interactions_graph import PairInteractionsData\n",
    "from conversant.interactions.reply_interactions_parser import get_reply_interactions_parser\n",
    "from stance_classification.classifiers.base_stance_classifier import BaseStanceClassifier\n",
    "from stance_classification.classifiers.greedy_stance_classifier import MSTStanceClassifier\n",
    "from stance_classification.draw_utils import new_figure\n",
    "%matplotlib inline\n",
    "\n",
    "from stance_classification.classifiers.maxcut_stance_classifier import MaxcutStanceClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_authors_map(authors_root_path: str) -> Dict[str, str]:\n",
    "    post_authors_map = {}\n",
    "    for topic_name in os.listdir(authors_root_path):\n",
    "        topic_dirpath = os.path.join(authors_root_path, topic_name)\n",
    "        for discussion_file in os.listdir(topic_dirpath):\n",
    "            discussion_path = os.path.join(topic_dirpath, discussion_file)\n",
    "            with open(discussion_path, 'r') as f:\n",
    "                post_author_pairs = list(map(lambda l: tuple(map(str.strip, l.strip().split(' ', 1))), f))\n",
    "                try:\n",
    "                    post_full_id_author_pairs = [(f\"{topic_name}.{post_id}\", author) for post_id, author in post_author_pairs]\n",
    "                    post_authors_map.update(post_full_id_author_pairs)\n",
    "                except:\n",
    "                    print([e for e in post_author_pairs if len(e) != 2])\n",
    "                    raise\n",
    "\n",
    "    return post_authors_map"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "4728"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_author_path = \"/home/dev/data/stance/create-debate/reason/stance/authors\"\n",
    "authors_map = load_authors_map(posts_author_path)\n",
    "len(authors_map)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_author(topic: str, post_id: str) -> str:\n",
    "    return authors_map.get(post_id, None)\n",
    "\n",
    "def get_record_from_post(topic_dir: str, meta_file: str) -> Dict[str, Any]:\n",
    "    topic = topic_dir.split(\"/\")[-1]\n",
    "    discussion_id = topic + \".\" + \"\".join(takewhile(str.isalpha, meta_file))\n",
    "    meta_filepath = os.path.join(topic_dir, meta_file)\n",
    "    text_filepath = os.path.join(topic_dir, meta_filepath.split(\".\")[0] + \".data\")\n",
    "    with open(text_filepath, 'r') as text_f:\n",
    "        text = text_f.read().strip()\n",
    "\n",
    "    \"\"\" example to meta file content:\n",
    "        ID=24\n",
    "        PID=23\n",
    "        Stance=-1\n",
    "        rebuttal=oppose\n",
    "    \"\"\"\n",
    "    record = {}\n",
    "    with open(meta_filepath, 'r') as meta_f:\n",
    "        post_id = discussion_id + next(meta_f).strip().split(\"=\")[1]\n",
    "        parent_id_str = next(meta_f).strip().split(\"=\")[1]\n",
    "        parent_post_id = (discussion_id + parent_id_str) if parent_id_str != \"-1\" else None\n",
    "        stance_str = next(meta_f).strip().split(\"=\")[1]\n",
    "        stance = int(bool(int(stance_str) + 1)) if len(stance_str) > 0 else None\n",
    "        rebuttal = next(meta_f).strip().split(\"=\")[1]\n",
    "        author_id = get_author(topic, post_id)\n",
    "        if parent_post_id == -1:\n",
    "            parent_post_id = None\n",
    "\n",
    "\n",
    "        record.update(\n",
    "            dict(topic=topic, discussion_id=discussion_id, post_id=post_id, author_id=author_id, creation_date=-1,\n",
    "                      parent_post_id=parent_post_id, text=text, discussion_stance_id=stance, rebuttal=rebuttal)\n",
    "        )\n",
    "    return record"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "4902"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_root_dir = \"/home/dev/data/stance/create-debate/reason/stance\"\n",
    "records = []\n",
    "for topic_dirname in os.listdir(data_root_dir):\n",
    "    if topic_dirname == \"author\": continue\n",
    "    topic_dirpath = os.path.join(data_root_dir, topic_dirname)\n",
    "    if not os.path.isdir(topic_dirpath): continue\n",
    "    for post_file in os.listdir(topic_dirpath):\n",
    "        if post_file.endswith(\".meta\"):\n",
    "            record = get_record_from_post(topic_dirpath, post_file)\n",
    "            records.append(record)\n",
    "\n",
    "len(records)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "         topic discussion_id        post_id   author_id  creation_date  \\\n0     abortion    abortion.A    abortion.A1   jstantall             -1   \n1     abortion    abortion.A   abortion.A10        NVYN             -1   \n2     abortion    abortion.A  abortion.A100    atypican             -1   \n3     abortion    abortion.A  abortion.A101    atypican             -1   \n4     abortion    abortion.A  abortion.A102  SMCdeBater             -1   \n...        ...           ...            ...         ...            ...   \n4897     obama       obama.O       obama.O5   illini527             -1   \n4898     obama       obama.O       obama.O6    1debater             -1   \n4899     obama       obama.O       obama.O7   iamdavidh             -1   \n4900     obama       obama.O       obama.O8  BlackSheep             -1   \n4901     obama       obama.O       obama.O9  chatturgha             -1   \n\n     parent_post_id                                               text  \\\n0              None  There is only one question when it comes to ab...   \n1       abortion.A3  People often try to personalize their pro-life...   \n2      abortion.A97  we're saying that the pregnant person should h...   \n3     abortion.A100  No answer to my retort, just a down vote. That...   \n4     abortion.A101  I'm sooo sick of people like you who feel like...   \n...             ...                                                ...   \n4897           None  It's funny how everyone blames the Republicans...   \n4898           None  \"Yes we can!\" roared the crowd. It was an emot...   \n4899       obama.O6  1. This is plagiarism. Cite your source next t...   \n4900           None  I think Obama has been a great President. I th...   \n4901           None  He would have been able to fulfill his promise...   \n\n      discussion_stance_id rebuttal  \n0                      0.0     null  \n1                      1.0   oppose  \n2                      1.0  support  \n3                      1.0  support  \n4                      0.0   oppose  \n...                    ...      ...  \n4897                   0.0     null  \n4898                   0.0     null  \n4899                   1.0   oppose  \n4900                   1.0     null  \n4901                   1.0     null  \n\n[4902 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic</th>\n      <th>discussion_id</th>\n      <th>post_id</th>\n      <th>author_id</th>\n      <th>creation_date</th>\n      <th>parent_post_id</th>\n      <th>text</th>\n      <th>discussion_stance_id</th>\n      <th>rebuttal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abortion</td>\n      <td>abortion.A</td>\n      <td>abortion.A1</td>\n      <td>jstantall</td>\n      <td>-1</td>\n      <td>None</td>\n      <td>There is only one question when it comes to ab...</td>\n      <td>0.0</td>\n      <td>null</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abortion</td>\n      <td>abortion.A</td>\n      <td>abortion.A10</td>\n      <td>NVYN</td>\n      <td>-1</td>\n      <td>abortion.A3</td>\n      <td>People often try to personalize their pro-life...</td>\n      <td>1.0</td>\n      <td>oppose</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abortion</td>\n      <td>abortion.A</td>\n      <td>abortion.A100</td>\n      <td>atypican</td>\n      <td>-1</td>\n      <td>abortion.A97</td>\n      <td>we're saying that the pregnant person should h...</td>\n      <td>1.0</td>\n      <td>support</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abortion</td>\n      <td>abortion.A</td>\n      <td>abortion.A101</td>\n      <td>atypican</td>\n      <td>-1</td>\n      <td>abortion.A100</td>\n      <td>No answer to my retort, just a down vote. That...</td>\n      <td>1.0</td>\n      <td>support</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abortion</td>\n      <td>abortion.A</td>\n      <td>abortion.A102</td>\n      <td>SMCdeBater</td>\n      <td>-1</td>\n      <td>abortion.A101</td>\n      <td>I'm sooo sick of people like you who feel like...</td>\n      <td>0.0</td>\n      <td>oppose</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4897</th>\n      <td>obama</td>\n      <td>obama.O</td>\n      <td>obama.O5</td>\n      <td>illini527</td>\n      <td>-1</td>\n      <td>None</td>\n      <td>It's funny how everyone blames the Republicans...</td>\n      <td>0.0</td>\n      <td>null</td>\n    </tr>\n    <tr>\n      <th>4898</th>\n      <td>obama</td>\n      <td>obama.O</td>\n      <td>obama.O6</td>\n      <td>1debater</td>\n      <td>-1</td>\n      <td>None</td>\n      <td>\"Yes we can!\" roared the crowd. It was an emot...</td>\n      <td>0.0</td>\n      <td>null</td>\n    </tr>\n    <tr>\n      <th>4899</th>\n      <td>obama</td>\n      <td>obama.O</td>\n      <td>obama.O7</td>\n      <td>iamdavidh</td>\n      <td>-1</td>\n      <td>obama.O6</td>\n      <td>1. This is plagiarism. Cite your source next t...</td>\n      <td>1.0</td>\n      <td>oppose</td>\n    </tr>\n    <tr>\n      <th>4900</th>\n      <td>obama</td>\n      <td>obama.O</td>\n      <td>obama.O8</td>\n      <td>BlackSheep</td>\n      <td>-1</td>\n      <td>None</td>\n      <td>I think Obama has been a great President. I th...</td>\n      <td>1.0</td>\n      <td>null</td>\n    </tr>\n    <tr>\n      <th>4901</th>\n      <td>obama</td>\n      <td>obama.O</td>\n      <td>obama.O9</td>\n      <td>chatturgha</td>\n      <td>-1</td>\n      <td>None</td>\n      <td>He would have been able to fulfill his promise...</td>\n      <td>1.0</td>\n      <td>null</td>\n    </tr>\n  </tbody>\n</table>\n<p>4902 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_records(records)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# unified_data_path = \"/home/dev/data/stance/create-debate/reason/stance/all_records.csv\"\n",
    "# df.to_csv(unified_data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### fill all missing parents as direct replies to the discussion title (with post id as the discussion's"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "0         abortion.A0\n1         abortion.A3\n2        abortion.A97\n3       abortion.A100\n4       abortion.A101\n            ...      \n4897         obama.O0\n4898         obama.O0\n4899         obama.O6\n4900         obama.O0\n4901         obama.O0\nName: parent_post_id, Length: 4902, dtype: object"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"parent_post_id\"] = df.apply(\n",
    "    lambda row: (row[\"discussion_id\"] + \"0\") if row[\"parent_post_id\"] is None else row[\"parent_post_id\"],\n",
    "    axis=1\n",
    ")\n",
    "df[\"parent_post_id\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### add the first post to the dataframe\n",
    "add the record that started the discussion as posts in the discussion, so the conversation parser would add them as records.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "new_records = []\n",
    "for discussion_id in df[\"discussion_id\"].unique():\n",
    "    topic = discussion_id.split(\".\")[0]\n",
    "    record = {\n",
    "        \"topic\": topic,\n",
    "        \"discussion_id\": discussion_id,\n",
    "        \"post_id\": discussion_id + \"0\",\n",
    "        \"author_id\": \"!UNK\",\n",
    "        \"creation_date\": \"00:00\",\n",
    "        \"parent_post_id\": None,\n",
    "        \"text\": \"\",\n",
    "        \"discussion_stance_id\": 0.5,\n",
    "        \"rebuttal\": None\n",
    "    }\n",
    "    new_records.append(record)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "         topic discussion_id        post_id   author_id creation_date  \\\n0     abortion    abortion.A    abortion.A1   jstantall            -1   \n1     abortion    abortion.A   abortion.A10        NVYN            -1   \n2     abortion    abortion.A  abortion.A100    atypican            -1   \n3     abortion    abortion.A  abortion.A101    atypican            -1   \n4     abortion    abortion.A  abortion.A102  SMCdeBater            -1   \n...        ...           ...            ...         ...           ...   \n4963     obama       obama.K       obama.K0        !UNK         00:00   \n4964     obama       obama.L       obama.L0        !UNK         00:00   \n4965     obama       obama.M       obama.M0        !UNK         00:00   \n4966     obama       obama.N       obama.N0        !UNK         00:00   \n4967     obama       obama.O       obama.O0        !UNK         00:00   \n\n     parent_post_id                                               text  \\\n0       abortion.A0  There is only one question when it comes to ab...   \n1       abortion.A3  People often try to personalize their pro-life...   \n2      abortion.A97  we're saying that the pregnant person should h...   \n3     abortion.A100  No answer to my retort, just a down vote. That...   \n4     abortion.A101  I'm sooo sick of people like you who feel like...   \n...             ...                                                ...   \n4963           None                                                      \n4964           None                                                      \n4965           None                                                      \n4966           None                                                      \n4967           None                                                      \n\n      discussion_stance_id rebuttal  \n0                      0.0     null  \n1                      1.0   oppose  \n2                      1.0  support  \n3                      1.0  support  \n4                      0.0   oppose  \n...                    ...      ...  \n4963                   0.5     None  \n4964                   0.5     None  \n4965                   0.5     None  \n4966                   0.5     None  \n4967                   0.5     None  \n\n[4968 rows x 9 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>topic</th>\n      <th>discussion_id</th>\n      <th>post_id</th>\n      <th>author_id</th>\n      <th>creation_date</th>\n      <th>parent_post_id</th>\n      <th>text</th>\n      <th>discussion_stance_id</th>\n      <th>rebuttal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>abortion</td>\n      <td>abortion.A</td>\n      <td>abortion.A1</td>\n      <td>jstantall</td>\n      <td>-1</td>\n      <td>abortion.A0</td>\n      <td>There is only one question when it comes to ab...</td>\n      <td>0.0</td>\n      <td>null</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>abortion</td>\n      <td>abortion.A</td>\n      <td>abortion.A10</td>\n      <td>NVYN</td>\n      <td>-1</td>\n      <td>abortion.A3</td>\n      <td>People often try to personalize their pro-life...</td>\n      <td>1.0</td>\n      <td>oppose</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>abortion</td>\n      <td>abortion.A</td>\n      <td>abortion.A100</td>\n      <td>atypican</td>\n      <td>-1</td>\n      <td>abortion.A97</td>\n      <td>we're saying that the pregnant person should h...</td>\n      <td>1.0</td>\n      <td>support</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>abortion</td>\n      <td>abortion.A</td>\n      <td>abortion.A101</td>\n      <td>atypican</td>\n      <td>-1</td>\n      <td>abortion.A100</td>\n      <td>No answer to my retort, just a down vote. That...</td>\n      <td>1.0</td>\n      <td>support</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>abortion</td>\n      <td>abortion.A</td>\n      <td>abortion.A102</td>\n      <td>SMCdeBater</td>\n      <td>-1</td>\n      <td>abortion.A101</td>\n      <td>I'm sooo sick of people like you who feel like...</td>\n      <td>0.0</td>\n      <td>oppose</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>4963</th>\n      <td>obama</td>\n      <td>obama.K</td>\n      <td>obama.K0</td>\n      <td>!UNK</td>\n      <td>00:00</td>\n      <td>None</td>\n      <td></td>\n      <td>0.5</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4964</th>\n      <td>obama</td>\n      <td>obama.L</td>\n      <td>obama.L0</td>\n      <td>!UNK</td>\n      <td>00:00</td>\n      <td>None</td>\n      <td></td>\n      <td>0.5</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4965</th>\n      <td>obama</td>\n      <td>obama.M</td>\n      <td>obama.M0</td>\n      <td>!UNK</td>\n      <td>00:00</td>\n      <td>None</td>\n      <td></td>\n      <td>0.5</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4966</th>\n      <td>obama</td>\n      <td>obama.N</td>\n      <td>obama.N0</td>\n      <td>!UNK</td>\n      <td>00:00</td>\n      <td>None</td>\n      <td></td>\n      <td>0.5</td>\n      <td>None</td>\n    </tr>\n    <tr>\n      <th>4967</th>\n      <td>obama</td>\n      <td>obama.O</td>\n      <td>obama.O0</td>\n      <td>!UNK</td>\n      <td>00:00</td>\n      <td>None</td>\n      <td></td>\n      <td>0.5</td>\n      <td>None</td>\n    </tr>\n  </tbody>\n</table>\n<p>4968 rows × 9 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.append(new_records, ignore_index=True)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf346eb2c7ae48619aed9a044ea8fe16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "66"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pasre_strategy = {\n",
    "    \"node_id\": \"post_id\",\n",
    "    \"author\": \"author_id\",\n",
    "    \"timestamp\": \"creation_date\",\n",
    "    \"parent_id\": \"parent_post_id\"\n",
    "    }\n",
    "parser = DataFrameConversationReader(pasre_strategy)\n",
    "gb = df.groupby(\"discussion_id\")\n",
    "convs: List[Conversation] = list(tqdm(map(parser.parse, map(itemgetter(1), gb))))\n",
    "len(convs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "1456"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_convs = [Conversation(child) for conv in convs for child in conv.root.children]\n",
    "len(sub_convs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#conversation stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1456\n",
      "3.2493131868131866\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "count    1456.000000\nmean        3.249313\nstd         6.341079\nmin         1.000000\n25%         1.000000\n50%         1.000000\n75%         2.000000\nmax        80.000000\ndtype: float64"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = [c.size for c in sub_convs]\n",
    "print(len(sizes))\n",
    "print(np.mean(sizes))\n",
    "print(np.median(sizes))\n",
    "pd.Series(sizes).describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:ylabel='Frequency'>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAD4CAYAAAAdIcpQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUFklEQVR4nO3df7RdZX3n8ffHRFBoh4DcYWiSaeKYBcNYURoRl52Olar8sITOWAeWHTMOq5lZQ6dau5aGdlaxM+MsWe2IOKtllREqWAsqWskgUxsjbdfMGgI3QBEIlDv8TARylV+tWDH6nT/Ok3KMCfvk5p4f1/t+rXXW3c+zn7P3N/ec5JP97H32SVUhSdILedG4C5AkTT7DQpLUybCQJHUyLCRJnQwLSVKnpeMuYBiOPvroWrVq1bjLkKQFZdu2bV+vqql9rfuhDItVq1YxPT097jIkaUFJ8tD+1jkNJUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSer0Q/kJ7oO1auMXx7LfBz985lj2K0ldPLKQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1GloYZHkiiS7ktzZ1/fbSe5JckeSP06yrG/dBUlmktyb5K19/ae1vpkkG4dVryRp/4Z5ZPEJ4LS9+jYDr6yqVwF/BVwAkOQE4Bzgn7Tn/F6SJUmWAL8LnA6cAJzbxkqSRmhoYVFVfwE8sVffn1bV7ta8CVjRltcB11TVt6vqAWAGOLk9Zqrq/qp6DrimjZUkjdA4z1n8G+B/teXlwCN963a0vv31/4AkG5JMJ5menZ0dQrmStHiNJSyS/AawG/jUfG2zqi6rqrVVtXZqamq+NitJApaOeodJ/jXwNuDUqqrWvRNY2TdsRevjBfolSSMy0iOLJKcB7wfOqqpn+1ZtAs5JcmiS1cAa4GbgFmBNktVJDqF3EnzTKGuWJA3xyCLJ1cAbgaOT7AAupHf106HA5iQAN1XVv6uqu5J8Brib3vTU+VX13badXwa+BCwBrqiqu4ZVsyRp34YWFlV17j66L3+B8R8CPrSP/huAG+axNEnSAfIT3JKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqdPQwiLJFUl2Jbmzr++oJJuT3Nd+Htn6k+RjSWaS3JHkpL7nrG/j70uyflj1SpL2b5hHFp8ATturbyOwparWAFtaG+B0YE17bAAuhV64ABcCrwNOBi7cEzCSpNEZWlhU1V8AT+zVvQ64si1fCZzd139V9dwELEtyLPBWYHNVPVFVTwKb+cEAkiQN2ajPWRxTVY+25ceAY9rycuCRvnE7Wt/++n9Akg1JppNMz87Ozm/VkrTIje0Ed1UVUPO4vcuqam1VrZ2ampqvzUqSGH1YPN6ml2g/d7X+ncDKvnErWt/++iVJIzTqsNgE7LmiaT1wXV//u9pVUacAT7fpqi8Bb0lyZDux/ZbWJ0kaoaXD2nCSq4E3Akcn2UHvqqYPA59Jch7wEPCONvwG4AxgBngWeDdAVT2R5D8Dt7Rx/6mq9j5pLkkasqGFRVWdu59Vp+5jbAHn72c7VwBXzGNpkqQD5Ce4JUmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVKngcIiyU8MuxBJ0uQa9Mji95LcnOTfJzliqBVJkibOQGFRVf8UeCewEtiW5I+SvHmolUmSJsbA5yyq6j7gPwIfAP4Z8LEk9yT558MqTpI0GQY9Z/GqJBcD24E3AT9XVf+4LV98oDtN8qtJ7kpyZ5Krk7wkyeokW5PMJPl0kkPa2ENbe6atX3Wg+5MkHZxBjyz+O3ArcGJVnV9VtwJU1dfoHW0MLMly4FeAtVX1SmAJcA5wEXBxVb0CeBI4rz3lPODJ1n9xGydJGqFBw+JM4I+q6lsASV6U5DCAqvrkHPa7FHhpkqXAYcCj9I5Srm3rrwTObsvrWpu2/tQkmcM+JUlzNGhYfBl4aV/7sNZ3wKpqJ/A7wMP0QuJpYBvwVFXtbsN2AMvb8nLgkfbc3W38y/bebpINSaaTTM/Ozs6lNEnSfgwaFi+pqr/Z02jLh81lh0mOpHe0sBr4MeBw4LS5bKtfVV1WVWurau3U1NTBbk6S1GfQsPhmkpP2NJL8JPCtOe7zZ4EHqmq2qr4DfB54A7CsTUsBrAB2tuWd9C7Zpa0/AvjGHPctSZqDpd1DAHgv8NkkXwMC/APgX85xnw8Dp7RzHt8CTgWmgRuBtwPXAOuB69r4Ta39f9v6r1RVzXHfkqQ5GCgsquqWJMcDx7Wue9tRwQGrqq1JrqV3ddVu4DbgMuCLwDVJ/kvru7w95XLgk0lmgCfoXTklSRqhQY8sAF4LrGrPOSkJVXXVXHZaVRcCF+7VfT9w8j7G/i3wC3PZjyRpfgwUFkk+Cfwj4Hbgu627gDmFhSRpYRn0yGItcILnCiRpcRr0aqg76Z3UliQtQoMeWRwN3J3kZuDbezqr6qyhVCVJmiiDhsUHh1mEJGmyDXrp7J8n+XFgTVV9uX1GYslwS5MkTYpBb1H+S/Ru4vf7rWs58IUh1SRJmjCDnuA+n94tOZ6Bv/sipL8/rKIkSZNl0LD4dlU9t6fR7tHkZbSStEgMGhZ/nuTX6X0HxZuBzwL/c3hlSZImyaBhsRGYBb4K/FvgBg7wG/IkSQvXoFdDfQ/4H+0hSVpkBr031APs4xxFVb183iuSJE2cA7k31B4voXcX2KPmvxxJ0iQa6JxFVX2j77Gzqj4KnDnc0iRJk2LQaaiT+povonekcSDfhSFJWsAG/Qf/v/Ut7wYeBN4x79VIkibSoFdD/cywC5EkTa5Bp6He90Lrq+oj81OOJGkSHcjVUK8FNrX2zwE3A/cNoyhJ0mQZNCxWACdV1V8DJPkg8MWq+sVhFSZJmhyD3u7jGOC5vvZzrU+StAgMGhZXATcn+WA7qtgKXDnXnSZZluTaJPck2Z7k9UmOSrI5yX3t55FtbJJ8LMlMkjv2uoxXkjQCg34o70PAu4En2+PdVfVfD2K/lwB/UlXHAycC2+ndrHBLVa0BtrQ2wOnAmvbYAFx6EPuVJM3BoEcWAIcBz1TVJcCOJKvnssMkRwA/DVwOUFXPVdVTwDqeP1q5Eji7La8Drqqem4BlSY6dy74lSXMz6NeqXgh8ALigdb0Y+MM57nM1vdud/0GS25J8PMnhwDFV9Wgb8xjPnxNZDjzS9/wdrU+SNCKDHln8PHAW8E2Aqvoa8KNz3OdS4CTg0qp6Tdvmxv4BVVUc4DfxJdmQZDrJ9Ozs7BxLkyTty6Bh8Vz/P+DtSGCudgA7qmpra19LLzwe3zO91H7uaut3Aiv7nr+i9X2fqrqsqtZW1dqpqamDKE+StLdBw+IzSX6f3vmCXwK+zBy/CKmqHgMeSXJc6zoVuJveB/7Wt771wHVteRPwrnZV1CnA033TVZKkEej8UF6SAJ8GjgeeAY4DfrOqNh/Efv8D8KkkhwD307vS6kX0Quk84CGev1HhDcAZwAzwbBsrSRqhzrCoqkpyQ1X9BHAwAdG/zdv5/i9U2uPUfe0fOH8+9itJmptBp6FuTfLaoVYiSZpYg94b6nXALyZ5kN7VS6H3n/5XDaswSdLkeMGwSPIPq+ph4K0jqkeSNIG6jiy+QO9usw8l+VxV/YsR1CRJmjBd5yzSt/zyYRYiSZpcXWFR+1mWJC0iXdNQJyZ5ht4RxkvbMjx/gvvvDbU6SdJEeMGwqKoloypEkjS5DuQW5ZKkRcqwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1GltYJFmS5LYk17f26iRbk8wk+XSSQ1r/oa0909avGlfNkrRYjfPI4j3A9r72RcDFVfUK4EngvNZ/HvBk67+4jZMkjdBYwiLJCuBM4OOtHeBNwLVtyJXA2W15XWvT1p/axkuSRmRcRxYfBd4PfK+1XwY8VVW7W3sHsLwtLwceAWjrn27jJUkjMvKwSPI2YFdVbZvn7W5IMp1kenZ2dj43LUmL3jiOLN4AnJXkQeAaetNPlwDLkuz5TvAVwM62vBNYCdDWHwF8Y++NVtVlVbW2qtZOTU0N908gSYvMyMOiqi6oqhVVtQo4B/hKVb0TuBF4exu2HriuLW9qbdr6r1RVjbBkSVr0JulzFh8A3pdkht45ictb/+XAy1r/+4CNY6pPkhatpd1Dhqeq/gz4s7Z8P3DyPsb8LfALIy1MkvR9JunIQpI0oQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUybCQJHUyLCRJnQwLSVInw0KS1MmwkCR1MiwkSZ0MC0lSJ8NCktTJsJAkdTIsJEmdDAtJUifDQpLUaeRhkWRlkhuT3J3kriTvaf1HJdmc5L7288jWnyQfSzKT5I4kJ426Zkla7MZxZLEb+LWqOgE4BTg/yQnARmBLVa0BtrQ2wOnAmvbYAFw6+pIlaXEbeVhU1aNVdWtb/mtgO7AcWAdc2YZdCZzdltcBV1XPTcCyJMeOtmpJWtzGes4iySrgNcBW4JiqerStegw4pi0vBx7pe9qO1rf3tjYkmU4yPTs7O7yiJWkRGltYJPkR4HPAe6vqmf51VVVAHcj2quqyqlpbVWunpqbmsVJJ0ljCIsmL6QXFp6rq86378T3TS+3nrta/E1jZ9/QVrU+SNCLjuBoqwOXA9qr6SN+qTcD6trweuK6v/13tqqhTgKf7pqskSSOwdAz7fAPwr4CvJrm99f068GHgM0nOAx4C3tHW3QCcAcwAzwLvHmm1kqTRh0VV/W8g+1l96j7GF3D+UIuSJL0gP8EtSepkWEiSOhkWkqROhoUkqZNhIUnqZFhIkjoZFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE6GhSSpk2EhSepkWEiSOo3j+yy0H6s2fnFs+37ww2eObd+SJp9HFpKkToaFJKmTYSFJ6mRYSJI6GRaSpE5eDSVgfFdieRWWtDB4ZCFJ6rRgwiLJaUnuTTKTZOO465GkxWRBTEMlWQL8LvBmYAdwS5JNVXX3eCvTQuUHIKUDsyDCAjgZmKmq+wGSXAOsAwyLBW6c/2iPy2L8My/GgPxhOw+4UMJiOfBIX3sH8Lr+AUk2ABta82+S3HsA2z8a+PpBVTgck1oXTG5tk1oXTG5tQ68rF835qZP6O4MJrS0XHVRdP76/FQslLDpV1WXAZXN5bpLpqlo7zyUdtEmtCya3tkmtCya3tkmtC6xtLoZV10I5wb0TWNnXXtH6JEkjsFDC4hZgTZLVSQ4BzgE2jbkmSVo0FsQ0VFXtTvLLwJeAJcAVVXXXPO5iTtNXIzCpdcHk1japdcHk1japdYG1zcVQ6kpVDWO7kqQfIgtlGkqSNEaGhSSp06IOi0m6hUiSK5LsSnJnX99RSTYnua/9PHIMda1McmOSu5PcleQ9E1TbS5LcnOQvW22/1fpXJ9naXtdPt4siRi7JkiS3Jbl+wup6MMlXk9yeZLr1TcLruSzJtUnuSbI9yesnpK7j2u9qz+OZJO+dkNp+tb3370xydfs7MZT32aINi75biJwOnACcm+SEMZb0CeC0vfo2Aluqag2wpbVHbTfwa1V1AnAKcH77PU1Cbd8G3lRVJwKvBk5LcgpwEXBxVb0CeBI4bwy1AbwH2N7XnpS6AH6mql7ddz3+JLyelwB/UlXHAyfS+92Nva6qurf9rl4N/CTwLPDH464tyXLgV4C1VfVKehf/nMOw3mdVtSgfwOuBL/W1LwAuGHNNq4A7+9r3Ase25WOBeyfg93YdvXt0TVRtwGHArfQ+2f91YOm+XucR1rOC3j8gbwKuBzIJdbV9PwgcvVffWF9P4AjgAdpFN5NS1z7qfAvwfyahNp6/s8VR9K5svR5467DeZ4v2yIJ930Jk+Zhq2Z9jqurRtvwYcMw4i0myCngNsJUJqa1N9dwO7AI2A/8PeKqqdrch43pdPwq8H/hea79sQuoCKOBPk2xrt8mB8b+eq4FZ4A/a1N3Hkxw+AXXt7Rzg6rY81tqqaifwO8DDwKPA08A2hvQ+W8xhsaBU778JY7vOOcmPAJ8D3ltVz/SvG2dtVfXd6k0PrKB3w8njx1FHvyRvA3ZV1bZx17IfP1VVJ9Gbgj0/yU/3rxzT67kUOAm4tKpeA3yTvaZ1JuDvwCHAWcBn9143jtraOZJ19IL2x4DD+cGp7HmzmMNiIdxC5PEkxwK0n7vGUUSSF9MLik9V1ecnqbY9quop4EZ6h93Lkuz5wOk4Xtc3AGcleRC4ht5U1CUTUBfwd/8jpap20Zt7P5nxv547gB1VtbW1r6UXHuOuq9/pwK1V9Xhrj7u2nwUeqKrZqvoO8Hl6772hvM8Wc1gshFuIbALWt+X19M4XjFSSAJcD26vqIxNW21SSZW35pfTOpWynFxpvH1dtVXVBVa2oqlX03ldfqap3jrsugCSHJ/nRPcv05uDvZMyvZ1U9BjyS5LjWdSq9ryAY+/usz7k8PwUF46/tYeCUJIe1v6d7fmfDeZ+N82TRuB/AGcBf0Zvn/o0x13I1vXnH79D7X9Z59Oa5twD3AV8GjhpDXT9F7/D6DuD29jhjQmp7FXBbq+1O4Ddb/8uBm4EZelMGh47xdX0jcP2k1NVq+Mv2uGvP+35CXs9XA9Pt9fwCcOQk1NVqOxz4BnBEX9/YawN+C7invf8/CRw6rPeZt/uQJHVazNNQkqQBGRaSpE6GhSSpk2EhSepkWEiSOhkWkqROhoUkqdP/B/tZgBZefKJ6AAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(sizes).plot.hist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n",
      "20.758928571428573\n",
      "16.0\n"
     ]
    }
   ],
   "source": [
    "filtered_sizes = [s for s in sizes if s >= 10]\n",
    "print(len(filtered_sizes))\n",
    "print(np.mean(filtered_sizes))\n",
    "print(np.median(filtered_sizes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "4731"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_labels = {(conv.id, node.node_id): node.data[\"discussion_stance_id\"] for conv in sub_convs for _,node in conv.iter_conversation() if node.data[\"discussion_stance_id\"] != 0.5}\n",
    "len(post_labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Author labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1398\n",
      "2717\n"
     ]
    }
   ],
   "source": [
    "def get_majority_vote(labels: List[int]) -> int:\n",
    "    return int(np.mean(labels) >= 0.5)\n",
    "\n",
    "def get_author_labels(c: Conversation) -> Dict[Any, int]:\n",
    "    authors_post_labels = {}\n",
    "    for depth, node in c.iter_conversation():\n",
    "        data = node.data\n",
    "        author = node.author\n",
    "        current_author_labels = authors_post_labels.setdefault(author, [])\n",
    "        current_author_labels.append(data[\"discussion_stance_id\"])\n",
    "\n",
    "    result_labels = {a: get_majority_vote(labels) for a, labels in authors_post_labels.items()}\n",
    "    return result_labels\n",
    "\n",
    "author_labels_per_conversation = {c.id: get_author_labels(c) for c in sub_convs}\n",
    "author_labels_per_conversation = {k: v for k, v in author_labels_per_conversation.items() if len(v) > 0 and not (len(v) == 1 and None in v)}\n",
    "print(len(author_labels_per_conversation))\n",
    "print(sum(len(v) for v in author_labels_per_conversation.values()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def get_ordered_candidates_for_pivot(graph: nx.Graph, weight_field: str = \"weight\") -> Sequence[Any]:\n",
    "    inv_weight_field = \"inv_weight\"\n",
    "    for _, _, pair_data in graph.edges(data=True):\n",
    "        weight = pair_data.data[weight_field]\n",
    "        pair_data.data[inv_weight_field] = 1 / weight\n",
    "\n",
    "    node_centralities = nx.closeness_centrality(graph, distance=inv_weight_field)\n",
    "    return list(map(itemgetter(0), sorted(node_centralities.items(), key=itemgetter(1), reverse=True)))\n",
    "\n",
    "def get_pivot_node(graph: nx.Graph, labeled_authors: Set[Any], weight_field: str = \"weight\") -> Any:\n",
    "    candidates = get_ordered_candidates_for_pivot(graph, weight_field=weight_field)\n",
    "    return next(iter(filter(labeled_authors.__contains__, candidates)), None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "def extend_preds(graph: nx.Graph, seed_node: Any, core_authors_preds: Dict[Any, int]) -> Dict[Any, int]:\n",
    "    extended_results = dict(core_authors_preds.items())\n",
    "    for (n1, n2) in nx.bfs_edges(graph, source=seed_node):\n",
    "        if n2 not in extended_results:\n",
    "            n1_label = extended_results[n1]\n",
    "            extended_results[n2] = 1 - n1_label\n",
    "\n",
    "    return extended_results\n",
    "\n",
    "def get_authors_labels_in_conv(conv: Conversation) -> Dict[Any, int]:\n",
    "    if conv.id not in author_labels_per_conversation:\n",
    "        return None\n",
    "\n",
    "    return author_labels_per_conversation[conv.id]\n",
    "\n",
    "def get_author_preds(clf: BaseStanceClassifier, pivot: Any) -> Dict[Any, int]:\n",
    "    support_label = authors_labels[pivot]\n",
    "    opposer_label = 1 - support_label\n",
    "    supporters = clf.get_supporters()\n",
    "    opposers = clf.get_complement()\n",
    "    preds = {}\n",
    "    for supporter in supporters:\n",
    "        preds[supporter] = support_label\n",
    "    for opposer in opposers:\n",
    "        preds[opposer] = opposer_label\n",
    "\n",
    "    return preds\n",
    "\n",
    "def get_maxcut_results(graph: InteractionsGraph, op: Any) -> MaxcutStanceClassifier:\n",
    "    maxcut = MaxcutStanceClassifier(weight_field=graph.WEIGHT_FIELD)\n",
    "    maxcut.set_input(graph.graph, op)\n",
    "    maxcut.classify_stance()\n",
    "    return maxcut\n",
    "\n",
    "def get_greedy_results(graph: InteractionsGraph, op: Any) -> BaseStanceClassifier:\n",
    "    clf = MSTStanceClassifier()#weight_field=graph.WEIGHT_FIELD)\n",
    "    clf.set_input(graph.graph)\n",
    "    clf.classify_stance(op)\n",
    "    return clf\n",
    "\n",
    "def align_gs_with_predictions(authors_labels: Dict[Any, int], author_preds: Dict[Any, int]) -> Tuple[List[int], List[int]]:\n",
    "    y_true, y_pred = [], []\n",
    "    for author, true_label in authors_labels.items():\n",
    "        pred = author_preds.get(author, None)\n",
    "        if pred is None: continue\n",
    "\n",
    "        y_true.append(true_label)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "def predict_for_partition(true: List[int], preds: List[int]) -> Tuple[List[int], List[int]]:\n",
    "    acc = accuracy_score(true, preds)\n",
    "    if acc < 0.5:\n",
    "        preds = [1-l for l in preds]\n",
    "\n",
    "    return true, preds\n",
    "\n",
    "def get_best_preds(true_labels: Dict[Any, int], pred_labels: Dict[Any, int]) -> Dict[Any, int]:\n",
    "    true, preds = align_gs_with_predictions(true_labels, pred_labels)\n",
    "    acc = accuracy_score(true, preds)\n",
    "    if acc < 0.5:\n",
    "        return {k: (1-  l) for k, l in pred_labels.items()}\n",
    "\n",
    "    return pred_labels\n",
    "\n",
    "def get_posts_preds(conv: Conversation, post_labels: Dict[Any, int], author_preds: Dict[Any, int]) -> Tuple[Dict[Any, int], Dict[Any, int]]:\n",
    "    posts_true, posts_pred = {}, {}\n",
    "    conv_id = conv.id\n",
    "    for depth, node in conv.iter_conversation():\n",
    "        label = post_labels.get((conv_id, node.node_id), None)\n",
    "        if label is None: continue\n",
    "        pred = author_preds.get(node.author, None)\n",
    "        if pred is None: continue\n",
    "\n",
    "        posts_true[node.node_id] = label\n",
    "        posts_pred[node.node_id] = pred\n",
    "\n",
    "    return posts_true, posts_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5d8098265694e28993d01f86ddd4e12"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "interactions_parser = get_reply_interactions_parser()\n",
    "\n",
    "convs_by_id: Dict[Any, Conversation] = {}\n",
    "full_graphs: Dict[Any, InteractionsGraph] = {}\n",
    "core_graphs: Dict[Any, InteractionsGraph] = {}\n",
    "maxcut_results: Dict[Any, MaxcutStanceClassifier] = {}\n",
    "pivot_nodes = {}\n",
    "\n",
    "author_predictions: Dict[Any, Dict[str, Dict[Any, int]]] = {}\n",
    "posts_predictions: Dict[Any, Dict[str, Dict[Any, int]]] = {}\n",
    "\n",
    "\n",
    "\n",
    "empty_core = []\n",
    "unlabeled_conversations = []\n",
    "unlabeled_op = []\n",
    "insufficient_author_labels = []\n",
    "too_small_cut_value = []\n",
    "op_not_in_core = []\n",
    "large_graphs = []\n",
    "single_author_conv = []\n",
    "\n",
    "extend_results = False\n",
    "naive_results = False\n",
    "\n",
    "def calc_weight(interactions: PairInteractionsData) -> float:\n",
    "    n_replies = interactions[\"replies\"]\n",
    "    # n_quotes = interactions[\"quotes\"]\n",
    "    return n_replies\n",
    "    # return n_quotes\n",
    "\n",
    "count_conv = 0\n",
    "for i, conv in tqdm(enumerate(sub_convs)):\n",
    "\n",
    "\n",
    "    count_conv += 1\n",
    "    authors_labels = get_authors_labels_in_conv(conv)\n",
    "    if authors_labels is None:\n",
    "        unlabeled_conversations.append(i)\n",
    "        continue\n",
    "\n",
    "    if len(authors_labels) == 0:\n",
    "        insufficient_author_labels.append(i)\n",
    "        continue\n",
    "\n",
    "    interaction_graph = interactions_parser.parse(conv)\n",
    "    interaction_graph.set_interaction_weights(calc_weight)\n",
    "    zero_edges = [(v, u) for v, u, d in interaction_graph.graph.edges(data=True) if d[\"weight\"] == 0]\n",
    "    interaction_graph.graph.remove_edges_from(zero_edges)\n",
    "\n",
    "    if len(conv.participants) <= 1:\n",
    "        single_author_conv.append(i)\n",
    "        continue\n",
    "\n",
    "    convs_by_id[conv.id] = conv\n",
    "    full_graphs[conv.id] = interaction_graph\n",
    "\n",
    "    pivot_node = get_pivot_node(interaction_graph.graph, authors_labels, weight_field=\"weight\")\n",
    "    pivot_nodes[conv.id] = pivot_node\n",
    "\n",
    "    mst = get_greedy_results(interaction_graph, pivot_node)\n",
    "    preds = get_author_preds(mst, pivot_node)\n",
    "    author_predictions[conv.id] = {\"mst\": preds}\n",
    "\n",
    "    if naive_results:\n",
    "        continue\n",
    "\n",
    "    core_interactions = interaction_graph.get_core_interactions()\n",
    "    core_graphs[conv.id] = core_interactions\n",
    "    if core_interactions.graph.size() == 0:\n",
    "        empty_core.append(i)\n",
    "        continue\n",
    "\n",
    "    components = list(nx.connected_components(core_interactions.graph))\n",
    "    core_interactions = core_interactions.get_subgraph(components[0])\n",
    "    pivot_node = get_pivot_node(core_interactions.graph, authors_labels, weight_field=\"weight\")\n",
    "    maxcut = get_maxcut_results(core_interactions, pivot_node)\n",
    "    if maxcut.cut_value < 3:\n",
    "        too_small_cut_value.append(i)\n",
    "        continue\n",
    "\n",
    "    maxcut_results[conv.id] = maxcut\n",
    "\n",
    "    # if core_interactions.graph.order() > 120:\n",
    "    #     large_graphs.append(conv)\n",
    "    #     continue\n",
    "\n",
    "    preds = get_author_preds(maxcut, pivot_node)\n",
    "    author_predictions[conv.id][\"core\"] = preds\n",
    "\n",
    "    # get extended results\n",
    "    preds = extend_preds(interaction_graph.graph, pivot_node, preds)\n",
    "    author_predictions[conv.id][\"full\"] = preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of conversations (in all topics): 66\n",
      "total number of conversations (in the relevant topics): 1456\n",
      "total number of conversations with labeled authors (in all topics): 1398\n",
      "total number of conversations with labeled authors (in the relevant topics): 1398\n",
      "number of conversations in eval: 521\n",
      "number of conversations with core in eval: 521\n",
      "number of unique authors in eval: 644\n",
      "number of unique authors in core: 155\n",
      "total number of labeled authors: 2717\n",
      "=========\n",
      "number of conversations with single author: 877\n",
      "number of conversations with empty core: 439\n",
      "number of conversations with op not in core: 0\n",
      "number of conversations with too large core: 0\n",
      "number of conversations with too small cut value: 9\n",
      "number of unlabeled conversations: 58\n",
      "number of conversations with unlabeled op: 0\n",
      "number of conversations with insufficient labeled authors: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"total number of conversations (in all topics): {len(convs)}\")\n",
    "print(f\"total number of conversations (in the relevant topics): {count_conv}\")\n",
    "print(f\"total number of conversations with labeled authors (in all topics): {len(author_labels_per_conversation)}\")\n",
    "print(f\"total number of conversations with labeled authors (in the relevant topics): {count_conv - len(unlabeled_conversations)}\")\n",
    "\n",
    "print(f\"number of conversations in eval: {len(convs_by_id)}\")\n",
    "print(f\"number of conversations with core in eval: {len(core_graphs)}\")\n",
    "all_authors_in_eval = set(chain(*[predictions[\"mst\"].keys() for predictions in author_predictions.values()]))\n",
    "print(f\"number of unique authors in eval: {len(all_authors_in_eval)}\")\n",
    "all_authors_in_core_eval = set(chain(*[predictions.get(\"core\", {}).keys() for predictions in author_predictions.values()]))\n",
    "print(f\"number of unique authors in core: {len(all_authors_in_core_eval)}\")\n",
    "\n",
    "labeled_authors = sum(len(v) for v in author_labels_per_conversation.values())\n",
    "print(f\"total number of labeled authors: {labeled_authors}\")\n",
    "print(\"=========\")\n",
    "print(f\"number of conversations with single author: {len(single_author_conv)}\")\n",
    "print(f\"number of conversations with empty core: {len(empty_core)}\")\n",
    "print(f\"number of conversations with op not in core: {len(op_not_in_core)}\")\n",
    "print(f\"number of conversations with too large core: {len(large_graphs)}\")\n",
    "print(f\"number of conversations with too small cut value: {len(too_small_cut_value)}\")\n",
    "print(f\"number of unlabeled conversations: {len(unlabeled_conversations)}\")\n",
    "print(f\"number of conversations with unlabeled op: {len(unlabeled_op)}\")\n",
    "print(f\"number of conversations with insufficient labeled authors: {len(insufficient_author_labels)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc ---- (macro): 0.8249673842139594\n",
      "acc best (macro): 0.880218525766471\n",
      "acc ---- (micro): 0.8229508196721311\n",
      "acc best (micro): 0.8754098360655738\n",
      "Showing results of predictor: core\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.85      0.81       137\n",
      "           1       0.87      0.80      0.83       168\n",
      "\n",
      "    accuracy                           0.82       305\n",
      "   macro avg       0.82      0.83      0.82       305\n",
      "weighted avg       0.83      0.82      0.82       305\n",
      "\n",
      "\n",
      "\t\tResults for best partition (regardless for stance assignment\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.90      0.87       137\n",
      "           1       0.91      0.86      0.88       168\n",
      "\n",
      "    accuracy                           0.88       305\n",
      "   macro avg       0.87      0.88      0.87       305\n",
      "weighted avg       0.88      0.88      0.88       305\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "acc ---- (macro): 0.7940132948795318\n",
      "acc best (macro): 0.8585507361293018\n",
      "acc ---- (micro): 0.7913385826771654\n",
      "acc best (micro): 0.8523622047244095\n",
      "Showing results of predictor: full\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.84      0.75       194\n",
      "           1       0.89      0.76      0.82       314\n",
      "\n",
      "    accuracy                           0.79       508\n",
      "   macro avg       0.79      0.80      0.79       508\n",
      "weighted avg       0.81      0.79      0.79       508\n",
      "\n",
      "\n",
      "\t\tResults for best partition (regardless for stance assignment\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.88      0.82       194\n",
      "           1       0.92      0.83      0.87       314\n",
      "\n",
      "    accuracy                           0.85       508\n",
      "   macro avg       0.84      0.86      0.85       508\n",
      "weighted avg       0.86      0.85      0.85       508\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "acc ---- (macro): 0.8070111135963004\n",
      "acc best (macro): 0.8283787521424418\n",
      "acc ---- (micro): 0.7853260869565217\n",
      "acc best (micro): 0.8141304347826087\n",
      "Showing results of predictor: mst\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.82      0.74       704\n",
      "           1       0.87      0.76      0.81      1136\n",
      "\n",
      "    accuracy                           0.79      1840\n",
      "   macro avg       0.78      0.79      0.78      1840\n",
      "weighted avg       0.80      0.79      0.79      1840\n",
      "\n",
      "\n",
      "\t\tResults for best partition (regardless for stance assignment\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.84      0.78       704\n",
      "           1       0.89      0.80      0.84      1136\n",
      "\n",
      "    accuracy                           0.81      1840\n",
      "   macro avg       0.80      0.82      0.81      1840\n",
      "weighted avg       0.82      0.81      0.82      1840\n",
      "\n",
      "-----------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "topic_id = 9\n",
    "for predictor in [\"core\", \"full\", \"mst\"]:\n",
    "    all_true, all_pred = [], []\n",
    "    all_true_best, all_pred_best = [], []\n",
    "\n",
    "    accuracies = []\n",
    "    best_accuracies = []\n",
    "    for conv_id, predictions in author_predictions.items():\n",
    "        conv = convs_by_id[conv_id]\n",
    "        # topic = conv.root.data[\"topic\"]\n",
    "        # if topic != topic_id: continue\n",
    "        author_labels = get_authors_labels_in_conv(conv)\n",
    "        author_preds = predictions.get(predictor, None)\n",
    "        if author_preds is None: continue\n",
    "\n",
    "        y_true, y_pred = align_gs_with_predictions(author_labels, author_preds)\n",
    "        all_true.extend(y_true)\n",
    "        all_pred.extend(y_pred)\n",
    "        accuracies.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "        best_preds = get_best_preds(author_labels, author_preds)\n",
    "        y_true, y_pred = align_gs_with_predictions(author_labels, best_preds)\n",
    "        all_true_best.extend(y_true)\n",
    "        all_pred_best.extend(y_pred)\n",
    "        best_accuracies.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "    print(\"acc ---- (macro):\", np.mean(accuracies))\n",
    "    print(\"acc best (macro):\", np.mean(best_accuracies))\n",
    "    print(\"acc ---- (micro):\", accuracy_score(all_true, all_pred))\n",
    "    print(\"acc best (micro):\", accuracy_score(all_true_best, all_pred_best))\n",
    "    print(f\"Showing results of predictor: {predictor}\")\n",
    "    print(classification_report(all_true, all_pred))\n",
    "    print(f\"\\n\\t\\tResults for best partition (regardless for stance assignment\")\n",
    "    print(classification_report(all_true_best, all_pred_best))\n",
    "    print(\"-----------------------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(66+78.7+77.1+68.3)/4\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for predictor in [\"core\", \"full\", \"mst\"]:\n",
    "    all_true, all_pred = [], []\n",
    "    all_true_best, all_pred_best = [], []\n",
    "    accuracies = []\n",
    "    best_accuracies = []\n",
    "    for conv_id, predictions in author_predictions.items():\n",
    "        conv = convs_by_id[conv_id]\n",
    "        author_labels = get_authors_labels_in_conv(conv)\n",
    "        author_preds = predictions.get(predictor, None)\n",
    "        if author_preds is None: continue\n",
    "\n",
    "        posts_true, posts_preds = get_posts_preds(conv, post_labels, author_preds)\n",
    "\n",
    "        y_true, y_pred = align_gs_with_predictions(posts_true, posts_preds)\n",
    "        all_true.extend(y_true)\n",
    "        all_pred.extend(y_pred)\n",
    "        accuracies.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "        best_preds = get_best_preds(posts_true, posts_preds)\n",
    "        y_true, y_pred = align_gs_with_predictions(posts_true, best_preds)\n",
    "        all_true_best.extend(y_true)\n",
    "        all_pred_best.extend(y_pred)\n",
    "        best_accuracies.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "    print(\"acc ---- (macro):\", np.mean(accuracies))\n",
    "    print(\"acc best (macro):\", np.mean(best_accuracies))\n",
    "    print(\"acc ---- (micro):\", accuracy_score(all_true, all_pred))\n",
    "    print(\"acc best (micro):\", accuracy_score(all_true_best, all_pred_best))\n",
    "    print(f\"Showing results of predictor: {predictor}\")\n",
    "    print(classification_report(all_true, all_pred))\n",
    "    print(f\"\\n\\tResults for best partition (regardless for stance assignment\")\n",
    "    print(classification_report(all_true_best, all_pred_best))\n",
    "    print(\"-----------------------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_pairs_average_distance(\n",
    "        pairs: Iterable[Tuple[int, int]],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    distances = list(starmap(lambda i, j: cosine(embeddings[i], embeddings[j]), pairs))\n",
    "    return float(np.mean(distances))\n",
    "\n",
    "\n",
    "def compute_average_angle_from_node(\n",
    "        node_index: int,\n",
    "        group_indices: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = ((node_index, i) for i in group_indices)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)\n",
    "\n",
    "\n",
    "def compute_group_average_angle(\n",
    "        group_indices: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = combinations(group_indices, 2)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)\n",
    "\n",
    "\n",
    "def compute_cross_groups_average_angle(\n",
    "        group1: Sequence[int],\n",
    "        group2: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = product(group1, group2)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "supporters_avg_angles = []\n",
    "opposers_avg_angles = []\n",
    "mean_cross_angle = []\n",
    "op2supporters = []\n",
    "op2opposers = []\n",
    "for i in range(len(maxcut_results)):\n",
    "    maxcut = maxcut_results[i]\n",
    "    op, all_embeddings, supporters, opposers =\\\n",
    "        maxcut.op, maxcut.embeddings, maxcut.get_supporters(), maxcut.get_complement()\n",
    "\n",
    "    op2supporters.append(compute_average_angle_from_node(op, supporters, all_embeddings))\n",
    "    op2opposers.append(compute_average_angle_from_node(op, opposers, all_embeddings))\n",
    "\n",
    "    supporters_avg_angles.append(compute_group_average_angle(supporters, all_embeddings))\n",
    "    opposers_avg_angles.append(compute_group_average_angle(opposers, all_embeddings))\n",
    "\n",
    "    mean_cross_angle.append(compute_cross_groups_average_angle(supporters, opposers, all_embeddings))\n",
    "\n",
    "print(f\"total conversations {len(maxcut_results)}\")\n",
    "print(f\"supporters avg. cosine {np.nanmean(supporters_avg_angles)}\")\n",
    "print(f\"opposers avg. cosine {np.nanmean(opposers_avg_angles)}\")\n",
    "print(f\"cross groups avg. cosine {np.mean(mean_cross_angle)}\")\n",
    "print(f\"op to supporters avg. cosine {np.mean(op2supporters)}\")\n",
    "print(f\"op to opposers avg. cosine {np.mean(op2opposers)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "strong_convs_indices = []\n",
    "for i in range(len(filtered_convs)):\n",
    "    op2s = op2supporters[i]\n",
    "    op2o = op2opposers[i]\n",
    "    if op2supporters[i] * op2opposers[i] == 0:\n",
    "        continue\n",
    "\n",
    "    diff = op2o - op2s\n",
    "    ratio = op2o / op2s\n",
    "    if (ratio > 2) and (diff > 1):\n",
    "        strong_convs_indices.append(i)\n",
    "\n",
    "len(strong_convs_indices)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# strong_true, strong_preds = zip(*[classification_results[i] for i in strong_convs_indices])\n",
    "# strong_true = list(chain(*strong_true))\n",
    "# strong_preds = list(chain(*strong_preds))\n",
    "strong_true = list(chain(*[author_true_best[i] for i in strong_convs_indices]))\n",
    "strong_preds = list(chain(*[author_pred_best[i] for i in strong_convs_indices]))\n",
    "print(classification_report(strong_true, strong_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_i = 0\n",
    "max_shape = 0\n",
    "# sizes = [(i, g.graph.order()) for i, g  in enumerate(core_graphs)]\n",
    "sizes = [(i, core_graphs[i].graph.order()) for i in range(len(filtered_convs))]\n",
    "sorted_sized = sorted(sizes, key=itemgetter(1), reverse=True)\n",
    "sorted_sized[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_index = 0\n",
    "\n",
    "maxcut = maxcut_results[result_index]\n",
    "op, emb, supporters, opposers = maxcut.op, maxcut.embeddings, maxcut.get_supporters(), maxcut.get_complement()\n",
    "\n",
    "s_cosine = compute_group_average_angle(supporters, emb)\n",
    "o_cosine = compute_group_average_angle(opposers, emb)\n",
    "cross_cosine = compute_cross_groups_average_angle(supporters, opposers, emb)\n",
    "op2support = compute_average_angle_from_node(op, supporters, emb)\n",
    "op2oppose = compute_average_angle_from_node(op, opposers, emb)\n",
    "print(f\"num supporters: {len(supporters)}\")\n",
    "print(f\"num opposers: {len(opposers)}\")\n",
    "print(f\"supporters avg. cosine: {s_cosine}\")\n",
    "print(f\"opposers avg. cosine: {o_cosine}\")\n",
    "print(f\"cross-groups avg. cosine: {cross_cosine}\")\n",
    "print(f\"op <-> supporters avg. cosine: {op2support}\")\n",
    "print(f\"op <-> opposers avg. cosine: {op2oppose}\")\n",
    "print(f\"supporters - opposers diff cosine with op: {op2oppose - op2support}\")\n",
    "print(f\"supporters - opposers ratio cosine with op: {op2oppose / op2support}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Author classification results\n",
    "For the current conversation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true = author_true[result_index]\n",
    "preds = author_pred[result_index]\n",
    "print(classification_report(true, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true = author_true_best[result_index]\n",
    "preds = author_pred_best[result_index]\n",
    "print(classification_report(true, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Post classification results\n",
    "For the current conversation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true = posts_true[result_index]\n",
    "preds = posts_pred[result_index]\n",
    "print(classification_report(true, preds))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Post partition classification results\n",
    "For the current conversation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true = post_true_best[result_index]\n",
    "preds = post_pred_best[result_index]\n",
    "print(classification_report(true, preds))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv = filtered_convs[result_index]\n",
    "author_labels = get_author_labels(conv)\n",
    "true_supporters = [n for n, l in author_labels.items() if l == 1]\n",
    "true_opposers = [n for n, l in author_labels.items() if l == 0]\n",
    "unknown_labels = set(author_labels.keys()) - (set(supporters) | set(opposers))\n",
    "len(author_labels), len(true_opposers), len(true_supporters), len(unknown_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "\n",
    "X = np.vstack([np.array(x) for x in emb.values()])\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "# X_2d = TSNE(n_components=2).fit_transform(X)\n",
    "print(pca.explained_variance_)\n",
    "op = maxcut.op\n",
    "nodes = emb.keys()\n",
    "tp_supporters_indices = [i for i, n in enumerate(nodes) if n in true_supporters and n in supporters]\n",
    "fn_supporters_indices = [i for i, n in enumerate(nodes) if n in true_supporters and n in opposers]\n",
    "tp_opposers_indices = [i for i, n in enumerate(nodes) if n in true_opposers and n in opposers]\n",
    "fn_opposers_indices = [i for i, n in enumerate(nodes) if n in true_opposers and n in supporters]\n",
    "unlabeled_supporters = [i for i, n in enumerate(nodes) if n not in author_labels and n in supporters]\n",
    "unlabeled_opposers = [i for i, n in enumerate(nodes) if n not in author_labels and n in opposers]\n",
    "\n",
    "op_index = [i for i, n in enumerate(nodes) if n == op]\n",
    "\n",
    "plt.scatter(X_2d[tp_supporters_indices, 0], X_2d[tp_supporters_indices, 1], color='g', marker='+')\n",
    "plt.scatter(X_2d[fn_supporters_indices, 0], X_2d[fn_supporters_indices, 1], color='g', marker='x')\n",
    "plt.scatter(X_2d[tp_opposers_indices, 0], X_2d[tp_opposers_indices, 1], color='r', marker='+')\n",
    "plt.scatter(X_2d[fn_opposers_indices, 0], X_2d[fn_opposers_indices, 1], color='r', marker='x')\n",
    "plt.scatter(X_2d[unlabeled_supporters, 0], X_2d[unlabeled_supporters, 1], color='grey', marker='+')\n",
    "plt.scatter(X_2d[unlabeled_opposers, 0], X_2d[unlabeled_opposers, 1], color='grey', marker='x')\n",
    "plt.scatter([X_2d[op_index, 0]], [X_2d[op_index, 1]], color='b', marker='o')\n",
    "\n",
    "# colors = ['b' if i == op else 'g' if i in supporters else 'r' for i in nodes]\n",
    "# markers = ['o' if i ==op else 'x' if i in supporters else '+' for i in nodes]\n",
    "# plt.scatter(X_2d[:, 0], X_2d[:, 1], color=colors)\n",
    "# op_index = [i for i, n  in enumerate(nodes) if n == op][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_figure()\n",
    "graph = maxcut.graph\n",
    "pos = nx.spring_layout(graph)\n",
    "\n",
    "all_nodes = list(nodes)\n",
    "tps = [all_nodes[i] for i in tp_supporters_indices]\n",
    "fns = [all_nodes[i] for i in fn_supporters_indices]\n",
    "fno = [all_nodes[i] for i in fn_opposers_indices]\n",
    "tpo = [all_nodes[i] for i in tp_opposers_indices]\n",
    "unks = [all_nodes[i] for i in unlabeled_supporters]\n",
    "unko = [all_nodes[i] for i in unlabeled_opposers]\n",
    "op = [all_nodes[i] for i in op_index]\n",
    "\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=tps, node_color='g', node_shape='s', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=fns, node_color='g', node_shape='^', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=fno, node_color='r', node_shape='s', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=tpo, node_color='r', node_shape='^', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=unks, node_color='grey', node_shape=\"s\", edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=unko, node_color='grey', node_shape=\"^\", edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=op, node_color='b', node_shape='o', edgecolors=\"black\")\n",
    "\n",
    "node_labels = {n: str(n) for n in graph.nodes}\n",
    "nx.draw_networkx_labels(graph, pos, labels=node_labels, font_color=\"tab:brown\")\n",
    "\n",
    "# Draw the edges that are in the cut.\n",
    "edge_weights = [np.log2(graph[e[0]][e[1]]['weight']) for e in maxcut.cut]\n",
    "nx.draw_networkx_edges(graph, pos, edgelist=maxcut.cut, edge_color=\"black\", width=edge_weights)\n",
    "#\n",
    "# # Draw the edges that are not in the cut\n",
    "leave = [e for e in graph.edges if e not in maxcut.cut]\n",
    "non_cut_weigths = [np.log2(graph[e[0]][e[1]]['weight']) for e in leave]\n",
    "nx.draw_networkx_edges(graph, pos, edgelist=leave, edge_color=\"darkgray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "conv_id = filtered_convs[result_index].id\n",
    "author_labels = author_labels_per_conversation[conv_id]\n",
    "print(author_labels)\n",
    "maxcut.draw(true_labels=author_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_graph = full_graphs[result_index]\n",
    "layout = nx.spring_layout(full_graph.graph)\n",
    "nx.draw(full_graph.graph, layout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kcore = core_graphs[result_index]\n",
    "layout = nx.spring_layout(kcore.graph)\n",
    "nx.draw(kcore.graph, layout)\n",
    "\n",
    "kcore.graph.order()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}