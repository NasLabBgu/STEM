{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import List, Any, Dict, Tuple, Set, Iterable, Sequence\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, starmap, groupby, product, chain, islice\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from conversant.conversation import Conversation\n",
    "from conversant.conversation.parse import DataFrameConversationReader\n",
    "from conversant.interactions import InteractionsGraph\n",
    "from conversant.interactions.interactions_graph import PairInteractionsData\n",
    "from conversant.interactions.reply_interactions_parser import get_reply_interactions_parser\n",
    "from stance_classification.classifiers.base_stance_classifier import BaseStanceClassifier\n",
    "from stance_classification.classifiers.greedy_stance_classifier import MSTStanceClassifier\n",
    "from stance_classification.data.iac import FourForumInteractionsBuilder\n",
    "from stance_classification.data.iac.fourforum_data import load_post_records, build_conversations\n",
    "from stance_classification.data.iac.fourforum_labels import load_author_labels, AuthorLabel\n",
    "from stance_classification.draw_utils import new_figure\n",
    "%matplotlib inline\n",
    "\n",
    "from stance_classification.classifiers.maxcut_stance_classifier import MaxcutStanceClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "      discussion_id  post_id  author_id        creation_date  parent_post_id  \\\n0               878     3557      27083  2008-05-07 23:06:11             NaN   \n1               878     3563       5901  2008-05-08 01:25:25             NaN   \n2               878     3623      11010  2008-05-08 15:03:14             NaN   \n3               878     3627      27083  2008-05-08 15:21:42          3623.0   \n4               878     3632       8705  2008-05-08 15:35:54             NaN   \n...             ...      ...        ...                  ...             ...   \n3046          56718   558884       1488  2014-05-09 05:30:18             NaN   \n3047          56718   558914       2827  2014-05-09 13:40:52        558884.0   \n3048          56718   558915       2827  2014-05-09 13:41:09             NaN   \n3049          56718   558927       2496  2014-05-09 16:26:02        558914.0   \n3050          56718   558964      17093  2014-05-10 01:37:37        558884.0   \n\n      parent_missing  text_id  points  discussion_stance_id is_rebuttal  \n0                  0   513135      -3                   0.0         NaN  \n1                  0   513160      -8                   0.0         NaN  \n2                  0   513211      11                   1.0         NaN  \n3                  0   513212       8                   0.0    disputed  \n4                  0   513276       4                   1.0         NaN  \n...              ...      ...     ...                   ...         ...  \n3046               0   771300       1                   0.0         NaN  \n3047               0   771301       1                   1.0    disputed  \n3048               0   771304       1                   1.0         NaN  \n3049               0   771302       1                   1.0   supported  \n3050               0   771303       1                   1.0    disputed  \n\n[3051 rows x 10 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discussion_id</th>\n      <th>post_id</th>\n      <th>author_id</th>\n      <th>creation_date</th>\n      <th>parent_post_id</th>\n      <th>parent_missing</th>\n      <th>text_id</th>\n      <th>points</th>\n      <th>discussion_stance_id</th>\n      <th>is_rebuttal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>878</td>\n      <td>3557</td>\n      <td>27083</td>\n      <td>2008-05-07 23:06:11</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>513135</td>\n      <td>-3</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>878</td>\n      <td>3563</td>\n      <td>5901</td>\n      <td>2008-05-08 01:25:25</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>513160</td>\n      <td>-8</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>878</td>\n      <td>3623</td>\n      <td>11010</td>\n      <td>2008-05-08 15:03:14</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>513211</td>\n      <td>11</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>878</td>\n      <td>3627</td>\n      <td>27083</td>\n      <td>2008-05-08 15:21:42</td>\n      <td>3623.0</td>\n      <td>0</td>\n      <td>513212</td>\n      <td>8</td>\n      <td>0.0</td>\n      <td>disputed</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>878</td>\n      <td>3632</td>\n      <td>8705</td>\n      <td>2008-05-08 15:35:54</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>513276</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3046</th>\n      <td>56718</td>\n      <td>558884</td>\n      <td>1488</td>\n      <td>2014-05-09 05:30:18</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>771300</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3047</th>\n      <td>56718</td>\n      <td>558914</td>\n      <td>2827</td>\n      <td>2014-05-09 13:40:52</td>\n      <td>558884.0</td>\n      <td>0</td>\n      <td>771301</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>disputed</td>\n    </tr>\n    <tr>\n      <th>3048</th>\n      <td>56718</td>\n      <td>558915</td>\n      <td>2827</td>\n      <td>2014-05-09 13:41:09</td>\n      <td>NaN</td>\n      <td>0</td>\n      <td>771304</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3049</th>\n      <td>56718</td>\n      <td>558927</td>\n      <td>2496</td>\n      <td>2014-05-09 16:26:02</td>\n      <td>558914.0</td>\n      <td>0</td>\n      <td>771302</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>supported</td>\n    </tr>\n    <tr>\n      <th>3050</th>\n      <td>56718</td>\n      <td>558964</td>\n      <td>17093</td>\n      <td>2014-05-10 01:37:37</td>\n      <td>558884.0</td>\n      <td>0</td>\n      <td>771303</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>disputed</td>\n    </tr>\n  </tbody>\n</table>\n<p>3051 rows × 10 columns</p>\n</div>"
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_dir = \"/Users/ronpick/studies/stance/alternative/createdebate_released\"\n",
    "data_path = f\"{base_dir}/post.txt\"\n",
    "header = [\"discussion_id\", \"post_id\", \"author_id\", \"creation_date\", \"parent_post_id\",\n",
    "          \"parent_missing\", \"text_id\", \"points\", \"discussion_stance_id\", \"is_rebuttal\"]\n",
    "\n",
    "df = pd.read_csv(data_path, sep='\\t', names=header, na_values=\"\\\\N\")\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "63"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discussions_info_path = f\"{base_dir}/discussion.txt\"\n",
    "discussions_header = [\"discussion_id\", \"link\", \"title\", \"op\", \"description_id\"]\n",
    "\n",
    "op_df = pd.read_csv(discussions_info_path, sep='\\t', names=discussions_header, na_values=\"\\\\N\")\n",
    "discussion_op_map = list(zip(op_df[\"discussion_id\"], op_df[\"op\"]))\n",
    "discussion_title_map = dict(zip(op_df[\"discussion_id\"], op_df[\"title\"]))\n",
    "discussion_inittext_map = dict(zip(op_df[\"discussion_id\"], op_df[\"description_id\"]))\n",
    "len(discussion_op_map)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "63"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discussions_topic_path = f\"{base_dir}/discussion_topic.txt\"\n",
    "discussions_topic_header = [\"discussion_id\", \"topic_id\"]\n",
    "\n",
    "topic_df = pd.read_csv(discussions_topic_path, sep='\\t', names=discussions_topic_header)\n",
    "discussion_topic_map = dict(zip(topic_df[\"discussion_id\"], topic_df[\"topic_id\"]))\n",
    "len(discussion_topic_map)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "df[\"root_discussion_id\"] = df[\"discussion_id\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### fill all missing parents as direct replies to the discussion title (with post id as the discussion's"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "0          878.0\n1          878.0\n2          878.0\n3         3623.0\n4          878.0\n          ...   \n3046     56718.0\n3047    558884.0\n3048     56718.0\n3049    558914.0\n3050    558884.0\nName: parent_post_id, Length: 3051, dtype: float64"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"parent_post_id\"] = df.apply(\n",
    "    lambda row: row[\"discussion_id\"] if pd.isna(row[\"parent_post_id\"]) else row[\"parent_post_id\"],\n",
    "    axis=1\n",
    ")\n",
    "df[\"parent_post_id\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### add the first post to the dataframe\n",
    "add the title of the discussion as posts in the discussion, so the conversation parser would add them as records.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'Should guns be banned in America?'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-51-458c09748887>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[0mtitle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdiscussion_title_map\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdiscussion_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 7\u001B[0;31m     \u001B[0mtitle\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtitle\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0misna\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtitle\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      8\u001B[0m     record = {\n\u001B[1;32m      9\u001B[0m         \u001B[0;34m\"discussion_id\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mdiscussion_id\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: invalid literal for int() with base 10: 'Should guns be banned in America?'"
     ]
    }
   ],
   "source": [
    "new_records = []\n",
    "for discussion_id, op in discussion_op_map:\n",
    "    init_text_id = discussion_inittext_map[discussion_id]\n",
    "    init_text_id = int(init_text_id) if not pd.isna(init_text_id) else None\n",
    "\n",
    "    title = discussion_title_map[discussion_id]\n",
    "    title = int(title) if not pd.isna(title) else None\n",
    "    record = {\n",
    "        \"discussion_id\": discussion_id,\n",
    "        \"post_id\": discussion_id,\n",
    "        \"author_id\": op,\n",
    "        \"creation_date\": \"00:00\",\n",
    "        \"parent_post_id\": None,\n",
    "        \"parent_missing\": 0,\n",
    "        \"text_id\": init_text_id,\n",
    "        \"points\": -1,\n",
    "        \"discussion_stance_id\": 0.5,\n",
    "        \"is_rebuttal\": None,\n",
    "        \"title\": title\n",
    "    }\n",
    "    new_records.append(record)\n",
    "\n",
    "df = df.append(new_records, ignore_index=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "      discussion_id  post_id  author_id        creation_date  parent_post_id  \\\n0               878     3557      27083  2008-05-07 23:06:11           878.0   \n1               878     3563       5901  2008-05-08 01:25:25           878.0   \n2               878     3623      11010  2008-05-08 15:03:14           878.0   \n3               878     3627      27083  2008-05-08 15:21:42          3623.0   \n4               878     3632       8705  2008-05-08 15:35:54           878.0   \n...             ...      ...        ...                  ...             ...   \n3046          56718   558884       1488  2014-05-09 05:30:18         56718.0   \n3047          56718   558914       2827  2014-05-09 13:40:52        558884.0   \n3048          56718   558915       2827  2014-05-09 13:41:09         56718.0   \n3049          56718   558927       2496  2014-05-09 16:26:02        558914.0   \n3050          56718   558964      17093  2014-05-10 01:37:37        558884.0   \n\n      parent_missing  text_id  points  discussion_stance_id is_rebuttal  \\\n0                  0   513135      -3                   0.0         NaN   \n1                  0   513160      -8                   0.0         NaN   \n2                  0   513211      11                   1.0         NaN   \n3                  0   513212       8                   0.0    disputed   \n4                  0   513276       4                   1.0         NaN   \n...              ...      ...     ...                   ...         ...   \n3046               0   771300       1                   0.0         NaN   \n3047               0   771301       1                   1.0    disputed   \n3048               0   771304       1                   1.0         NaN   \n3049               0   771302       1                   1.0   supported   \n3050               0   771303       1                   1.0    disputed   \n\n      root_discussion_id  topic                              title  \n0                    878      9  Should guns be banned in America?  \n1                    878      9  Should guns be banned in America?  \n2                    878      9  Should guns be banned in America?  \n3                    878      9  Should guns be banned in America?  \n4                    878      9  Should guns be banned in America?  \n...                  ...    ...                                ...  \n3046               56718      9                        gun control  \n3047               56718      9                        gun control  \n3048               56718      9                        gun control  \n3049               56718      9                        gun control  \n3050               56718      9                        gun control  \n\n[3051 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>discussion_id</th>\n      <th>post_id</th>\n      <th>author_id</th>\n      <th>creation_date</th>\n      <th>parent_post_id</th>\n      <th>parent_missing</th>\n      <th>text_id</th>\n      <th>points</th>\n      <th>discussion_stance_id</th>\n      <th>is_rebuttal</th>\n      <th>root_discussion_id</th>\n      <th>topic</th>\n      <th>title</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>878</td>\n      <td>3557</td>\n      <td>27083</td>\n      <td>2008-05-07 23:06:11</td>\n      <td>878.0</td>\n      <td>0</td>\n      <td>513135</td>\n      <td>-3</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>878</td>\n      <td>9</td>\n      <td>Should guns be banned in America?</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>878</td>\n      <td>3563</td>\n      <td>5901</td>\n      <td>2008-05-08 01:25:25</td>\n      <td>878.0</td>\n      <td>0</td>\n      <td>513160</td>\n      <td>-8</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>878</td>\n      <td>9</td>\n      <td>Should guns be banned in America?</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>878</td>\n      <td>3623</td>\n      <td>11010</td>\n      <td>2008-05-08 15:03:14</td>\n      <td>878.0</td>\n      <td>0</td>\n      <td>513211</td>\n      <td>11</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>878</td>\n      <td>9</td>\n      <td>Should guns be banned in America?</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>878</td>\n      <td>3627</td>\n      <td>27083</td>\n      <td>2008-05-08 15:21:42</td>\n      <td>3623.0</td>\n      <td>0</td>\n      <td>513212</td>\n      <td>8</td>\n      <td>0.0</td>\n      <td>disputed</td>\n      <td>878</td>\n      <td>9</td>\n      <td>Should guns be banned in America?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>878</td>\n      <td>3632</td>\n      <td>8705</td>\n      <td>2008-05-08 15:35:54</td>\n      <td>878.0</td>\n      <td>0</td>\n      <td>513276</td>\n      <td>4</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>878</td>\n      <td>9</td>\n      <td>Should guns be banned in America?</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3046</th>\n      <td>56718</td>\n      <td>558884</td>\n      <td>1488</td>\n      <td>2014-05-09 05:30:18</td>\n      <td>56718.0</td>\n      <td>0</td>\n      <td>771300</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>56718</td>\n      <td>9</td>\n      <td>gun control</td>\n    </tr>\n    <tr>\n      <th>3047</th>\n      <td>56718</td>\n      <td>558914</td>\n      <td>2827</td>\n      <td>2014-05-09 13:40:52</td>\n      <td>558884.0</td>\n      <td>0</td>\n      <td>771301</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>disputed</td>\n      <td>56718</td>\n      <td>9</td>\n      <td>gun control</td>\n    </tr>\n    <tr>\n      <th>3048</th>\n      <td>56718</td>\n      <td>558915</td>\n      <td>2827</td>\n      <td>2014-05-09 13:41:09</td>\n      <td>56718.0</td>\n      <td>0</td>\n      <td>771304</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>NaN</td>\n      <td>56718</td>\n      <td>9</td>\n      <td>gun control</td>\n    </tr>\n    <tr>\n      <th>3049</th>\n      <td>56718</td>\n      <td>558927</td>\n      <td>2496</td>\n      <td>2014-05-09 16:26:02</td>\n      <td>558914.0</td>\n      <td>0</td>\n      <td>771302</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>supported</td>\n      <td>56718</td>\n      <td>9</td>\n      <td>gun control</td>\n    </tr>\n    <tr>\n      <th>3050</th>\n      <td>56718</td>\n      <td>558964</td>\n      <td>17093</td>\n      <td>2014-05-10 01:37:37</td>\n      <td>558884.0</td>\n      <td>0</td>\n      <td>771303</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>disputed</td>\n      <td>56718</td>\n      <td>9</td>\n      <td>gun control</td>\n    </tr>\n  </tbody>\n</table>\n<p>3051 rows × 13 columns</p>\n</div>"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add topic to the df\n",
    "df[\"topic\"] = df.apply(lambda row: discussion_topic_map[row[\"discussion_id\"]], axis=1)\n",
    "df[\"title\"] = df.apply(lambda row: discussion_title_map[row[\"discussion_id\"]], axis=1)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "df.to_csv(\"/Users/ronpick/workspace/zero-shot-stance/data/createdebate/iac-createdebate-subconvs.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "96303317e3b84db88925296716470c85"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "63"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pasre_strategy = {\n",
    "    \"node_id\": \"post_id\",\n",
    "    \"author\": \"author_id\",\n",
    "    \"timestamp\": \"creation_date\",\n",
    "    \"parent_id\": \"parent_post_id\"\n",
    "    }\n",
    "parser = DataFrameConversationReader(pasre_strategy)\n",
    "gb = df.groupby(\"discussion_id\")\n",
    "convs: List[Conversation] = list(tqdm(map(parser.parse, map(itemgetter(1), gb))))\n",
    "len(convs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "74"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_convs = [Conversation(child) for conv in convs for child in conv.root.children]\n",
    "len(sub_convs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# conversation stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n",
      "5.4324324324324325\n",
      "2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": "count    74.000000\nmean      5.432432\nstd       8.810145\nmin       1.000000\n25%       1.000000\n50%       2.000000\n75%       5.750000\nmax      54.000000\ndtype: float64"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sizes = [c.size for c in sub_convs]\n",
    "print(len(sizes))\n",
    "print(np.mean(sizes))\n",
    "print(np.median(sizes))\n",
    "pd.Series(sizes).describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:ylabel='Frequency'>"
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(sizes).plot.hist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filtered_sizes = [s for s in sizes if s >= 10]\n",
    "print(len(filtered_sizes))\n",
    "print(np.mean(filtered_sizes))\n",
    "print(np.median(filtered_sizes))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def decide_stance(self, graph: nx.Graph, cut_nodes: Set[Any], labeled_nodes: Dict[Any, int]) -> int:\n",
    "    \"\"\"\n",
    "    :param labeled_nodes:\n",
    "    :param graph:\n",
    "    :param cut_nodes:\n",
    "    :param weight_field:\n",
    "    :return: return the inferred stance label of the cut nodes.\n",
    "    \"\"\"\n",
    "    if self.op in self.graph.nodes:\n",
    "        pivot_node = self.op\n",
    "    else:\n",
    "        pivot_node = self.__get_ordered_candidates_for_pivot(graph)\n",
    "\n",
    "    cut_nodes_support = pivot_node in cut_nodes\n",
    "    return int(cut_nodes_support)\n",
    "\n",
    "def get_ordered_candidates_for_pivot(graph: nx.Graph, weight_field: str = \"weight\") -> Sequence[Any]:\n",
    "    inv_weight_field = \"inv_weight\"\n",
    "    for _, _, pair_data in graph.edges(data=True):\n",
    "        weight = pair_data.data[weight_field]\n",
    "        pair_data.data[inv_weight_field] = 1 / weight\n",
    "\n",
    "    node_centralities = nx.closeness_centrality(graph, distance=inv_weight_field)\n",
    "    return list(map(itemgetter(0), sorted(node_centralities.items(), key=itemgetter(1), reverse=True)))\n",
    "\n",
    "def get_pivot_node(graph: nx.Graph, labeled_authors: Set[Any], weight_field: str = \"weight\") -> Any:\n",
    "    candidates = get_ordered_candidates_for_pivot(graph, weight_field=weight_field)\n",
    "    return next(iter(filter(labeled_authors.__contains__, candidates)), None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Author labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_majority_vote(labels: List[int]) -> int:\n",
    "    return int(np.mean(labels) >= 0.5)\n",
    "\n",
    "def get_author_labels(c: Conversation) -> Dict[Any, int]:\n",
    "    authors_post_labels = {}\n",
    "    for depth, node in c.iter_conversation():\n",
    "        data = node.data\n",
    "        author = node.author\n",
    "        current_author_labels = authors_post_labels.setdefault(author, [])\n",
    "        current_author_labels.append(data[\"discussion_stance_id\"])\n",
    "\n",
    "    result_labels = {a: get_majority_vote(labels) for a, labels in authors_post_labels.items()}\n",
    "    return result_labels\n",
    "\n",
    "author_labels_per_conversation = {c.id: get_author_labels(c) for c in sub_convs}\n",
    "author_labels_per_conversation = {k: v for k, v in author_labels_per_conversation.items() if len(v) > 0}\n",
    "print(len(author_labels_per_conversation))\n",
    "print(sum(len(v) for v in author_labels_per_conversation.values()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load posts labels (Chang Li)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def load_post_label_mapping(path: str) -> Dict[str, int]:\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def decode_original_post_identification(post_id: str) -> Tuple[str, int, int]:\n",
    "    topic, numeric_id = post_id.split('.')\n",
    "    original_discussion_index = int(numeric_id[:-5])\n",
    "    original_post_index = int(numeric_id[-3:])\n",
    "    return topic, original_discussion_index, original_post_index\n",
    "\n",
    "\n",
    "labels_path = \"/home/dev/data/stance/chang-li/data/compressed-4forum/allPostLabelMap.pickle\"\n",
    "raw_post_labels = load_post_label_mapping(labels_path)\n",
    "post_labels = {itemgetter(1,2)(decode_original_post_identification(raw_post_id)): (stance % 2) for (raw_post_id, stance) in raw_post_labels.items()}\n",
    "len(post_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_author_labels(conv: Conversation) -> Dict[Any, int]:\n",
    "    if conv.id not in author_labels_per_conversation:\n",
    "        return None\n",
    "\n",
    "    return author_labels_per_conversation[conv.id]\n",
    "\n",
    "def get_maxcut_results(graph: InteractionsGraph, op: Any) -> MaxcutStanceClassifier:\n",
    "    maxcut = MaxcutStanceClassifier(weight_field=graph.WEIGHT_FIELD)\n",
    "    maxcut.set_input(graph.graph, op)\n",
    "    maxcut.classify_stance()\n",
    "    return maxcut\n",
    "\n",
    "def get_greedy_results(graph: InteractionsGraph, op: Any) -> BaseStanceClassifier:\n",
    "    clf = MSTStanceClassifier()#weight_field=graph.WEIGHT_FIELD)\n",
    "    clf.set_input(graph.graph)\n",
    "    clf.classify_stance(op)\n",
    "    return clf\n",
    "\n",
    "def get_author_preds(clf: BaseStanceClassifier, pivot: Any) -> Dict[Any, int]:\n",
    "    support_label = authors_labels[pivot]\n",
    "    opposer_label = 1 - support_label\n",
    "    supporters = clf.get_supporters()\n",
    "    opposers = clf.get_complement()\n",
    "    preds = {}\n",
    "    for supporter in supporters:\n",
    "        preds[supporter] = support_label\n",
    "    for opposer in opposers:\n",
    "        preds[opposer] = opposer_label\n",
    "\n",
    "    return preds\n",
    "\n",
    "def align_gs_with_predictions(authors_labels: Dict[Any, int], author_preds: Dict[Any, int]) -> Tuple[List[int], List[int]]:\n",
    "    y_true, y_pred = [], []\n",
    "    for author, true_label in authors_labels.items():\n",
    "        pred = author_preds.get(author, None)\n",
    "        if pred is None: continue\n",
    "\n",
    "        y_true.append(true_label)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "def align_posts_gs_with_predictions(conv: Conversation, author_preds: Dict[Any, int]) -> Tuple[List[int], List[int]]:\n",
    "    y_true, y_pred = [], []\n",
    "    for (_, node) in conv.iter_conversation():\n",
    "        label = node.data[\"discussion_stance_id\"]\n",
    "        if label == 0.5: continue\n",
    "        if pd.isna(label): continue\n",
    "        pred = author_preds.get(node.author, None)\n",
    "        if pred is None: continue\n",
    "\n",
    "        y_true.append(label)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "\n",
    "def predict_for_partition(true: List[int], preds: List[int]) -> Tuple[List[int], List[int]]:\n",
    "    acc = accuracy_score(true, preds)\n",
    "    if acc < 0.5:\n",
    "        preds = [1-l for l in preds]\n",
    "\n",
    "    return true, preds\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interactions_parser = get_reply_interactions_parser()\n",
    "author_true, author_pred = [], []\n",
    "author_true_best, author_pred_best = [], []\n",
    "posts_true, posts_pred = [], []\n",
    "post_true_best, post_pred_best = [], []\n",
    "filtered_convs = []\n",
    "pivot_nodes = []\n",
    "full_graphs = []\n",
    "core_graphs = []\n",
    "maxcut_results: Dict[Any, MaxcutStanceClassifier] = {}\n",
    "classification_results: List[Tuple[List[int], List[int]]] = []\n",
    "empty_core = []\n",
    "unlabeled_conversations = []\n",
    "unlabeled_op = []\n",
    "insufficient_author_labels = []\n",
    "too_small_cut_value = []\n",
    "op_not_in_core = []\n",
    "large_graphs = []\n",
    "\n",
    "def calc_weight(interactions: PairInteractionsData) -> float:\n",
    "    n_replies = interactions[\"replies\"]\n",
    "    # n_quotes = interactions[\"quotes\"]\n",
    "    return n_replies\n",
    "    # return n_quotes\n",
    "\n",
    "\"\"\"abortion = 3\n",
    "   gay marriage = 8\n",
    "   marijuana = 10\n",
    "   obamacare = 15\n",
    "   \"\"\"\n",
    "# convs[0].root.data[\"topic\"]\n",
    "# conv: Conversation\n",
    "relevant_topics = {3,8,10,15}\n",
    "count_conv = 0\n",
    "for i, conv in tqdm(enumerate(sub_convs)):\n",
    "    # topic = conv.root.data[\"topic\"]\n",
    "    # print(topic)\n",
    "    # if topic not in relevant_topics: continue\n",
    "    count_conv += 1\n",
    "    authors_labels = get_author_labels(conv)\n",
    "    if authors_labels is None:\n",
    "        unlabeled_conversations.append(i)\n",
    "        continue\n",
    "\n",
    "    op = conv.root.author\n",
    "    if op not in authors_labels:\n",
    "        unlabeled_op.append(i)\n",
    "        continue\n",
    "\n",
    "    if len(authors_labels) < 3:\n",
    "        insufficient_author_labels.append(i)\n",
    "        continue\n",
    "\n",
    "    interaction_graph = interactions_parser.parse(conv)\n",
    "\n",
    "    interaction_graph.set_interaction_weights(calc_weight)\n",
    "    zero_edges = [(v, u) for v, u, d in interaction_graph.graph.edges(data=True) if d[\"weight\"] == 0]\n",
    "    interaction_graph.graph.remove_edges_from(zero_edges)\n",
    "\n",
    "    pivot_node = get_pivot_node(interaction_graph.graph, authors_labels, weight_field=\"weight\")\n",
    "    clf = get_greedy_results(interaction_graph, pivot_node)\n",
    "\n",
    "    core_interactions = interaction_graph.get_core_interactions()\n",
    "    if core_interactions.graph.size() == 0:\n",
    "        empty_core.append(i)\n",
    "\n",
    "    if core_interactions.graph.size() > 0:\n",
    "        components = list(nx.connected_components(core_interactions.graph))\n",
    "        core_interactions = core_interactions.get_subgraph(components[0])\n",
    "        pivot_node = get_pivot_node(core_interactions.graph, authors_labels, weight_field=\"weight\")\n",
    "        pivot_nodes.append(pivot_node)\n",
    "        maxcut = get_maxcut_results(core_interactions, pivot_node)\n",
    "        if maxcut.cut_value < 3:\n",
    "            too_small_cut_value.append(i)\n",
    "        else:\n",
    "            maxcut_results[conv.id] = maxcut\n",
    "            clf = maxcut\n",
    "\n",
    "    if core_interactions.graph.order() > 120:\n",
    "        large_graphs.append(conv)\n",
    "        continue\n",
    "\n",
    "    authors_preds = get_author_preds(clf, pivot_node)\n",
    "\n",
    "    true, preds = align_gs_with_predictions(authors_labels, authors_preds)\n",
    "    author_true.append(true)\n",
    "    author_pred.append(preds)\n",
    "\n",
    "    true_best, preds_best = predict_for_partition(true, preds)\n",
    "    author_true_best.append(true_best)\n",
    "    author_pred_best.append(preds_best)\n",
    "\n",
    "    true, preds = align_posts_gs_with_predictions(conv, authors_preds)\n",
    "    posts_true.append(true)\n",
    "    posts_pred.append(preds)\n",
    "\n",
    "    true, preds = predict_for_partition(true, preds)\n",
    "    post_true_best.append(true)\n",
    "    post_pred_best.append(preds)\n",
    "\n",
    "    filtered_convs.append(conv)\n",
    "    full_graphs.append(interaction_graph)\n",
    "    core_graphs.append(core_interactions)\n",
    "    classification_results.append((true, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"total number of conversations (in all topics): {len(sub_convs)}\")\n",
    "print(f\"total number of conversations (in the relevant topics): {count_conv}\")\n",
    "print(f\"total number of conversations with labeled authors (in all topics): {len(author_labels_per_conversation)}\")\n",
    "print(f\"total number of conversations with labeled authors (in the relevant topics): {count_conv - len(unlabeled_conversations)}\")\n",
    "\n",
    "print(f\"number of conversations in eval: {len(filtered_convs)}\")\n",
    "labeled_authors = sum(len(v) for v in author_labels_per_conversation.values())\n",
    "print(f\"total number of labeled authors: {labeled_authors}\")\n",
    "print(f\"number of authors in eval: {sum(map(len, author_true))}\")\n",
    "print(f\"number of posts in eval: {sum(map(len, posts_true))}\")\n",
    "print(\"=========\")\n",
    "print(f\"number of conversations with empty core: {len(empty_core)}\")\n",
    "print(f\"number of conversations with op not in core: {len(op_not_in_core)}\")\n",
    "print(f\"number of conversations with too large core: {len(large_graphs)}\")\n",
    "print(f\"number of conversations with too small cut value: {len(too_small_cut_value)}\")\n",
    "print(f\"number of unlabeled conversations: {len(unlabeled_conversations)}\")\n",
    "print(f\"number of conversations with unlabeled op: {len(unlabeled_op)}\")\n",
    "print(f\"number of conversations with insufficient labeled authors: {len(insufficient_author_labels)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# i, size = not_in_core_sorted[20]\n",
    "# print(\"index\", i)\n",
    "# \"size\", size"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# c = sub_convs[i]\n",
    "# print(c.op)\n",
    "# ig = interactions_parser.parse(c)\n",
    "# ig.set_interaction_weights(calc_weight)\n",
    "# pos = nx.spring_layout(ig.graph, seed=19191)\n",
    "# nx.draw_networkx(ig.graph, pos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sorted(nx.closeness_centrality(ig.graph, distance=\"replies\").items(), key=itemgetter(1), reverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# core = ig.get_core_interactions()\n",
    "# pos = nx.spring_layout(core.graph, seed=19191)\n",
    "# nx.draw_networkx(core.graph, pos)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# nx.closeness_centrality(core.graph, distance=\"weight\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# labeled_authors = author_labels_per_conversation[c.id].keys()\n",
    "# get_pivot_node(core.graph, labeled_authors, weight_field=\"weight\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# list(core.graph.edges(data=True))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true = list(chain(*author_true))\n",
    "y_pred = list(chain(*author_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_true = list(chain(*author_true_best))\n",
    "y_pred = list(chain(*author_pred_best))\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = [l%2 for l in list(chain(*posts_true))]\n",
    "y_true = list(chain(*posts_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = [l%2 for l in list(chain(*post_true_best))]\n",
    "y_true = list(chain(*post_pred_best))\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_pairs_average_distance(\n",
    "        pairs: Iterable[Tuple[int, int]],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    distances = list(starmap(lambda i, j: cosine(embeddings[i], embeddings[j]), pairs))\n",
    "    return float(np.mean(distances))\n",
    "\n",
    "\n",
    "def compute_average_angle_from_node(\n",
    "        node_index: int,\n",
    "        group_indices: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = ((node_index, i) for i in group_indices)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)\n",
    "\n",
    "\n",
    "def compute_group_average_angle(\n",
    "        group_indices: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = combinations(group_indices, 2)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)\n",
    "\n",
    "\n",
    "def compute_cross_groups_average_angle(\n",
    "        group1: Sequence[int],\n",
    "        group2: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = product(group1, group2)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "supporters_avg_angles = []\n",
    "opposers_avg_angles = []\n",
    "mean_cross_angle = []\n",
    "op2supporters = []\n",
    "op2opposers = []\n",
    "for i in range(len(maxcut_results)):\n",
    "    maxcut = maxcut_results[i]\n",
    "    op, all_embeddings, supporters, opposers =\\\n",
    "        maxcut.op, maxcut.embeddings, maxcut.get_supporters(), maxcut.get_complement()\n",
    "\n",
    "    op2supporters.append(compute_average_angle_from_node(op, supporters, all_embeddings))\n",
    "    op2opposers.append(compute_average_angle_from_node(op, opposers, all_embeddings))\n",
    "\n",
    "    supporters_avg_angles.append(compute_group_average_angle(supporters, all_embeddings))\n",
    "    opposers_avg_angles.append(compute_group_average_angle(opposers, all_embeddings))\n",
    "\n",
    "    mean_cross_angle.append(compute_cross_groups_average_angle(supporters, opposers, all_embeddings))\n",
    "\n",
    "print(f\"total conversations {len(maxcut_results)}\")\n",
    "print(f\"supporters avg. cosine {np.nanmean(supporters_avg_angles)}\")\n",
    "print(f\"opposers avg. cosine {np.nanmean(opposers_avg_angles)}\")\n",
    "print(f\"cross groups avg. cosine {np.mean(mean_cross_angle)}\")\n",
    "print(f\"op to supporters avg. cosine {np.mean(op2supporters)}\")\n",
    "print(f\"op to opposers avg. cosine {np.mean(op2opposers)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "strong_convs_indices = []\n",
    "for i in range(len(filtered_convs)):\n",
    "    op2s = op2supporters[i]\n",
    "    op2o = op2opposers[i]\n",
    "    if op2supporters[i] * op2opposers[i] == 0:\n",
    "        continue\n",
    "\n",
    "    diff = op2o - op2s\n",
    "    ratio = op2o / op2s\n",
    "    if (ratio > 2) and (diff > 1):\n",
    "        strong_convs_indices.append(i)\n",
    "\n",
    "len(strong_convs_indices)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# strong_true, strong_preds = zip(*[classification_results[i] for i in strong_convs_indices])\n",
    "# strong_true = list(chain(*strong_true))\n",
    "# strong_preds = list(chain(*strong_preds))\n",
    "strong_true = list(chain(*[author_true_best[i] for i in strong_convs_indices]))\n",
    "strong_preds = list(chain(*[author_pred_best[i] for i in strong_convs_indices]))\n",
    "print(classification_report(strong_true, strong_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_i = 0\n",
    "max_shape = 0\n",
    "# sizes = [(i, g.graph.order()) for i, g  in enumerate(core_graphs)]\n",
    "sizes = [(i, core_graphs[i].graph.order()) for i in range(len(filtered_convs))]\n",
    "sorted_sized = sorted(sizes, key=itemgetter(1), reverse=True)\n",
    "sorted_sized[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_index = 0\n",
    "\n",
    "maxcut = maxcut_results[result_index]\n",
    "op, emb, supporters, opposers = maxcut.op, maxcut.embeddings, maxcut.get_supporters(), maxcut.get_complement()\n",
    "\n",
    "s_cosine = compute_group_average_angle(supporters, emb)\n",
    "o_cosine = compute_group_average_angle(opposers, emb)\n",
    "cross_cosine = compute_cross_groups_average_angle(supporters, opposers, emb)\n",
    "op2support = compute_average_angle_from_node(op, supporters, emb)\n",
    "op2oppose = compute_average_angle_from_node(op, opposers, emb)\n",
    "print(f\"num supporters: {len(supporters)}\")\n",
    "print(f\"num opposers: {len(opposers)}\")\n",
    "print(f\"supporters avg. cosine: {s_cosine}\")\n",
    "print(f\"opposers avg. cosine: {o_cosine}\")\n",
    "print(f\"cross-groups avg. cosine: {cross_cosine}\")\n",
    "print(f\"op <-> supporters avg. cosine: {op2support}\")\n",
    "print(f\"op <-> opposers avg. cosine: {op2oppose}\")\n",
    "print(f\"supporters - opposers diff cosine with op: {op2oppose - op2support}\")\n",
    "print(f\"supporters - opposers ratio cosine with op: {op2oppose / op2support}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Author classification results\n",
    "For the current conversation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true = author_true[result_index]\n",
    "preds = author_pred[result_index]\n",
    "print(classification_report(true, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true = author_true_best[result_index]\n",
    "preds = author_pred_best[result_index]\n",
    "print(classification_report(true, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Post classification results\n",
    "For the current conversation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true = posts_true[result_index]\n",
    "preds = posts_pred[result_index]\n",
    "print(classification_report(true, preds))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Post partition classification results\n",
    "For the current conversation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true = post_true_best[result_index]\n",
    "preds = post_pred_best[result_index]\n",
    "print(classification_report(true, preds))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv = filtered_convs[result_index]\n",
    "author_labels = get_author_labels(conv)\n",
    "true_supporters = [n for n, l in author_labels.items() if l == 1]\n",
    "true_opposers = [n for n, l in author_labels.items() if l == 0]\n",
    "unknown_labels = set(author_labels.keys()) - (set(supporters) | set(opposers))\n",
    "len(author_labels), len(true_opposers), len(true_supporters), len(unknown_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "\n",
    "X = np.vstack([np.array(x) for x in emb.values()])\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "# X_2d = TSNE(n_components=2).fit_transform(X)\n",
    "print(pca.explained_variance_)\n",
    "op = maxcut.op\n",
    "nodes = emb.keys()\n",
    "tp_supporters_indices = [i for i, n in enumerate(nodes) if n in true_supporters and n in supporters]\n",
    "fn_supporters_indices = [i for i, n in enumerate(nodes) if n in true_supporters and n in opposers]\n",
    "tp_opposers_indices = [i for i, n in enumerate(nodes) if n in true_opposers and n in opposers]\n",
    "fn_opposers_indices = [i for i, n in enumerate(nodes) if n in true_opposers and n in supporters]\n",
    "unlabeled_supporters = [i for i, n in enumerate(nodes) if n not in author_labels and n in supporters]\n",
    "unlabeled_opposers = [i for i, n in enumerate(nodes) if n not in author_labels and n in opposers]\n",
    "\n",
    "op_index = [i for i, n in enumerate(nodes) if n == op]\n",
    "\n",
    "plt.scatter(X_2d[tp_supporters_indices, 0], X_2d[tp_supporters_indices, 1], color='g', marker='+')\n",
    "plt.scatter(X_2d[fn_supporters_indices, 0], X_2d[fn_supporters_indices, 1], color='g', marker='x')\n",
    "plt.scatter(X_2d[tp_opposers_indices, 0], X_2d[tp_opposers_indices, 1], color='r', marker='+')\n",
    "plt.scatter(X_2d[fn_opposers_indices, 0], X_2d[fn_opposers_indices, 1], color='r', marker='x')\n",
    "plt.scatter(X_2d[unlabeled_supporters, 0], X_2d[unlabeled_supporters, 1], color='grey', marker='+')\n",
    "plt.scatter(X_2d[unlabeled_opposers, 0], X_2d[unlabeled_opposers, 1], color='grey', marker='x')\n",
    "plt.scatter([X_2d[op_index, 0]], [X_2d[op_index, 1]], color='b', marker='o')\n",
    "\n",
    "# colors = ['b' if i == op else 'g' if i in supporters else 'r' for i in nodes]\n",
    "# markers = ['o' if i ==op else 'x' if i in supporters else '+' for i in nodes]\n",
    "# plt.scatter(X_2d[:, 0], X_2d[:, 1], color=colors)\n",
    "# op_index = [i for i, n  in enumerate(nodes) if n == op][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_figure()\n",
    "graph = maxcut.graph\n",
    "pos = nx.spring_layout(graph)\n",
    "\n",
    "all_nodes = list(nodes)\n",
    "tps = [all_nodes[i] for i in tp_supporters_indices]\n",
    "fns = [all_nodes[i] for i in fn_supporters_indices]\n",
    "fno = [all_nodes[i] for i in fn_opposers_indices]\n",
    "tpo = [all_nodes[i] for i in tp_opposers_indices]\n",
    "unks = [all_nodes[i] for i in unlabeled_supporters]\n",
    "unko = [all_nodes[i] for i in unlabeled_opposers]\n",
    "op = [all_nodes[i] for i in op_index]\n",
    "\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=tps, node_color='g', node_shape='s', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=fns, node_color='g', node_shape='^', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=fno, node_color='r', node_shape='s', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=tpo, node_color='r', node_shape='^', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=unks, node_color='grey', node_shape=\"s\", edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=unko, node_color='grey', node_shape=\"^\", edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=op, node_color='b', node_shape='o', edgecolors=\"black\")\n",
    "\n",
    "node_labels = {n: str(n) for n in graph.nodes}\n",
    "nx.draw_networkx_labels(graph, pos, labels=node_labels, font_color=\"tab:brown\")\n",
    "\n",
    "# Draw the edges that are in the cut.\n",
    "edge_weights = [np.log2(graph[e[0]][e[1]]['weight']) for e in maxcut.cut]\n",
    "nx.draw_networkx_edges(graph, pos, edgelist=maxcut.cut, edge_color=\"black\", width=edge_weights)\n",
    "#\n",
    "# # Draw the edges that are not in the cut\n",
    "leave = [e for e in graph.edges if e not in maxcut.cut]\n",
    "non_cut_weigths = [np.log2(graph[e[0]][e[1]]['weight']) for e in leave]\n",
    "nx.draw_networkx_edges(graph, pos, edgelist=leave, edge_color=\"darkgray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "conv_id = filtered_convs[result_index].id\n",
    "author_labels = author_labels_per_conversation[conv_id]\n",
    "print(author_labels)\n",
    "maxcut.draw(true_labels=author_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_graph = full_graphs[result_index]\n",
    "layout = nx.spring_layout(full_graph.graph)\n",
    "nx.draw(full_graph.graph, layout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kcore = core_graphs[result_index]\n",
    "layout = nx.spring_layout(kcore.graph)\n",
    "nx.draw(kcore.graph, layout)\n",
    "\n",
    "kcore.graph.order()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "## Predicting posts labels\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}