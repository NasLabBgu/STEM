{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from stance_classification.draw_utils import new_figure\n",
    "%matplotlib inline\n",
    "\n",
    "import csv\n",
    "from itertools import combinations, starmap, groupby, product, chain, islice\n",
    "from itertools import groupby, chain, product, starmap\n",
    "from operator import itemgetter\n",
    "from typing import Any, List, Sequence\n",
    "import logging\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from conversant.interactions import InteractionsGraph\n",
    "from conversant.interactions.interactions_graph import PairInteractionsData\n",
    "from stance_classification.classifiers.maxcut_stance_classifier import MaxcutStanceClassifier\n",
    "from stance_classification.user_interaction.cmv_stance_interactions_graph_builder import CMVStanceBasedInteractionGraphBuilder\n",
    "logging.basicConfig()\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "from conversant.conversation.examples.controversial_feature_extraction import *\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded total of 16306\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=16306.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d1395df89904034ba7f9f91619c3e8e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trees_file_path = '/home/dev/data/stance/cmv/trees_2.0.txt'\n",
    "total_trees = sum(1 for _ in iter_trees_from_lines(trees_file_path))\n",
    "\n",
    "print(f'loaded total of {total_trees}')\n",
    "\n",
    "trees = tqdm(iter_trees_from_lines(trees_file_path), total=total_trees)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def load_labels(path) -> Dict[Tuple[str, str], bool]:\n",
    "    with open(path, 'r') as labels_f:\n",
    "        reader = csv.reader(labels_f)\n",
    "        next(reader) # skip header\n",
    "        nodes_labels_mapping = {tuple(record[0: 2]): bool(1 + int(record[2])) for record in reader if int(record[2]) != 0}\n",
    "        return nodes_labels_mapping"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "16306"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_reader = CMVConversationReader()\n",
    "conversations = list(map(conv_reader.parse, trees))\n",
    "len(conversations)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "convs = conversations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "25536"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "336 * 19 * 4"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "152\n"
     ]
    }
   ],
   "source": [
    "# labeled_trees_path = \"/home/<user>/data/bgu/labeled/61019_notcut_trees.txt\"\n",
    "author_labels = load_labels(\"/home/dev/data/stance/cmv/stance-gs-extended.csv\")\n",
    "# author_labels = load_labels(\"/home/dev/data/stance/cmv/stance-mturk-gs-v1.7.0.csv\")\n",
    "author_labels = sorted([(r[0][0], r[0][1], r[1]) for r in author_labels.items()], key=itemgetter(0, 1))\n",
    "\n",
    "def create_author_labels_dict(records: Iterable[Tuple[str, str, str]]) -> Dict[Any, int]:\n",
    "    return {r[1]: r[2] for r in records}\n",
    "\n",
    "author_labels_per_conversation = {cid: create_author_labels_dict(records) for cid, records in groupby(author_labels, key=lambda r: r[0])}\n",
    "author_labels_per_conversation = {k: v for k, v in author_labels_per_conversation.items() if len(v) > 0}\n",
    "print(len(author_labels_per_conversation))\n",
    "print(sum(len(v) for v in author_labels_per_conversation.values()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# author_labels_per_conversation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def get_author_labels(conv: Conversation) -> Dict[Any, int]:\n",
    "    if conv.id not in author_labels_per_conversation:\n",
    "        return None\n",
    "\n",
    "    return author_labels_per_conversation[conv.id]\n",
    "\n",
    "def get_maxcut_results(graph: InteractionsGraph, op: Any) -> MaxcutStanceClassifier:\n",
    "    maxcut = MaxcutStanceClassifier(weight_field=graph.WEIGHT_FIELD)\n",
    "    maxcut.set_input(graph.graph)\n",
    "    maxcut.classify_stance(op)\n",
    "    return maxcut\n",
    "\n",
    "def align_gs_with_predictions(maxcut: MaxcutStanceClassifier, authors_labels: Dict[Any, int]) -> Tuple[List[int], List[int]]:\n",
    "    support_label = 1\n",
    "    opposer_label = 0\n",
    "    supporters = maxcut.get_supporters()\n",
    "    opposers = maxcut.get_complement()\n",
    "\n",
    "    y_true, y_pred = [], []\n",
    "    for supporter in supporters:\n",
    "        true_label = authors_labels.get(supporter)\n",
    "        if true_label is not None:\n",
    "            y_true.append(true_label)\n",
    "            y_pred.append(support_label)\n",
    "\n",
    "    for opposer in opposers:\n",
    "        true_label = authors_labels.get(opposer)\n",
    "        if true_label is not None:\n",
    "            y_true.append(true_label)\n",
    "            y_pred.append(opposer_label)\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "def predict_for_partition(true: List[int], preds: List[int]) -> Tuple[List[int], List[int]]:\n",
    "    acc = accuracy_score(true, preds)\n",
    "    if acc < 0.5:\n",
    "        preds = [1-l for l in preds]\n",
    "\n",
    "    return true, preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=16306.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f380104635e4c1d8ec3bc1f84e1fe94"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "interactions_parser = CMVStanceBasedInteractionGraphBuilder()\n",
    "author_true, author_pred = [], []\n",
    "author_true_partition, author_pred_partition = [], []\n",
    "posts_true, posts_pred = [], []\n",
    "post_true_partition, post_pred_partition = [], []\n",
    "filtered_convs = []\n",
    "full_graphs = []\n",
    "core_graphs = []\n",
    "maxcut_results: List[MaxcutStanceClassifier] = []\n",
    "classification_results: List[Tuple[List[int], List[int]]] = []\n",
    "empty_core = []\n",
    "unlabeled_conversations = []\n",
    "unlabeled_op = []\n",
    "insufficient_author_labels = []\n",
    "too_small_cut_value = []\n",
    "op_not_in_core = []\n",
    "large_graphs = []\n",
    "\n",
    "def calc_weight(interactions: PairInteractionsData) -> float:\n",
    "    n_replies = interactions[\"replies\"]\n",
    "    n_quotes = interactions[\"quotes\"]\n",
    "    n_deltas = interactions[\"deltas\"]\n",
    "    # return n_replies + n_quotes\n",
    "    return n_replies + n_quotes + n_deltas\n",
    "\n",
    "# \"\"\"abortion = 3\n",
    "#    evolution = 7\n",
    "#    gay marriage = 8\n",
    "#    gun control = 9\n",
    "#    \"\"\"\n",
    "# convs[0].root.data[\"topic\"]\n",
    "# conv: Conversation\n",
    "for conv in tqdm(convs):\n",
    "    # topic = conv.root.data[\"topic\"]\n",
    "    # if topic != 9: continue\n",
    "    authors_labels = get_author_labels(conv)\n",
    "    if authors_labels is None:\n",
    "        unlabeled_conversations.append(conv)\n",
    "        continue\n",
    "\n",
    "    op = conv.root.author\n",
    "    # if op not in authors_labels:\n",
    "    #     unlabeled_op.append(conv)\n",
    "    #     continue\n",
    "\n",
    "    if len(authors_labels) < 3:\n",
    "        insufficient_author_labels.append(conv)\n",
    "        continue\n",
    "\n",
    "    interaction_graph = interactions_parser.build(conv)\n",
    "\n",
    "    interaction_graph.set_interaction_weights(calc_weight)\n",
    "    zero_edges = [(v, u) for v, u, d in interaction_graph.graph.edges(data=True) if d[\"weight\"] == 0]\n",
    "    interaction_graph.graph.remove_edges_from(zero_edges)\n",
    "\n",
    "    core_interactions = interaction_graph.get_core_interactions()\n",
    "    if op not in core_interactions.graph.nodes:\n",
    "        op_not_in_core.append(conv)\n",
    "        continue\n",
    "\n",
    "    core_interactions = core_interactions.get_op_connected_components()\n",
    "    if core_interactions.graph.size() < 2:\n",
    "            empty_core.append(conv)\n",
    "            continue\n",
    "\n",
    "    # if core_interactions.graph.order() > 120:\n",
    "    #     large_graphs.append(conv)\n",
    "    #     continue\n",
    "\n",
    "    maxcut = get_maxcut_results(core_interactions, op)\n",
    "    if maxcut.cut_value < 3:\n",
    "        too_small_cut_value.append(conv)\n",
    "        continue\n",
    "\n",
    "    true, preds = align_gs_with_predictions(maxcut, authors_labels)\n",
    "    author_true.append(true)\n",
    "    author_pred.append(preds)\n",
    "\n",
    "    true, preds = predict_for_partition(true, preds)\n",
    "    author_true_partition.append(true)\n",
    "    author_pred_partition.append(preds)\n",
    "\n",
    "    # true, preds = predict_post_labels(conv, post_labels, maxcut.get_supporters(), maxcut.get_complement())\n",
    "    # posts_true.append(true)\n",
    "    # posts_pred.append(preds)\n",
    "\n",
    "    # true, preds = predict_for_partition(true, preds)\n",
    "    # post_true_partition.append(true)\n",
    "    # post_pred_partition.append(preds)\n",
    "\n",
    "    filtered_convs.append(conv)\n",
    "    full_graphs.append(interaction_graph)\n",
    "    core_graphs.append(core_interactions)\n",
    "    maxcut_results.append(maxcut)\n",
    "    classification_results.append((true, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of conversations: 16306\n",
      "total number of conversations with labeled authors: 13\n",
      "number of conversations in eval: 13\n",
      "total number of labeled authors: 152\n",
      "number of authors in eval: 143\n",
      "number of posts in eval: 0\n",
      "=========\n",
      "number of conversations with empty core: 0\n",
      "number of conversations with op not in core: 0\n",
      "number of conversations with too large core: 0\n",
      "number of conversations with too small cut value: 0\n",
      "number of unlabeled conversations: 16293\n",
      "number of conversations with unlabeled op: 0\n",
      "number of conversations with insufficient labeled authors: 0\n"
     ]
    }
   ],
   "source": [
    "print(f\"total number of conversations: {len(convs)}\")\n",
    "print(f\"total number of conversations with labeled authors: {len(author_labels_per_conversation)}\")\n",
    "print(f\"number of conversations in eval: {len(filtered_convs)}\")\n",
    "labeled_authors = sum(len(v) for v in author_labels_per_conversation.values())\n",
    "print(f\"total number of labeled authors: {labeled_authors}\")\n",
    "print(f\"number of authors in eval: {sum(map(len, author_true))}\")\n",
    "print(f\"number of posts in eval: {sum(map(len, posts_true))}\")\n",
    "print(\"=========\")\n",
    "print(f\"number of conversations with empty core: {len(empty_core)}\")\n",
    "print(f\"number of conversations with op not in core: {len(op_not_in_core)}\")\n",
    "print(f\"number of conversations with too large core: {len(large_graphs)}\")\n",
    "print(f\"number of conversations with too small cut value: {len(too_small_cut_value)}\")\n",
    "print(f\"number of unlabeled conversations: {len(unlabeled_conversations)}\")\n",
    "print(f\"number of conversations with unlabeled op: {len(unlabeled_op)}\")\n",
    "print(f\"number of conversations with insufficient labeled authors: {len(insufficient_author_labels)}\")\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.79      0.75        67\n",
      "        True       0.63      0.53      0.58        45\n",
      "\n",
      "    accuracy                           0.69       112\n",
      "   macro avg       0.67      0.66      0.67       112\n",
      "weighted avg       0.68      0.69      0.68       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = list(chain(*author_true))\n",
    "y_pred = list(chain(*author_pred))\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.72      0.79      0.75        67\n",
      "        True       0.63      0.53      0.58        45\n",
      "\n",
      "    accuracy                           0.69       112\n",
      "   macro avg       0.67      0.66      0.67       112\n",
      "weighted avg       0.68      0.69      0.68       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_true = list(chain(*author_true_partition))\n",
    "y_pred = list(chain(*author_pred_partition))\n",
    "print(classification_report(y_true, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "\n",
    "def compute_pairs_average_distance(\n",
    "        pairs: Iterable[Tuple[int, int]],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    distances = list(starmap(lambda i, j: cosine(embeddings[i], embeddings[j]), pairs))\n",
    "    return float(np.mean(distances))\n",
    "\n",
    "\n",
    "def compute_average_angle_from_node(\n",
    "        node_index: int,\n",
    "        group_indices: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = ((node_index, i) for i in group_indices)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)\n",
    "\n",
    "\n",
    "def compute_group_average_angle(\n",
    "        group_indices: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = combinations(group_indices, 2)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)\n",
    "\n",
    "\n",
    "def compute_cross_groups_average_angle(\n",
    "        group1: Sequence[int],\n",
    "        group2: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = product(group1, group2)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "supporters_avg_angles = []\n",
    "opposers_avg_angles = []\n",
    "mean_cross_angle = []\n",
    "op2supporters = []\n",
    "op2opposers = []\n",
    "for i in range(len(maxcut_results)):\n",
    "    maxcut = maxcut_results[i]\n",
    "    op, all_embeddings, supporters, opposers =\\\n",
    "        maxcut.op, maxcut.embeddings, maxcut.get_supporters(), maxcut.get_complement()\n",
    "\n",
    "    op2supporters.append(compute_average_angle_from_node(op, supporters, all_embeddings))\n",
    "    op2opposers.append(compute_average_angle_from_node(op, opposers, all_embeddings))\n",
    "\n",
    "    supporters_avg_angles.append(compute_group_average_angle(supporters, all_embeddings))\n",
    "    opposers_avg_angles.append(compute_group_average_angle(opposers, all_embeddings))\n",
    "\n",
    "    mean_cross_angle.append(compute_cross_groups_average_angle(supporters, opposers, all_embeddings))\n",
    "\n",
    "print(f\"total conversations {len(maxcut_results)}\")\n",
    "print(f\"supporters avg. cosine {np.nanmean(supporters_avg_angles)}\")\n",
    "print(f\"opposers avg. cosine {np.nanmean(opposers_avg_angles)}\")\n",
    "print(f\"cross groups avg. cosine {np.mean(mean_cross_angle)}\")\n",
    "print(f\"op to supporters avg. cosine {np.mean(op2supporters)}\")\n",
    "print(f\"op to opposers avg. cosine {np.mean(op2opposers)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "strong_convs_indices = []\n",
    "for i in range(len(filtered_convs)):\n",
    "    op2s = op2supporters[i]\n",
    "    op2o = op2opposers[i]\n",
    "    if op2supporters[i] * op2opposers[i] == 0:\n",
    "        continue\n",
    "\n",
    "    diff = op2o - op2s\n",
    "    ratio = op2o / op2s\n",
    "    if (ratio > 2) and (diff > 1):\n",
    "        strong_convs_indices.append(i)\n",
    "\n",
    "len(strong_convs_indices)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# strong_true, strong_preds = zip(*[classification_results[i] for i in strong_convs_indices])\n",
    "# strong_true = list(chain(*strong_true))\n",
    "# strong_preds = list(chain(*strong_preds))\n",
    "strong_true = list(chain(*[author_true[i] for i in strong_convs_indices]))\n",
    "strong_preds = list(chain(*[author_pred[i] for i in strong_convs_indices]))\n",
    "print(classification_report(strong_true, strong_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_i = 0\n",
    "max_shape = 0\n",
    "# sizes = [(i, g.graph.order()) for i, g  in enumerate(core_graphs)]\n",
    "sizes = [(i, core_graphs[i].graph.order()) for i in strong_convs_indices]\n",
    "sorted_sized = sorted(sizes, key=itemgetter(1), reverse=True)\n",
    "sorted_sized[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "strong_convs_indices"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_index = 0\n",
    "\n",
    "maxcut = maxcut_results[result_index]\n",
    "op, emb, supporters, opposers = maxcut.op, maxcut.embeddings, maxcut.get_supporters(), maxcut.get_complement()\n",
    "\n",
    "s_cosine = compute_group_average_angle(supporters, emb)\n",
    "o_cosine = compute_group_average_angle(opposers, emb)\n",
    "cross_cosine = compute_cross_groups_average_angle(supporters, opposers, emb)\n",
    "op2support = compute_average_angle_from_node(op, supporters, emb)\n",
    "op2oppose = compute_average_angle_from_node(op, opposers, emb)\n",
    "print(f\"num supporters: {len(supporters)}\")\n",
    "print(f\"num opposers: {len(opposers)}\")\n",
    "print(f\"supporters avg. cosine: {s_cosine}\")\n",
    "print(f\"opposers avg. cosine: {o_cosine}\")\n",
    "print(f\"cross-groups avg. cosine: {cross_cosine}\")\n",
    "print(f\"op <-> supporters avg. cosine: {op2support}\")\n",
    "print(f\"op <-> opposers avg. cosine: {op2oppose}\")\n",
    "print(f\"supporters - opposers diff cosine with op: {op2oppose - op2support}\")\n",
    "print(f\"supporters - opposers ratio cosine with op: {op2oppose / op2support}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Author classification results\n",
    "For the current conversation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true = author_true[result_index]\n",
    "preds = author_pred[result_index]\n",
    "print(classification_report(true, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Post classification results\n",
    "For the current conversation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# true = posts_true[result_index]\n",
    "# preds = posts_pred[result_index]\n",
    "# print(classification_report(true, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Post partition classification results\n",
    "For the current conversation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# true = post_true_partition[result_index]\n",
    "# preds = post_pred_partition[result_index]\n",
    "# print(classification_report(true, preds))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv = filtered_convs[result_index]\n",
    "author_labels = get_author_labels(conv)\n",
    "true_supporters = [n for n, l in author_labels.items() if l == 1]\n",
    "true_opposers = [n for n, l in author_labels.items() if l == 0]\n",
    "unknown_labels = set(author_labels.keys()) - (set(supporters) | set(opposers))\n",
    "len(author_labels), len(true_opposers), len(true_supporters), len(unknown_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "\n",
    "X = np.vstack([np.array(x) for x in emb.values()])\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "# X_2d = TSNE(n_components=2).fit_transform(X)\n",
    "print(pca.explained_variance_)\n",
    "op = maxcut.op\n",
    "nodes = emb.keys()\n",
    "tp_supporters_indices = [i for i, n in enumerate(nodes) if n in true_supporters and n in supporters]\n",
    "fn_supporters_indices = [i for i, n in enumerate(nodes) if n in true_supporters and n in opposers]\n",
    "tp_opposers_indices = [i for i, n in enumerate(nodes) if n in true_opposers and n in opposers]\n",
    "fn_opposers_indices = [i for i, n in enumerate(nodes) if n in true_opposers and n in supporters]\n",
    "unlabeled_supporters = [i for i, n in enumerate(nodes) if n not in author_labels and n in supporters]\n",
    "unlabeled_opposers = [i for i, n in enumerate(nodes) if n not in author_labels and n in opposers]\n",
    "\n",
    "op_index = [i for i, n in enumerate(nodes) if n == op]\n",
    "\n",
    "plt.scatter(X_2d[tp_supporters_indices, 0], X_2d[tp_supporters_indices, 1], color='g', marker='+')\n",
    "plt.scatter(X_2d[fn_supporters_indices, 0], X_2d[fn_supporters_indices, 1], color='r', marker='+')\n",
    "plt.scatter(X_2d[tp_opposers_indices, 0], X_2d[tp_opposers_indices, 1], color='r', marker='x')\n",
    "plt.scatter(X_2d[fn_opposers_indices, 0], X_2d[fn_opposers_indices, 1], color='g', marker='x')\n",
    "plt.scatter(X_2d[unlabeled_supporters, 0], X_2d[unlabeled_supporters, 1], color='g', marker='_')\n",
    "plt.scatter(X_2d[unlabeled_opposers, 0], X_2d[unlabeled_opposers, 1], color='r', marker='_')\n",
    "plt.scatter([X_2d[op_index, 0]], [X_2d[op_index, 1]], color='b', marker='o')\n",
    "\n",
    "# colors = ['b' if i == op else 'g' if i in supporters else 'r' for i in nodes]\n",
    "# markers = ['o' if i ==op else 'x' if i in supporters else '+' for i in nodes]\n",
    "# plt.scatter(X_2d[:, 0], X_2d[:, 1], color=colors)\n",
    "# op_index = [i for i, n  in enumerate(nodes) if n == op][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_figure()\n",
    "graph = maxcut.graph\n",
    "pos = nx.spring_layout(graph)\n",
    "\n",
    "all_nodes = list(nodes)\n",
    "tps = [all_nodes[i] for i in tp_supporters_indices]\n",
    "fns = [all_nodes[i] for i in fn_supporters_indices]\n",
    "fno = [all_nodes[i] for i in fn_opposers_indices]\n",
    "tpo = [all_nodes[i] for i in tp_opposers_indices]\n",
    "unks = [all_nodes[i] for i in unlabeled_supporters]\n",
    "unko = [all_nodes[i] for i in unlabeled_opposers]\n",
    "op = [all_nodes[i] for i in op_index]\n",
    "\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=tps, node_color='g', node_shape='s', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=fns, node_color='g', node_shape='^', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=fno, node_color='r', node_shape='s', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=tpo, node_color='r', node_shape='^', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=unks, node_color='grey', node_shape=\"s\", edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=unko, node_color='grey', node_shape=\"^\", edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=op, node_color='b', node_shape='o', edgecolors=\"black\")\n",
    "\n",
    "node_labels = {n: str(n) for n in graph.nodes}\n",
    "nx.draw_networkx_labels(graph, pos, labels=node_labels, font_color=\"tab:brown\")\n",
    "\n",
    "# Draw the edges that are in the cut.\n",
    "edge_weights = [np.log2(graph[e[0]][e[1]]['weight']) for e in maxcut.cut]\n",
    "nx.draw_networkx_edges(graph, pos, edgelist=maxcut.cut, edge_color=\"black\", width=edge_weights)\n",
    "#\n",
    "# # Draw the edges that are not in the cut\n",
    "leave = [e for e in graph.edges if e not in maxcut.cut]\n",
    "non_cut_weigths = [np.log2(graph[e[0]][e[1]]['weight']) for e in leave]\n",
    "nx.draw_networkx_edges(graph, pos, edgelist=leave, edge_color=\"darkgray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv_id = filtered_convs[result_index].id\n",
    "author_labels = author_labels_per_conversation[conv_id]\n",
    "print(author_labels)\n",
    "maxcut.draw(true_labels=author_labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}