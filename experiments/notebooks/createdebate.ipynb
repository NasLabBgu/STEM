{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from typing import List, Any, Dict, Tuple, Set, Iterable, Sequence\n",
    "from operator import itemgetter\n",
    "from itertools import combinations, starmap, groupby, product, chain, islice, takewhile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine\n",
    "import networkx as nx\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from conversant.conversation import Conversation\n",
    "from conversant.conversation.parse import DataFrameConversationReader\n",
    "from conversant.interactions import InteractionsGraph\n",
    "from conversant.interactions.interactions_graph import PairInteractionsData\n",
    "from conversant.interactions.reply_interactions_parser import get_reply_interactions_parser\n",
    "from stance_classification.classifiers.base_stance_classifier import BaseStanceClassifier\n",
    "from stance_classification.classifiers.greedy_stance_classifier import MSTStanceClassifier\n",
    "from stance_classification.draw_utils import new_figure\n",
    "%matplotlib inline\n",
    "\n",
    "from stance_classification.classifiers.maxcut_stance_classifier import MaxcutStanceClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def load_authors_map(authors_root_path: str) -> Dict[str, str]:\n",
    "    post_authors_map = {}\n",
    "    for topic_name in os.listdir(authors_root_path):\n",
    "        topic_dirpath = os.path.join(authors_root_path, topic_name)\n",
    "        for discussion_file in os.listdir(topic_dirpath):\n",
    "            discussion_path = os.path.join(topic_dirpath, discussion_file)\n",
    "            with open(discussion_path, 'r') as f:\n",
    "                post_author_pairs = list(map(lambda l: tuple(map(str.strip, l.strip().split(' ', 1))), f))\n",
    "                try:\n",
    "                    post_full_id_author_pairs = [(f\"{topic_name}.{post_id}\", author) for post_id, author in post_author_pairs]\n",
    "                    post_authors_map.update(post_full_id_author_pairs)\n",
    "                except:\n",
    "                    print([e for e in post_author_pairs if len(e) != 2])\n",
    "                    raise\n",
    "\n",
    "    return post_authors_map"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/dev/data/stance/create-debate/reason/stance/authors'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-8a88e73012ed>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mposts_author_path\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"/home/dev/data/stance/create-debate/reason/stance/authors\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mauthors_map\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mload_authors_map\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mposts_author_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mauthors_map\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-2-9fc4b603431a>\u001B[0m in \u001B[0;36mload_authors_map\u001B[0;34m(authors_root_path)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mload_authors_map\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mauthors_root_path\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mDict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m     \u001B[0mpost_authors_map\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m{\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0;32mfor\u001B[0m \u001B[0mtopic_name\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlistdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mauthors_root_path\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m         \u001B[0mtopic_dirpath\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mauthors_root_path\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtopic_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mdiscussion_file\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlistdir\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtopic_dirpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/home/dev/data/stance/create-debate/reason/stance/authors'"
     ]
    }
   ],
   "source": [
    "posts_author_path = \"/home/dev/data/stance/create-debate/reason/stance/authors\"\n",
    "authors_map = load_authors_map(posts_author_path)\n",
    "len(authors_map)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_author(topic: str, post_id: str) -> str:\n",
    "    return authors_map.get(post_id, None)\n",
    "\n",
    "def get_record_from_post(topic_dir: str, meta_file: str) -> Dict[str, Any]:\n",
    "    topic = topic_dir.split(\"/\")[-1]\n",
    "    discussion_id = topic + \".\" + \"\".join(takewhile(str.isalpha, meta_file))\n",
    "    meta_filepath = os.path.join(topic_dir, meta_file)\n",
    "    text_filepath = os.path.join(topic_dir, meta_filepath.split(\".\")[0] + \".data\")\n",
    "    with open(text_filepath, 'r') as text_f:\n",
    "        text = text_f.read().strip()\n",
    "\n",
    "    \"\"\" example to meta file content:\n",
    "        ID=24\n",
    "        PID=23\n",
    "        Stance=-1\n",
    "        rebuttal=oppose\n",
    "    \"\"\"\n",
    "    record = {}\n",
    "    with open(meta_filepath, 'r') as meta_f:\n",
    "        post_id = discussion_id + next(meta_f).strip().split(\"=\")[1]\n",
    "        parent_id_str = next(meta_f).strip().split(\"=\")[1]\n",
    "        parent_post_id = (discussion_id + parent_id_str) if parent_id_str != \"-1\" else None\n",
    "        stance_str = next(meta_f).strip().split(\"=\")[1]\n",
    "        stance = int(bool(int(stance_str) + 1)) if len(stance_str) > 0 else None\n",
    "        rebuttal = next(meta_f).strip().split(\"=\")[1]\n",
    "        author_id = get_author(topic, post_id)\n",
    "        if parent_post_id == -1:\n",
    "            parent_post_id = None\n",
    "\n",
    "\n",
    "        record.update(\n",
    "            dict(topic=topic, discussion_id=discussion_id, post_id=post_id, author_id=author_id, creation_date=-1,\n",
    "                      parent_post_id=parent_post_id, text=text, discussion_stance_id=stance, rebuttal=rebuttal)\n",
    "        )\n",
    "    return record"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data_root_dir = \"/home/dev/data/stance/create-debate/reason/stance\"\n",
    "records = []\n",
    "for topic_dirname in os.listdir(data_root_dir):\n",
    "    if topic_dirname == \"author\": continue\n",
    "    topic_dirpath = os.path.join(data_root_dir, topic_dirname)\n",
    "    if not os.path.isdir(topic_dirpath): continue\n",
    "    for post_file in os.listdir(topic_dirpath):\n",
    "        if post_file.endswith(\".meta\"):\n",
    "            record = get_record_from_post(topic_dirpath, post_file)\n",
    "            records.append(record)\n",
    "\n",
    "len(records)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(records)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# unified_data_path = \"/home/dev/data/stance/create-debate/reason/stance/all_records.csv\"\n",
    "# df.to_csv(unified_data_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### fill all missing parents as direct replies to the discussion title (with post id as the discussion's"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"parent_post_id\"] = df.apply(\n",
    "    lambda row: (row[\"discussion_id\"] + \"0\") if row[\"parent_post_id\"] is None else row[\"parent_post_id\"],\n",
    "    axis=1\n",
    ")\n",
    "df[\"parent_post_id\"]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### add the first post to the dataframe\n",
    "add the record that started the discussion as posts in the discussion, so the conversation parser would add them as records.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_records = []\n",
    "for discussion_id in df[\"discussion_id\"].unique():\n",
    "    topic = discussion_id.split(\".\")[0]\n",
    "    record = {\n",
    "        \"topic\": topic,\n",
    "        \"discussion_id\": discussion_id,\n",
    "        \"post_id\": discussion_id + \"0\",\n",
    "        \"author_id\": \"!UNK\",\n",
    "        \"creation_date\": \"00:00\",\n",
    "        \"parent_post_id\": None,\n",
    "        \"text\": \"\",\n",
    "        \"discussion_stance_id\": 0.5,\n",
    "        \"rebuttal\": None\n",
    "    }\n",
    "    new_records.append(record)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.append(new_records, ignore_index=True)\n",
    "df.to_csv(\"/Users/ronpick/workspace/zero-shot-stance/data/createdebate/createdebate-subconvs.csv\", index=False)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pasre_strategy = {\n",
    "    \"node_id\": \"post_id\",\n",
    "    \"author\": \"author_id\",\n",
    "    \"timestamp\": \"creation_date\",\n",
    "    \"parent_id\": \"parent_post_id\"\n",
    "    }\n",
    "parser = DataFrameConversationReader(pasre_strategy)\n",
    "gb = df.groupby(\"discussion_id\")\n",
    "convs: List[Conversation] = list(tqdm(map(parser.parse, map(itemgetter(1), gb))))\n",
    "len(convs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sub_convs = [Conversation(child) for conv in convs for child in conv.root.children]\n",
    "len(sub_convs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#conversation stats"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sizes = [c.size for c in sub_convs]\n",
    "print(len(sizes))\n",
    "print(np.mean(sizes))\n",
    "print(np.median(sizes))\n",
    "pd.Series(sizes).describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pd.Series(sizes).plot.hist()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "filtered_sizes = [s for s in sizes if s >= 10]\n",
    "print(len(filtered_sizes))\n",
    "print(np.mean(filtered_sizes))\n",
    "print(np.median(filtered_sizes))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "post_labels = {(conv.id, node.node_id): node.data[\"discussion_stance_id\"] for conv in sub_convs for _,node in conv.iter_conversation() if node.data[\"discussion_stance_id\"] != 0.5}\n",
    "len(post_labels)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load Author labels"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_majority_vote(labels: List[int]) -> int:\n",
    "    return int(np.mean(labels) >= 0.5)\n",
    "\n",
    "def get_author_labels(c: Conversation) -> Dict[Any, int]:\n",
    "    authors_post_labels = {}\n",
    "    for depth, node in c.iter_conversation():\n",
    "        data = node.data\n",
    "        author = node.author\n",
    "        current_author_labels = authors_post_labels.setdefault(author, [])\n",
    "        current_author_labels.append(data[\"discussion_stance_id\"])\n",
    "\n",
    "    result_labels = {a: get_majority_vote(labels) for a, labels in authors_post_labels.items()}\n",
    "    return result_labels\n",
    "\n",
    "author_labels_per_conversation = {c.id: get_author_labels(c) for c in sub_convs}\n",
    "author_labels_per_conversation = {k: v for k, v in author_labels_per_conversation.items() if len(v) > 0 and not (len(v) == 1 and None in v)}\n",
    "print(len(author_labels_per_conversation))\n",
    "print(sum(len(v) for v in author_labels_per_conversation.values()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_ordered_candidates_for_pivot(graph: nx.Graph, weight_field: str = \"weight\") -> Sequence[Any]:\n",
    "    inv_weight_field = \"inv_weight\"\n",
    "    for _, _, pair_data in graph.edges(data=True):\n",
    "        weight = pair_data.data[weight_field]\n",
    "        pair_data.data[inv_weight_field] = 1 / weight\n",
    "\n",
    "    node_centralities = nx.closeness_centrality(graph, distance=inv_weight_field)\n",
    "    return list(map(itemgetter(0), sorted(node_centralities.items(), key=itemgetter(1), reverse=True)))\n",
    "\n",
    "def get_pivot_node(graph: nx.Graph, labeled_authors: Set[Any], weight_field: str = \"weight\") -> Any:\n",
    "    candidates = get_ordered_candidates_for_pivot(graph, weight_field=weight_field)\n",
    "    return next(iter(filter(labeled_authors.__contains__, candidates)), None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def extend_preds(graph: nx.Graph, seed_node: Any, core_authors_preds: Dict[Any, int]) -> Dict[Any, int]:\n",
    "    extended_results = dict(core_authors_preds.items())\n",
    "    for (n1, n2) in nx.bfs_edges(graph, source=seed_node):\n",
    "        if n2 not in extended_results:\n",
    "            n1_label = extended_results[n1]\n",
    "            extended_results[n2] = 1 - n1_label\n",
    "\n",
    "    return extended_results\n",
    "\n",
    "def get_authors_labels_in_conv(conv: Conversation) -> Dict[Any, int]:\n",
    "    if conv.id not in author_labels_per_conversation:\n",
    "        return None\n",
    "\n",
    "    return author_labels_per_conversation[conv.id]\n",
    "\n",
    "def get_author_preds(clf: BaseStanceClassifier, pivot: Any) -> Dict[Any, int]:\n",
    "    support_label = authors_labels[pivot]\n",
    "    opposer_label = 1 - support_label\n",
    "    supporters = clf.get_supporters()\n",
    "    opposers = clf.get_complement()\n",
    "    preds = {}\n",
    "    for supporter in supporters:\n",
    "        preds[supporter] = support_label\n",
    "    for opposer in opposers:\n",
    "        preds[opposer] = opposer_label\n",
    "\n",
    "    return preds\n",
    "\n",
    "def get_maxcut_results(graph: InteractionsGraph, op: Any) -> MaxcutStanceClassifier:\n",
    "    maxcut = MaxcutStanceClassifier(weight_field=graph.WEIGHT_FIELD)\n",
    "    maxcut.set_input(graph.graph, op)\n",
    "    maxcut.classify_stance()\n",
    "    return maxcut\n",
    "\n",
    "def get_greedy_results(graph: InteractionsGraph, op: Any) -> BaseStanceClassifier:\n",
    "    clf = MSTStanceClassifier()#weight_field=graph.WEIGHT_FIELD)\n",
    "    clf.set_input(graph.graph)\n",
    "    clf.classify_stance(op)\n",
    "    return clf\n",
    "\n",
    "def align_gs_with_predictions(authors_labels: Dict[Any, int], author_preds: Dict[Any, int]) -> Tuple[List[int], List[int]]:\n",
    "    y_true, y_pred = [], []\n",
    "    for author, true_label in authors_labels.items():\n",
    "        pred = author_preds.get(author, None)\n",
    "        if pred is None: continue\n",
    "\n",
    "        y_true.append(true_label)\n",
    "        y_pred.append(pred)\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "def predict_for_partition(true: List[int], preds: List[int]) -> Tuple[List[int], List[int]]:\n",
    "    acc = accuracy_score(true, preds)\n",
    "    if acc < 0.5:\n",
    "        preds = [1-l for l in preds]\n",
    "\n",
    "    return true, preds\n",
    "\n",
    "def get_best_preds(true_labels: Dict[Any, int], pred_labels: Dict[Any, int]) -> Dict[Any, int]:\n",
    "    true, preds = align_gs_with_predictions(true_labels, pred_labels)\n",
    "    acc = accuracy_score(true, preds)\n",
    "    if acc < 0.5:\n",
    "        return {k: (1-  l) for k, l in pred_labels.items()}\n",
    "\n",
    "    return pred_labels\n",
    "\n",
    "def get_posts_preds(conv: Conversation, post_labels: Dict[Any, int], author_preds: Dict[Any, int]) -> Tuple[Dict[Any, int], Dict[Any, int]]:\n",
    "    posts_true, posts_pred = {}, {}\n",
    "    conv_id = conv.id\n",
    "    for depth, node in conv.iter_conversation():\n",
    "        label = post_labels.get((conv_id, node.node_id), None)\n",
    "        if label is None: continue\n",
    "        pred = author_preds.get(node.author, None)\n",
    "        if pred is None: continue\n",
    "\n",
    "        posts_true[node.node_id] = label\n",
    "        posts_pred[node.node_id] = pred\n",
    "\n",
    "    return posts_true, posts_pred"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interactions_parser = get_reply_interactions_parser()\n",
    "\n",
    "convs_by_id: Dict[Any, Conversation] = {}\n",
    "full_graphs: Dict[Any, InteractionsGraph] = {}\n",
    "core_graphs: Dict[Any, InteractionsGraph] = {}\n",
    "maxcut_results: Dict[Any, MaxcutStanceClassifier] = {}\n",
    "pivot_nodes = {}\n",
    "\n",
    "author_predictions: Dict[Any, Dict[str, Dict[Any, int]]] = {}\n",
    "posts_predictions: Dict[Any, Dict[str, Dict[Any, int]]] = {}\n",
    "\n",
    "\n",
    "\n",
    "empty_core = []\n",
    "unlabeled_conversations = []\n",
    "unlabeled_op = []\n",
    "insufficient_author_labels = []\n",
    "too_small_cut_value = []\n",
    "op_not_in_core = []\n",
    "large_graphs = []\n",
    "single_author_conv = []\n",
    "\n",
    "extend_results = False\n",
    "naive_results = False\n",
    "\n",
    "def calc_weight(interactions: PairInteractionsData) -> float:\n",
    "    n_replies = interactions[\"replies\"]\n",
    "    # n_quotes = interactions[\"quotes\"]\n",
    "    return n_replies\n",
    "    # return n_quotes\n",
    "\n",
    "count_conv = 0\n",
    "for i, conv in tqdm(enumerate(sub_convs)):\n",
    "\n",
    "\n",
    "    count_conv += 1\n",
    "    authors_labels = get_authors_labels_in_conv(conv)\n",
    "    if authors_labels is None:\n",
    "        unlabeled_conversations.append(i)\n",
    "        continue\n",
    "\n",
    "    if len(authors_labels) == 0:\n",
    "        insufficient_author_labels.append(i)\n",
    "        continue\n",
    "\n",
    "    interaction_graph = interactions_parser.parse(conv)\n",
    "    interaction_graph.set_interaction_weights(calc_weight)\n",
    "    zero_edges = [(v, u) for v, u, d in interaction_graph.graph.edges(data=True) if d[\"weight\"] == 0]\n",
    "    interaction_graph.graph.remove_edges_from(zero_edges)\n",
    "\n",
    "    if len(conv.participants) <= 1:\n",
    "        single_author_conv.append(i)\n",
    "        continue\n",
    "\n",
    "    convs_by_id[conv.id] = conv\n",
    "    full_graphs[conv.id] = interaction_graph\n",
    "\n",
    "    pivot_node = get_pivot_node(interaction_graph.graph, authors_labels, weight_field=\"weight\")\n",
    "    pivot_nodes[conv.id] = pivot_node\n",
    "\n",
    "    mst = get_greedy_results(interaction_graph, pivot_node)\n",
    "    preds = get_author_preds(mst, pivot_node)\n",
    "    author_predictions[conv.id] = {\"mst\": preds}\n",
    "\n",
    "    if naive_results:\n",
    "        continue\n",
    "\n",
    "    core_interactions = interaction_graph.get_core_interactions()\n",
    "    core_graphs[conv.id] = core_interactions\n",
    "    if core_interactions.graph.size() == 0:\n",
    "        empty_core.append(i)\n",
    "        continue\n",
    "\n",
    "    components = list(nx.connected_components(core_interactions.graph))\n",
    "    core_interactions = core_interactions.get_subgraph(components[0])\n",
    "    pivot_node = get_pivot_node(core_interactions.graph, authors_labels, weight_field=\"weight\")\n",
    "    maxcut = get_maxcut_results(core_interactions, pivot_node)\n",
    "    if maxcut.cut_value < 3:\n",
    "        too_small_cut_value.append(i)\n",
    "        continue\n",
    "\n",
    "    maxcut_results[conv.id] = maxcut\n",
    "\n",
    "    # if core_interactions.graph.order() > 120:\n",
    "    #     large_graphs.append(conv)\n",
    "    #     continue\n",
    "\n",
    "    preds = get_author_preds(maxcut, pivot_node)\n",
    "    author_predictions[conv.id][\"core\"] = preds\n",
    "\n",
    "    # get extended results\n",
    "    preds = extend_preds(interaction_graph.graph, pivot_node, preds)\n",
    "    author_predictions[conv.id][\"full\"] = preds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f\"total number of conversations (in all topics): {len(convs)}\")\n",
    "print(f\"total number of conversations (in the relevant topics): {count_conv}\")\n",
    "print(f\"total number of conversations with labeled authors (in all topics): {len(author_labels_per_conversation)}\")\n",
    "print(f\"total number of conversations with labeled authors (in the relevant topics): {count_conv - len(unlabeled_conversations)}\")\n",
    "\n",
    "print(f\"number of conversations in eval: {len(convs_by_id)}\")\n",
    "print(f\"number of conversations with core in eval: {len(core_graphs)}\")\n",
    "all_authors_in_eval = set(chain(*[predictions[\"mst\"].keys() for predictions in author_predictions.values()]))\n",
    "print(f\"number of unique authors in eval: {len(all_authors_in_eval)}\")\n",
    "all_authors_in_core_eval = set(chain(*[predictions.get(\"core\", {}).keys() for predictions in author_predictions.values()]))\n",
    "print(f\"number of unique authors in core: {len(all_authors_in_core_eval)}\")\n",
    "\n",
    "labeled_authors = sum(len(v) for v in author_labels_per_conversation.values())\n",
    "print(f\"total number of labeled authors: {labeled_authors}\")\n",
    "print(\"=========\")\n",
    "print(f\"number of conversations with single author: {len(single_author_conv)}\")\n",
    "print(f\"number of conversations with empty core: {len(empty_core)}\")\n",
    "print(f\"number of conversations with op not in core: {len(op_not_in_core)}\")\n",
    "print(f\"number of conversations with too large core: {len(large_graphs)}\")\n",
    "print(f\"number of conversations with too small cut value: {len(too_small_cut_value)}\")\n",
    "print(f\"number of unlabeled conversations: {len(unlabeled_conversations)}\")\n",
    "print(f\"number of conversations with unlabeled op: {len(unlabeled_op)}\")\n",
    "print(f\"number of conversations with insufficient labeled authors: {len(insufficient_author_labels)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic_id = 9\n",
    "for predictor in [\"core\", \"full\", \"mst\"]:\n",
    "    all_true, all_pred = [], []\n",
    "    all_true_best, all_pred_best = [], []\n",
    "\n",
    "    accuracies = []\n",
    "    best_accuracies = []\n",
    "    for conv_id, predictions in author_predictions.items():\n",
    "        conv = convs_by_id[conv_id]\n",
    "        # topic = conv.root.data[\"topic\"]\n",
    "        # if topic != topic_id: continue\n",
    "        author_labels = get_authors_labels_in_conv(conv)\n",
    "        author_preds = predictions.get(predictor, None)\n",
    "        if author_preds is None: continue\n",
    "\n",
    "        y_true, y_pred = align_gs_with_predictions(author_labels, author_preds)\n",
    "        all_true.extend(y_true)\n",
    "        all_pred.extend(y_pred)\n",
    "        accuracies.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "        best_preds = get_best_preds(author_labels, author_preds)\n",
    "        y_true, y_pred = align_gs_with_predictions(author_labels, best_preds)\n",
    "        all_true_best.extend(y_true)\n",
    "        all_pred_best.extend(y_pred)\n",
    "        best_accuracies.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "    print(\"acc ---- (macro):\", np.mean(accuracies))\n",
    "    print(\"acc best (macro):\", np.mean(best_accuracies))\n",
    "    print(\"acc ---- (micro):\", accuracy_score(all_true, all_pred))\n",
    "    print(\"acc best (micro):\", accuracy_score(all_true_best, all_pred_best))\n",
    "    print(f\"Showing results of predictor: {predictor}\")\n",
    "    print(classification_report(all_true, all_pred))\n",
    "    print(f\"\\n\\t\\tResults for best partition (regardless for stance assignment\")\n",
    "    print(classification_report(all_true_best, all_pred_best))\n",
    "    print(\"-----------------------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "(66+78.7+77.1+68.3)/4\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for predictor in [\"core\", \"full\", \"mst\"]:\n",
    "    all_true, all_pred = [], []\n",
    "    all_true_best, all_pred_best = [], []\n",
    "    accuracies = []\n",
    "    best_accuracies = []\n",
    "    for conv_id, predictions in author_predictions.items():\n",
    "        conv = convs_by_id[conv_id]\n",
    "        author_labels = get_authors_labels_in_conv(conv)\n",
    "        author_preds = predictions.get(predictor, None)\n",
    "        if author_preds is None: continue\n",
    "\n",
    "        posts_true, posts_preds = get_posts_preds(conv, post_labels, author_preds)\n",
    "\n",
    "        y_true, y_pred = align_gs_with_predictions(posts_true, posts_preds)\n",
    "        all_true.extend(y_true)\n",
    "        all_pred.extend(y_pred)\n",
    "        accuracies.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "        best_preds = get_best_preds(posts_true, posts_preds)\n",
    "        y_true, y_pred = align_gs_with_predictions(posts_true, best_preds)\n",
    "        all_true_best.extend(y_true)\n",
    "        all_pred_best.extend(y_pred)\n",
    "        best_accuracies.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "    print(\"acc ---- (macro):\", np.mean(accuracies))\n",
    "    print(\"acc best (macro):\", np.mean(best_accuracies))\n",
    "    print(\"acc ---- (micro):\", accuracy_score(all_true, all_pred))\n",
    "    print(\"acc best (micro):\", accuracy_score(all_true_best, all_pred_best))\n",
    "    print(f\"Showing results of predictor: {predictor}\")\n",
    "    print(classification_report(all_true, all_pred))\n",
    "    print(f\"\\n\\tResults for best partition (regardless for stance assignment\")\n",
    "    print(classification_report(all_true_best, all_pred_best))\n",
    "    print(\"-----------------------------------------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_pairs_average_distance(\n",
    "        pairs: Iterable[Tuple[int, int]],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    distances = list(starmap(lambda i, j: cosine(embeddings[i], embeddings[j]), pairs))\n",
    "    return float(np.mean(distances))\n",
    "\n",
    "\n",
    "def compute_average_angle_from_node(\n",
    "        node_index: int,\n",
    "        group_indices: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = ((node_index, i) for i in group_indices)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)\n",
    "\n",
    "\n",
    "def compute_group_average_angle(\n",
    "        group_indices: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = combinations(group_indices, 2)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)\n",
    "\n",
    "\n",
    "def compute_cross_groups_average_angle(\n",
    "        group1: Sequence[int],\n",
    "        group2: Sequence[int],\n",
    "        embeddings: Sequence[np.ndarray]\n",
    ") -> float:\n",
    "    pairs = product(group1, group2)\n",
    "    return compute_pairs_average_distance(pairs, embeddings)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "supporters_avg_angles = []\n",
    "opposers_avg_angles = []\n",
    "mean_cross_angle = []\n",
    "op2supporters = []\n",
    "op2opposers = []\n",
    "for i in range(len(maxcut_results)):\n",
    "    maxcut = maxcut_results[i]\n",
    "    op, all_embeddings, supporters, opposers =\\\n",
    "        maxcut.op, maxcut.embeddings, maxcut.get_supporters(), maxcut.get_complement()\n",
    "\n",
    "    op2supporters.append(compute_average_angle_from_node(op, supporters, all_embeddings))\n",
    "    op2opposers.append(compute_average_angle_from_node(op, opposers, all_embeddings))\n",
    "\n",
    "    supporters_avg_angles.append(compute_group_average_angle(supporters, all_embeddings))\n",
    "    opposers_avg_angles.append(compute_group_average_angle(opposers, all_embeddings))\n",
    "\n",
    "    mean_cross_angle.append(compute_cross_groups_average_angle(supporters, opposers, all_embeddings))\n",
    "\n",
    "print(f\"total conversations {len(maxcut_results)}\")\n",
    "print(f\"supporters avg. cosine {np.nanmean(supporters_avg_angles)}\")\n",
    "print(f\"opposers avg. cosine {np.nanmean(opposers_avg_angles)}\")\n",
    "print(f\"cross groups avg. cosine {np.mean(mean_cross_angle)}\")\n",
    "print(f\"op to supporters avg. cosine {np.mean(op2supporters)}\")\n",
    "print(f\"op to opposers avg. cosine {np.mean(op2opposers)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "strong_convs_indices = []\n",
    "for i in range(len(filtered_convs)):\n",
    "    op2s = op2supporters[i]\n",
    "    op2o = op2opposers[i]\n",
    "    if op2supporters[i] * op2opposers[i] == 0:\n",
    "        continue\n",
    "\n",
    "    diff = op2o - op2s\n",
    "    ratio = op2o / op2s\n",
    "    if (ratio > 2) and (diff > 1):\n",
    "        strong_convs_indices.append(i)\n",
    "\n",
    "len(strong_convs_indices)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# strong_true, strong_preds = zip(*[classification_results[i] for i in strong_convs_indices])\n",
    "# strong_true = list(chain(*strong_true))\n",
    "# strong_preds = list(chain(*strong_preds))\n",
    "strong_true = list(chain(*[author_true_best[i] for i in strong_convs_indices]))\n",
    "strong_preds = list(chain(*[author_pred_best[i] for i in strong_convs_indices]))\n",
    "print(classification_report(strong_true, strong_preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "max_i = 0\n",
    "max_shape = 0\n",
    "# sizes = [(i, g.graph.order()) for i, g  in enumerate(core_graphs)]\n",
    "sizes = [(i, core_graphs[i].graph.order()) for i in range(len(filtered_convs))]\n",
    "sorted_sized = sorted(sizes, key=itemgetter(1), reverse=True)\n",
    "sorted_sized[:20]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result_index = 0\n",
    "\n",
    "maxcut = maxcut_results[result_index]\n",
    "op, emb, supporters, opposers = maxcut.op, maxcut.embeddings, maxcut.get_supporters(), maxcut.get_complement()\n",
    "\n",
    "s_cosine = compute_group_average_angle(supporters, emb)\n",
    "o_cosine = compute_group_average_angle(opposers, emb)\n",
    "cross_cosine = compute_cross_groups_average_angle(supporters, opposers, emb)\n",
    "op2support = compute_average_angle_from_node(op, supporters, emb)\n",
    "op2oppose = compute_average_angle_from_node(op, opposers, emb)\n",
    "print(f\"num supporters: {len(supporters)}\")\n",
    "print(f\"num opposers: {len(opposers)}\")\n",
    "print(f\"supporters avg. cosine: {s_cosine}\")\n",
    "print(f\"opposers avg. cosine: {o_cosine}\")\n",
    "print(f\"cross-groups avg. cosine: {cross_cosine}\")\n",
    "print(f\"op <-> supporters avg. cosine: {op2support}\")\n",
    "print(f\"op <-> opposers avg. cosine: {op2oppose}\")\n",
    "print(f\"supporters - opposers diff cosine with op: {op2oppose - op2support}\")\n",
    "print(f\"supporters - opposers ratio cosine with op: {op2oppose / op2support}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Author classification results\n",
    "For the current conversation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true = author_true[result_index]\n",
    "preds = author_pred[result_index]\n",
    "print(classification_report(true, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true = author_true_best[result_index]\n",
    "preds = author_pred_best[result_index]\n",
    "print(classification_report(true, preds))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Post classification results\n",
    "For the current conversation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true = posts_true[result_index]\n",
    "preds = posts_pred[result_index]\n",
    "print(classification_report(true, preds))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Post partition classification results\n",
    "For the current conversation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "true = post_true_best[result_index]\n",
    "preds = post_pred_best[result_index]\n",
    "print(classification_report(true, preds))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "conv = filtered_convs[result_index]\n",
    "author_labels = get_author_labels(conv)\n",
    "true_supporters = [n for n, l in author_labels.items() if l == 1]\n",
    "true_opposers = [n for n, l in author_labels.items() if l == 0]\n",
    "unknown_labels = set(author_labels.keys()) - (set(supporters) | set(opposers))\n",
    "len(author_labels), len(true_opposers), len(true_supporters), len(unknown_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "\n",
    "X = np.vstack([np.array(x) for x in emb.values()])\n",
    "pca = PCA(n_components=2)\n",
    "X_2d = pca.fit_transform(X)\n",
    "# X_2d = TSNE(n_components=2).fit_transform(X)\n",
    "print(pca.explained_variance_)\n",
    "op = maxcut.op\n",
    "nodes = emb.keys()\n",
    "tp_supporters_indices = [i for i, n in enumerate(nodes) if n in true_supporters and n in supporters]\n",
    "fn_supporters_indices = [i for i, n in enumerate(nodes) if n in true_supporters and n in opposers]\n",
    "tp_opposers_indices = [i for i, n in enumerate(nodes) if n in true_opposers and n in opposers]\n",
    "fn_opposers_indices = [i for i, n in enumerate(nodes) if n in true_opposers and n in supporters]\n",
    "unlabeled_supporters = [i for i, n in enumerate(nodes) if n not in author_labels and n in supporters]\n",
    "unlabeled_opposers = [i for i, n in enumerate(nodes) if n not in author_labels and n in opposers]\n",
    "\n",
    "op_index = [i for i, n in enumerate(nodes) if n == op]\n",
    "\n",
    "plt.scatter(X_2d[tp_supporters_indices, 0], X_2d[tp_supporters_indices, 1], color='g', marker='+')\n",
    "plt.scatter(X_2d[fn_supporters_indices, 0], X_2d[fn_supporters_indices, 1], color='g', marker='x')\n",
    "plt.scatter(X_2d[tp_opposers_indices, 0], X_2d[tp_opposers_indices, 1], color='r', marker='+')\n",
    "plt.scatter(X_2d[fn_opposers_indices, 0], X_2d[fn_opposers_indices, 1], color='r', marker='x')\n",
    "plt.scatter(X_2d[unlabeled_supporters, 0], X_2d[unlabeled_supporters, 1], color='grey', marker='+')\n",
    "plt.scatter(X_2d[unlabeled_opposers, 0], X_2d[unlabeled_opposers, 1], color='grey', marker='x')\n",
    "plt.scatter([X_2d[op_index, 0]], [X_2d[op_index, 1]], color='b', marker='o')\n",
    "\n",
    "# colors = ['b' if i == op else 'g' if i in supporters else 'r' for i in nodes]\n",
    "# markers = ['o' if i ==op else 'x' if i in supporters else '+' for i in nodes]\n",
    "# plt.scatter(X_2d[:, 0], X_2d[:, 1], color=colors)\n",
    "# op_index = [i for i, n  in enumerate(nodes) if n == op][0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "new_figure()\n",
    "graph = maxcut.graph\n",
    "pos = nx.spring_layout(graph)\n",
    "\n",
    "all_nodes = list(nodes)\n",
    "tps = [all_nodes[i] for i in tp_supporters_indices]\n",
    "fns = [all_nodes[i] for i in fn_supporters_indices]\n",
    "fno = [all_nodes[i] for i in fn_opposers_indices]\n",
    "tpo = [all_nodes[i] for i in tp_opposers_indices]\n",
    "unks = [all_nodes[i] for i in unlabeled_supporters]\n",
    "unko = [all_nodes[i] for i in unlabeled_opposers]\n",
    "op = [all_nodes[i] for i in op_index]\n",
    "\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=tps, node_color='g', node_shape='s', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=fns, node_color='g', node_shape='^', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=fno, node_color='r', node_shape='s', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=tpo, node_color='r', node_shape='^', edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=unks, node_color='grey', node_shape=\"s\", edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=unko, node_color='grey', node_shape=\"^\", edgecolors=\"black\")\n",
    "nx.draw_networkx_nodes(graph, pos, nodelist=op, node_color='b', node_shape='o', edgecolors=\"black\")\n",
    "\n",
    "node_labels = {n: str(n) for n in graph.nodes}\n",
    "nx.draw_networkx_labels(graph, pos, labels=node_labels, font_color=\"tab:brown\")\n",
    "\n",
    "# Draw the edges that are in the cut.\n",
    "edge_weights = [np.log2(graph[e[0]][e[1]]['weight']) for e in maxcut.cut]\n",
    "nx.draw_networkx_edges(graph, pos, edgelist=maxcut.cut, edge_color=\"black\", width=edge_weights)\n",
    "#\n",
    "# # Draw the edges that are not in the cut\n",
    "leave = [e for e in graph.edges if e not in maxcut.cut]\n",
    "non_cut_weigths = [np.log2(graph[e[0]][e[1]]['weight']) for e in leave]\n",
    "nx.draw_networkx_edges(graph, pos, edgelist=leave, edge_color=\"darkgray\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "conv_id = filtered_convs[result_index].id\n",
    "author_labels = author_labels_per_conversation[conv_id]\n",
    "print(author_labels)\n",
    "maxcut.draw(true_labels=author_labels)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "full_graph = full_graphs[result_index]\n",
    "layout = nx.spring_layout(full_graph.graph)\n",
    "nx.draw(full_graph.graph, layout)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kcore = core_graphs[result_index]\n",
    "layout = nx.spring_layout(kcore.graph)\n",
    "nx.draw(kcore.graph, layout)\n",
    "\n",
    "kcore.graph.order()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}